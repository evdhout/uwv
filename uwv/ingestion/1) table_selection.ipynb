{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cbsodata\n",
    "import re\n",
    "import json\n",
    "import requests\n",
    "import concurrent.futures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting criteria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the desired SBI codes\n",
    "# Load the SBI data from the JSON file\n",
    "with open('data/sbi_data.json', 'r', encoding='utf-8') as sbi_file:\n",
    "    sbi_data = json.load(sbi_file)\n",
    "    \n",
    "# Define the desired SBI information\n",
    "desired_sbi_title = [\"Q Gezondheids- en welzijnszorg\", \"G Handel\", \"C Industrie\", \"M Specialistische zakelijke diensten\", \"N Verhuur en overige zakelijke diensten\", \"O Openbaar bestuur en overheidsdiensten\"]\n",
    "# desired_sbi_title = None\n",
    "    \n",
    "# Define the desired frequencies\n",
    "# desired_frequencies = None  # Set to None if you don't want to filter by frequencies\n",
    "desired_frequencies = [\n",
    "    \"Fourtimesayear\", \"Viermaalperjaar\", \"Quarterly\", \"Perkwartaal\", \"Threemonthly\", \"Perdriemaanden\", # Quarterly\n",
    "    \"Monthly\",  \"Permaand\", # Monthly\n",
    "    # \"Perweek\",  \"Weekly\", # Weekly\n",
    "    # \"Stopgezet\", \"Discontinued\" # Other\n",
    "]\n",
    "\n",
    "# Define the desired identifiers\n",
    "desired_identifiers = None  # Set to None if you don't want to filter by identifiers\n",
    "# desired_identifiers = ['80072ned'] \n",
    "\n",
    "# Define the undesired substrings in the short titles. Data for the Caribian island is excluded\n",
    "undesired_short_titles = ['Caribisch', 'Bonaire']\n",
    "\n",
    "# Define the desired language. Data is available in English and Dutch.\n",
    "desired_language = 'nl'\n",
    "\n",
    "# Define the period range\n",
    "start_year_threshold = 2008\n",
    "end_year_threshold = 2022\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch the list of tables\n",
    "tables = cbsodata.get_table_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered data has been saved to 'table_selection.json'.\n",
      "Filtered identifiers, short titles, periods, and frequencies:\n",
      "Identifier: 83451NED, ShortTitle: Werkgelegenheid; banen, lonen per maand, Period: 2006 januari - 2024 augustus, Frequency: Permaand\n",
      "Identifier: 85928NED, ShortTitle: Prijs van Arbeid; index 2021=100; nr, Period: 2001-2024 juni, Frequency: Perkwartaal\n",
      "Identifier: 85663NED, ShortTitle: Cao-lonen; indexcijfers (2020=100), Period: 1972 jaar - 2024 oktober, Frequency: Permaand\n",
      "Identifier: 80072ned, ShortTitle: Ziekteverzuimpercentage SBI 2008, Period: 1e kwartaal 1996 - 2e kwartaal 2024, Frequency: Perkwartaal\n",
      "Identifier: 81589NED, ShortTitle: Bedrijven; bedrijfstak, Period: 2007 kwI - 2024 kw IV, Frequency: Perkwartaal\n",
      "Identifier: 83147NED, ShortTitle: Bedrijven; fusies en overnames, Period: 2007 - 2024; 2007 1e kwartaal - 2024 3e kwartaal, Frequency: Perkwartaal\n",
      "Identifier: 81588NED, ShortTitle: Bedrijven; bedrijfsgrootte en rechtsvorm, Period: 2007 kwI-2024 kw IV, Frequency: Perkwartaal\n",
      "Identifier: 83149NED, ShortTitle: Bedrijven; opheffingen, Period: 2007 - 2024; 2007 1e kwartaal - 2024 3e kwartaal, Frequency: Perkwartaal\n",
      "Identifier: 83148NED, ShortTitle: Bedrijven; oprichtingen, Period: 2007 - 2024; 2007 1e kwartaal - 2024 3e kwartaal, Frequency: Perkwartaal\n"
     ]
    }
   ],
   "source": [
    "# Function to extract the first and last four-digit numbers from a period string\n",
    "def extract_years(period):\n",
    "    # Find all sequences of four digits\n",
    "    years = re.findall(r'\\b\\d{4}\\b', period)\n",
    "    if len(years) >= 2:\n",
    "        return int(years[0]), int(years[-1])\n",
    "    elif len(years) == 1:\n",
    "        return int(years[0]), int(years[0])\n",
    "    else:\n",
    "        return None, None\n",
    "\n",
    "# List to store the filtered data\n",
    "filtered_data = []\n",
    "\n",
    "# Filter tables and extract identifiers, short titles, languages, periods, frequencies, and SBI code\n",
    "for table in tables:\n",
    "    identifier = table.get('Identifier', 'N/A')\n",
    "    frequency = table.get('Frequency', 'N/A')\n",
    "    short_title = table.get('ShortTitle', 'N/A')\n",
    "    language = table.get('Language', 'N/A')\n",
    "    period = table.get('Period', 'N/A')\n",
    "    \n",
    "    # By default, set these filters to True if no specific filter is applied\n",
    "    passes_identifier_filter = True if desired_identifiers is None else identifier in desired_identifiers\n",
    "    passes_frequency_filter = True if desired_frequencies is None else frequency in desired_frequencies\n",
    "\n",
    "    # Check if the table contains the desired SBI information\n",
    "    sbi_info = sbi_data.get(identifier, None)\n",
    "    passes_sbi_filter = False\n",
    "    sbi_codes_and_titles = []  # This will store all SBI codes and titles\n",
    "\n",
    "    if isinstance(sbi_info, list):\n",
    "        # Extract the titles from the SBI data and compare with the desired_sbi_title list\n",
    "        sbi_titles = {sbi_entry.get('Title', '') for sbi_entry in sbi_info}\n",
    "        \n",
    "        # Check if all desired_sbi_title elements are in the sbi_titles\n",
    "        if all(title in sbi_titles for title in desired_sbi_title):\n",
    "            passes_sbi_filter = True\n",
    "            # Collect all the matching SBI codes and titles\n",
    "            for sbi_entry in sbi_info:\n",
    "                sbi_code = sbi_entry.get('Key', 'Unknown SBI Code')\n",
    "                sbi_title = sbi_entry.get('Title', 'Unknown SBI Title')\n",
    "                sbi_codes_and_titles.append(f\"{sbi_code}: {sbi_title}\")\n",
    "\n",
    "    # Apply all the filters including the SBI code filter\n",
    "    if (passes_identifier_filter and\n",
    "        passes_frequency_filter and\n",
    "        passes_sbi_filter and\n",
    "        language == desired_language and\n",
    "        not any(substring in short_title for substring in undesired_short_titles)):\n",
    "\n",
    "        start_year, end_year = extract_years(period)\n",
    "\n",
    "        if start_year is not None and end_year is not None:\n",
    "            # Check if the period range is within the desired thresholds\n",
    "            if start_year <= start_year_threshold and end_year >= end_year_threshold:\n",
    "                # Append all relevant data including all SBI codes and titles\n",
    "                filtered_data.append({\n",
    "                    'Identifier': identifier,\n",
    "                    'ShortTitle': short_title,\n",
    "                    'Language': language,\n",
    "                    'Period': period,\n",
    "                    'Frequency': frequency,\n",
    "                    'SBI_Codes_and_Titles': sbi_codes_and_titles\n",
    "                })\n",
    "\n",
    "# Save the filtered data to a JSON file\n",
    "with open('data/table_selection.json', 'w', encoding='utf-8') as json_file:\n",
    "    json.dump(filtered_data, json_file, indent=4, ensure_ascii=False)\n",
    "\n",
    "print(\"Filtered data has been saved to 'table_selection.json'.\")\n",
    "\n",
    "# Print the filtered data\n",
    "print(\"Filtered identifiers, short titles, periods, and frequencies:\")\n",
    "for entry in filtered_data:\n",
    "    print(f\"Identifier: {entry['Identifier']}, ShortTitle: {entry['ShortTitle']}, Period: {entry['Period']}, Frequency: {entry['Frequency']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appendix 1 - overview of all frequency, language, period options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize sets for unique frequencies, periods, and languages\n",
    "unique_identifiers = set()\n",
    "unique_frequencies = set()\n",
    "unique_periods = set()\n",
    "unique_languages = set()\n",
    "\n",
    "# Loop through the tables and collect unique frequencies, periods, and languages\n",
    "for table in tables:\n",
    "    identifier = table.get('Identifier', 'N/A')\n",
    "    frequency = table.get('Frequency', 'N/A')\n",
    "    period = table.get('Period', 'N/A')\n",
    "    language = table.get('Language', 'N/A')\n",
    "    \n",
    "    unique_identifiers.add(identifier)\n",
    "    unique_frequencies.add(frequency)\n",
    "    unique_periods.add(period)\n",
    "    unique_languages.add(language)\n",
    "\n",
    "# Convert sets to lists for easier manipulation and JSON serialization\n",
    "unique_identifiers = list(unique_identifiers)\n",
    "unique_frequencies = list(unique_frequencies)\n",
    "unique_periods = list(unique_periods)\n",
    "unique_languages = list(unique_languages)\n",
    "\n",
    "# Create a dictionary to store all the unique data\n",
    "unique_data = {\n",
    "    \"identifiers\": unique_identifiers,\n",
    "    \"frequencies\": unique_frequencies,\n",
    "    \"periods\": unique_periods,\n",
    "    \"languages\": unique_languages\n",
    "}\n",
    "\n",
    "# Save the unique data as a JSON file in the 'data' folder\n",
    "with open('data/unique_data.json', 'w') as json_file:\n",
    "    json.dump(unique_data, json_file, indent=4)\n",
    "\n",
    "print(\"Unique identifiers, frequencies, periods, and languages have been saved to 'data/unique_data.json'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appendix 2 - extracting SBI data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the identifiers from the 'data/unique_data.json' file\n",
    "with open('data/unique_data.json', 'r', encoding='utf-8') as json_file:\n",
    "    unique_data = json.load(json_file)\n",
    "    identifiers = unique_data.get(\"identifiers\", [])  # Extract identifiers list, defaulting to an empty list if not found\n",
    "\n",
    "# Function to check if the identifier is for a Dutch (NED) table and ignore other types (like ENG)\n",
    "def is_valid_ned_identifier(identifier):\n",
    "    # Only process identifiers that end with 'NED' or 'ned', ignore others\n",
    "    return identifier.lower().endswith('ned')\n",
    "\n",
    "# Filter out non-NED identifiers\n",
    "identifiers = [identifier for identifier in identifiers if is_valid_ned_identifier(identifier)]\n",
    "\n",
    "# Function to fetch SBI code information for a single identifier, with fallback between two URLs\n",
    "def fetch_sbi_code(identifier):\n",
    "    urls = [\n",
    "        f\"https://opendata.cbs.nl/ODataApi/OData/{identifier}/BedrijfstakkenBranchesSBI2008\",\n",
    "        f\"https://opendata.cbs.nl/ODataApi/OData/{identifier}/BedrijfskenmerkenSBI2008\"\n",
    "    ]\n",
    "    \n",
    "    for url in urls:\n",
    "        try:\n",
    "            # Send a GET request to the constructed URL\n",
    "            print(f\"Trying URL: {url}\")\n",
    "            response = requests.get(url)\n",
    "            \n",
    "            # Check if the request was successful (HTTP status code 200)\n",
    "            if response.status_code == 200:\n",
    "                # Convert the response to JSON format\n",
    "                data = response.json()\n",
    "\n",
    "                # Check if the 'value' key contains SBI data\n",
    "                if 'value' in data and data['value']:\n",
    "                    return (identifier, data['value'])  # Return identifier with SBI data\n",
    "                else:\n",
    "                    return (identifier, 'No SBI information available')  # No data available\n",
    "            elif response.status_code == 404:\n",
    "                # Try the next URL if the current one returns 404\n",
    "                print(f\"URL {url} returned 404, trying next URL...\")\n",
    "                continue\n",
    "            else:\n",
    "                return (identifier, f\"Request failed with status code {response.status_code}\")\n",
    "        \n",
    "        except Exception as e:\n",
    "            return (identifier, f\"Error occurred: {str(e)}\")\n",
    "\n",
    "    # If neither URL works, return a failure message\n",
    "    return (identifier, \"Failed to fetch SBI data from both URLs\")\n",
    "\n",
    "# Function to extract SBI code information using concurrent requests\n",
    "def extract_sbi_codes_concurrent(identifiers):\n",
    "    sbi_data_dict = {}\n",
    "    \n",
    "    # Use ThreadPoolExecutor to send requests concurrently\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=10) as executor:\n",
    "        # Submit all the fetch_sbi_code tasks\n",
    "        future_to_identifier = {executor.submit(fetch_sbi_code, identifier): identifier for identifier in identifiers}\n",
    "        \n",
    "        # As each request finishes, process the result\n",
    "        for future in concurrent.futures.as_completed(future_to_identifier):\n",
    "            identifier, result = future.result()  # Get the result from the future\n",
    "            sbi_data_dict[identifier] = result  # Store in the dictionary\n",
    "\n",
    "    return sbi_data_dict\n",
    "\n",
    "# Call the concurrent version of the SBI code extraction function\n",
    "sbi_data = extract_sbi_codes_concurrent(identifiers)\n",
    "\n",
    "# Save the dictionary to a file\n",
    "with open('data/sbi_data.json', 'w') as f:\n",
    "    json.dump(sbi_data, f, indent=4)\n",
    "\n",
    "print(\"SBI data has been saved to 'data/sbi_data.json'.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
