{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from IPython.display import display\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load csv into a dataframe\n",
    "df = pd.read_csv(\"data/merged_table.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Selecting time range (exclude the test set data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the Year_Quarter column as the index for easy operations\n",
    "df.set_index('Year_Quarter', inplace=True)\n",
    "\n",
    "# Filter the index to include only values between 2008 and 2021 (inclusive)\n",
    "df_filtered = df[(df.index >= '2008') & (df.index <= '2022')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# General view of data & missing data\n",
    "There is not missing data, the selected time frame is succesfully applied, no strange things to see"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overview of the DataFrame\n",
    "df_filtered.info()\n",
    "\n",
    "# Missing values count and percentage\n",
    "missing_counts = df_filtered.isnull().sum()\n",
    "missing_percentage = (df_filtered.isnull().mean() * 100).sort_values(ascending=False)\n",
    "\n",
    "# Display columns with missing values\n",
    "print(\"\\nColumns with missing values and their percentages:\")\n",
    "print(missing_percentage[missing_percentage > 0])\n",
    "\n",
    "# Quick statistical summary\n",
    "print(\"\\nStatistical summary of the dataset:\")\n",
    "display(df_filtered.describe(include='all'))\n",
    "\n",
    "# Display the first few rows of the dataset\n",
    "print(\"\\nFirst few rows of the dataset:\")\n",
    "display(df_filtered.head())\n",
    "\n",
    "# Display the first few rows of the dataset\n",
    "print(\"\\nLast few rows of the dataset:\")\n",
    "display(df_filtered.tail())\n",
    "\n",
    "# Check the shape of the dataset\n",
    "print(\"\\nShape of the dataset:\")\n",
    "print(f\"Rows: {df_filtered.shape[0]}, Columns: {df_filtered.shape[1]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization\n",
    "- Sick leave data shows a clear seasonal pattern\n",
    "- Temperature data reflects a similar seasonal pattern\n",
    "- Sick leave also seems to have a slowly upward trend\n",
    "- Number of natural persons and rechtspersonen shows a similar pattern\n",
    "- Many features show a completely different pattern than sick leave"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 5\n",
    "numerical_columns = df_filtered.select_dtypes(include='number').columns\n",
    "\n",
    "# Group by 'BedrijfstakkenBranchesSBI2008' and plot for each industry\n",
    "for industry, group in df_filtered.groupby('BedrijfstakkenBranchesSBI2008'):\n",
    "    print(f\"Processing industry: {industry}\")\n",
    "    \n",
    "    # Iterate through batches of numerical columns\n",
    "    for i in range(0, len(numerical_columns), batch_size):\n",
    "        batch_columns = numerical_columns[i:i + batch_size]\n",
    "        \n",
    "        # Plot the selected batch for the current industry group\n",
    "        group[batch_columns].plot(\n",
    "            subplots=True, \n",
    "            figsize=(12, 8), \n",
    "            title=f'{industry} - Time Series Trends for Batch {i//batch_size + 1}'\n",
    "        )\n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the target variable and industry column\n",
    "target_column = '80072ned_Ziekteverzuimpercentage_1'  # Replace with your target variable column\n",
    "industry_column = 'BedrijfstakkenBranchesSBI2008'\n",
    "\n",
    "# Set the correlation threshold\n",
    "threshold = 0.7\n",
    "\n",
    "# Dictionary to store selected columns for each industry\n",
    "selected_columns_by_industry = {}\n",
    "\n",
    "# List to store all unique selected columns across industries\n",
    "all_selected_columns = []\n",
    "\n",
    "# Get the unique industries\n",
    "industries = df_filtered[industry_column].unique()\n",
    "\n",
    "# Iterate over each industry and calculate correlation\n",
    "for industry in industries:\n",
    "    # Filter the DataFrame for the current industry\n",
    "    industry_data = df_filtered[df_filtered[industry_column] == industry]\n",
    "    \n",
    "    # Select only numeric columns\n",
    "    numeric_data = industry_data.select_dtypes(include='number')\n",
    "    \n",
    "    # Calculate correlation matrix\n",
    "    correlation_matrix = numeric_data.corr()\n",
    "    \n",
    "    # Sort features by their absolute correlation with the target\n",
    "    correlation_with_target = correlation_matrix[target_column].abs().sort_values(ascending=False)\n",
    "    \n",
    "    # Display columns with correlation > threshold\n",
    "    filtered_columns = correlation_with_target[correlation_with_target > threshold]\n",
    "    print(f\"\\nColumns with correlation > {threshold} for {industry}:\\n\")\n",
    "    print(filtered_columns)\n",
    "    \n",
    "    # Add selected columns to the industry-specific dictionary\n",
    "    selected_columns_by_industry[industry] = filtered_columns.index.tolist()\n",
    "    \n",
    "    # Add columns to the master list\n",
    "    all_selected_columns.extend(filtered_columns.index.tolist())\n",
    "\n",
    "# Remove duplicates from the combined list\n",
    "all_selected_columns = list(set(all_selected_columns))\n",
    "\n",
    "# Display the combined list of selected columns\n",
    "print(\"\\nAll selected columns across industries:\")\n",
    "print(all_selected_columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the industry column explicitly to the selected columns\n",
    "industry_column = 'BedrijfstakkenBranchesSBI2008'  # Replace with your actual industry column name\n",
    "if industry_column not in all_selected_columns:\n",
    "    all_selected_columns.append(industry_column)\n",
    "\n",
    "# Create a new DataFrame with the selected columns and the industry column\n",
    "selected_df = df_filtered[all_selected_columns]\n",
    "\n",
    "# Display the shape and first few rows of the new DataFrame\n",
    "print(f\"New DataFrame shape: {selected_df.shape}\")\n",
    "selected_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.cluster.hierarchy as sch\n",
    "\n",
    "# Compute the correlation matrix for numeric columns\n",
    "correlation_matrix = selected_df.select_dtypes(include='number').corr()\n",
    "\n",
    "# Perform hierarchical clustering to order the correlation matrix\n",
    "linkage = sch.linkage(correlation_matrix, method='ward')\n",
    "dendrogram_order = sch.leaves_list(linkage)\n",
    "ordered_corr_matrix = correlation_matrix.iloc[dendrogram_order, dendrogram_order]\n",
    "\n",
    "# Set up the matplotlib figure\n",
    "plt.figure(figsize=(8, 6))  # Decrease the figure size\n",
    "\n",
    "# Create a heatmap with seaborn\n",
    "sns.heatmap(\n",
    "    ordered_corr_matrix, \n",
    "    annot=True,        # Display correlation values\n",
    "    cmap='coolwarm',   # Color scheme\n",
    "    fmt='.2f',         # Format for correlation values\n",
    "    vmin=-1, vmax=1,   # Range for correlation values\n",
    "    square=True,       # Make cells square\n",
    "    cbar_kws={\"shrink\": .8},  # Colorbar size\n",
    "    annot_kws={\"size\": 8}  # Set annotation text size\n",
    ")\n",
    "\n",
    "# Add titles and labels\n",
    "plt.title('Clustered Feature Correlation Heatmap', fontsize=14)\n",
    "plt.xticks(fontsize=10, rotation=45)  # Adjust x-axis labels\n",
    "plt.yticks(fontsize=10)              # Adjust y-axis labels\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VIF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate Variance Inflation Factor (VIF)\n",
    "def calculate_vif(dataframe):\n",
    "    \"\"\"\n",
    "    Calculate Variance Inflation Factor (VIF) for each feature in the dataframe.\n",
    "    \n",
    "    Parameters:\n",
    "        dataframe (DataFrame): DataFrame containing numerical features.\n",
    "\n",
    "    Returns:\n",
    "        DataFrame: DataFrame with features and their corresponding VIF values.\n",
    "    \"\"\"\n",
    "    vif_data = pd.DataFrame()\n",
    "    vif_data[\"Feature\"] = dataframe.columns\n",
    "    vif_data[\"VIF\"] = [\n",
    "        variance_inflation_factor(dataframe.values, i) for i in range(dataframe.shape[1])\n",
    "    ]\n",
    "    return vif_data\n",
    "\n",
    "# Select only numeric columns from the filtered DataFrame\n",
    "numeric_columns = selected_df.select_dtypes(include='number')\n",
    "\n",
    "# Calculate VIF for numeric columns\n",
    "vif_df = calculate_vif(numeric_columns)\n",
    "\n",
    "# Exclude rows with NaN or infinite VIF values\n",
    "vif_df = vif_df[~vif_df['VIF'].isin([float('inf'), float('nan')])]\n",
    "\n",
    "# Filter for columns with VIF <= 100\n",
    "low_vif_df = vif_df[vif_df['VIF'] <= 100]\n",
    "\n",
    "# Display columns with VIF <= 10\n",
    "print(\"Features with VIF <= 10:\")\n",
    "print(low_vif_df)\n",
    "\n",
    "# Filter the original DataFrame to retain only columns with VIF <= 10\n",
    "selected_df_no_multicollinearity = df_filtered[low_vif_df['Feature']]\n",
    "\n",
    "# Display updated DataFrame shape\n",
    "print(f\"Updated DataFrame shape after VIF filtering: {selected_df_no_multicollinearity.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time series analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_timeseries = df_filtered[['BedrijfstakkenBranchesSBI2008'] + [col for col in df_filtered.columns if '80072ned_Ziekteverzuimpercentage_1' in col]]\n",
    "\n",
    "# Define the industry column\n",
    "industry_column = 'BedrijfstakkenBranchesSBI2008'\n",
    "\n",
    "# Get the unique industries\n",
    "industries = df_timeseries[industry_column].unique()\n",
    "\n",
    "df_timeseries.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ACF\n",
    "This is an Autocorrelation Function (ACF) plot. Here’s how to interpret it:\n",
    "\n",
    "Initial Observation:\n",
    "\n",
    "The first bar (lag 0) is always 1, as it represents the autocorrelation of the series with itself.\n",
    "Subsequent bars represent the correlation of the series with lagged versions of itself.\n",
    "High Correlation at Specific Lags:\n",
    "\n",
    "You see significant spikes at regular intervals (e.g., lags 1, 5, 9, 13, 17). This suggests a seasonal pattern in the data with a periodicity of approximately 4 lags.\n",
    "Gradual Decline:\n",
    "\n",
    "The values decline gradually (but not strictly exponentially). This could indicate a trend or non-stationarity in the data. The presence of a trend suggests the need for differencing to achieve stationarity before modeling.\n",
    "Confidence Intervals (Shaded Region):\n",
    "\n",
    "The blue shaded region represents the 95% confidence interval. Any spikes outside this region indicate statistically significant autocorrelations.\n",
    "Spikes at lags like 1, 5, and so on are significant, reinforcing the idea of seasonality.\n",
    "Key Takeaways for This Plot:\n",
    "Seasonality:\n",
    "\n",
    "Regular spikes suggest that the data exhibits seasonality. If this is quarterly data, the periodicity may align with yearly cycles (e.g., sales, weather, etc.).\n",
    "Non-Stationarity:\n",
    "\n",
    "The slow decay in autocorrelation suggests the presence of a trend, implying non-stationarity. You may need to apply differencing (e.g., first difference) to remove the trend and stabilize the mean.\n",
    "Next Steps:\n",
    "\n",
    "Check the Partial Autocorrelation Function (PACF) to determine the order of the AR component.\n",
    "Consider applying seasonal differencing (e.g., SARIMA) to account for the observed periodicity.\n",
    "\n",
    "## PACF\n",
    "This is a Partial Autocorrelation Function (PACF) plot. Here’s how to interpret it and correlate it with the ACF plot you provided earlier:\n",
    "\n",
    "Key Observations from the PACF Plot:\n",
    "Lag 1 Spike:\n",
    "\n",
    "The first significant spike is at lag 1, indicating a strong relationship between the current value and the value at lag 1.\n",
    "This suggests that an AR(1) (AutoRegressive model of order 1) component may be useful in modeling.\n",
    "Seasonal Pattern:\n",
    "\n",
    "There are other significant spikes at lags such as 5, 9, and possibly 13, which align with the seasonal pattern observed in the ACF.\n",
    "This reinforces the idea of seasonality with periodicity around 4 lags.\n",
    "Decay:\n",
    "\n",
    "Unlike the ACF, the PACF doesn't show gradual decay; instead, it drops to near zero after lag 1 (for non-seasonal components). This indicates that AR terms (rather than MA terms) are likely more relevant for the non-seasonal part of the model.\n",
    "Confidence Intervals (Shaded Region):\n",
    "\n",
    "Spikes within the blue region are not statistically significant. The significant spikes (outside this region) should guide the choice of AR terms and seasonal components.\n",
    "\n",
    "## Next step\n",
    "Based on this PACF plot, consider fitting an ARIMA model, starting with AR(1) for the non-seasonal part.\n",
    "Use seasonal decomposition or additional diagnostics to confirm seasonal effects before adding seasonal components to the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define the target variable\n",
    "y = df_filtered['80072ned_Ziekteverzuimpercentage_1']  # Replace with your target variable column name\n",
    "\n",
    "# Plot ACF and PACF\n",
    "plt.figure(figsize=(10, 6))\n",
    "plot_acf(y, lags=20, title='Autocorrelation Function (ACF)')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plot_pacf(y, lags=20, title='Partial Autocorrelation Function (PACF)')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
