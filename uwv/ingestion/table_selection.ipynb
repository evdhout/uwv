{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cbsodata\n",
    "import re\n",
    "import json\n",
    "import requests\n",
    "import concurrent.futures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting criteria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the desired SBI codes\n",
    "# Load the SBI data from the JSON file\n",
    "with open('data/sbi_data.json', 'r', encoding='utf-8') as sbi_file:\n",
    "    sbi_data = json.load(sbi_file)\n",
    "    \n",
    "# Define the desired SBI information\n",
    "desired_sbi_title = [\"Q Gezondheids- en welzijnszorg\", \"C Industrie\", \"O Openbaar bestuur en overheidsdiensten\", \"P Onderwijs\"]\n",
    "    \n",
    "# Define the desired frequencies\n",
    "# desired_frequencies = None  # Set to None if you don't want to filter by frequencies\n",
    "desired_frequencies = [\n",
    "    \"Fourtimesayear\", \"Viermaalperjaar\", \"Quarterly\", \"Perkwartaal\", \"Threemonthly\", \"Perdriemaanden\", # Quarterly\n",
    "    \"Monthly\",  \"Permaand\",# Monthly\n",
    "    \"Perweek\",  \"Weekly\", # Weekly\n",
    "    \"Stopgezet\", \"Discontinued\" # Other\n",
    "]\n",
    "\n",
    "# Define the desired identifiers\n",
    "desired_identifiers = None  # Set to None if you don't want to filter by identifiers\n",
    "# desired_identifiers = ['85917NED', '83156NED', '80072ned', '81628NED']\n",
    "\n",
    "# Define the undesired substrings in the short titles. Data for the Caribian island is excluded\n",
    "undesired_short_titles = ['Caribisch', 'Bonaire']\n",
    "\n",
    "# Define the desired language. Data is available in English and Dutch.\n",
    "desired_language = 'nl'\n",
    "\n",
    "# Define the period range\n",
    "start_year_threshold = 2016\n",
    "end_year_threshold = 2022\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch the list of tables\n",
    "tables = cbsodata.get_table_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract the first and last four-digit numbers from a period string\n",
    "def extract_years(period):\n",
    "    # Find all sequences of four digits\n",
    "    years = re.findall(r'\\b\\d{4}\\b', period)\n",
    "    if len(years) >= 2:\n",
    "        return int(years[0]), int(years[-1])\n",
    "    elif len(years) == 1:\n",
    "        return int(years[0]), int(years[0])\n",
    "    else:\n",
    "        return None, None\n",
    "\n",
    "# List to store the filtered data\n",
    "filtered_data = []\n",
    "\n",
    "# Filter tables and extract identifiers, short titles, languages, periods, frequencies, and SBI code\n",
    "for table in tables:\n",
    "    identifier = table.get('Identifier', 'N/A')\n",
    "    frequency = table.get('Frequency', 'N/A')\n",
    "    short_title = table.get('ShortTitle', 'N/A')\n",
    "    language = table.get('Language', 'N/A')\n",
    "    period = table.get('Period', 'N/A')\n",
    "    \n",
    "    # By default, set these filters to True if no specific filter is applied\n",
    "    passes_identifier_filter = True if desired_identifiers is None else identifier in desired_identifiers\n",
    "    passes_frequency_filter = True if desired_frequencies is None else frequency in desired_frequencies\n",
    "\n",
    "    # Check if the table contains the desired SBI information\n",
    "    sbi_info = sbi_data.get(identifier, None)\n",
    "    passes_sbi_filter = False\n",
    "    sbi_codes_and_titles = []  # This will store all SBI codes and titles\n",
    "\n",
    "    if isinstance(sbi_info, list):\n",
    "        # Extract the titles from the SBI data and compare with the desired_sbi_title list\n",
    "        sbi_titles = {sbi_entry.get('Title', '') for sbi_entry in sbi_info}\n",
    "        \n",
    "        # Check if all desired_sbi_title elements are in the sbi_titles\n",
    "        if all(title in sbi_titles for title in desired_sbi_title):\n",
    "            passes_sbi_filter = True\n",
    "            # Collect all the matching SBI codes and titles\n",
    "            for sbi_entry in sbi_info:\n",
    "                sbi_code = sbi_entry.get('Key', 'Unknown SBI Code')\n",
    "                sbi_title = sbi_entry.get('Title', 'Unknown SBI Title')\n",
    "                sbi_codes_and_titles.append(f\"{sbi_code}: {sbi_title}\")\n",
    "\n",
    "    # Apply all the filters including the SBI code filter\n",
    "    if (passes_identifier_filter and\n",
    "        passes_frequency_filter and\n",
    "        passes_sbi_filter and\n",
    "        language == desired_language and\n",
    "        not any(substring in short_title for substring in undesired_short_titles)):\n",
    "\n",
    "        start_year, end_year = extract_years(period)\n",
    "\n",
    "        if start_year is not None and end_year is not None:\n",
    "            # Check if the period range is within the desired thresholds\n",
    "            if start_year <= start_year_threshold and end_year >= end_year_threshold:\n",
    "                # Append all relevant data including all SBI codes and titles\n",
    "                filtered_data.append({\n",
    "                    'Identifier': identifier,\n",
    "                    'ShortTitle': short_title,\n",
    "                    'Language': language,\n",
    "                    'Period': period,\n",
    "                    'Frequency': frequency,\n",
    "                    'SBI_Codes_and_Titles': sbi_codes_and_titles\n",
    "                })\n",
    "\n",
    "# Save the filtered data to a JSON file\n",
    "with open('data/table_selection.json', 'w', encoding='utf-8') as json_file:\n",
    "    json.dump(filtered_data, json_file, indent=4, ensure_ascii=False)\n",
    "\n",
    "print(\"Filtered data has been saved to 'table_selection.json'.\")\n",
    "\n",
    "# Print the filtered data\n",
    "print(\"Filtered identifiers, short titles, periods, and frequencies:\")\n",
    "for entry in filtered_data:\n",
    "    print(f\"Identifier: {entry['Identifier']}, ShortTitle: {entry['ShortTitle']}, Period: {entry['Period']}, Frequency: {entry['Frequency']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appendix 1 - overview of all frequency, language, period options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize sets for unique frequencies, periods, and languages\n",
    "unique_frequencies = set()\n",
    "unique_periods = set()\n",
    "unique_languages = set()\n",
    "\n",
    "# Loop through the tables and collect unique frequencies, periods, and languages\n",
    "for table in tables:\n",
    "    frequency = table.get('Frequency', 'N/A')\n",
    "    period = table.get('Period', 'N/A')\n",
    "    language = table.get('Language', 'N/A')\n",
    "    \n",
    "    unique_frequencies.add(frequency)\n",
    "    unique_periods.add(period)\n",
    "    unique_languages.add(language)\n",
    "\n",
    "# Convert sets to lists for easier manipulation and JSON serialization\n",
    "unique_frequencies = list(unique_frequencies)\n",
    "unique_periods = list(unique_periods)\n",
    "unique_languages = list(unique_languages)\n",
    "\n",
    "# Create a dictionary to store all the unique data\n",
    "unique_data = {\n",
    "    \"frequencies\": unique_frequencies,\n",
    "    \"periods\": unique_periods,\n",
    "    \"languages\": unique_languages\n",
    "}\n",
    "\n",
    "# Save the unique data as a JSON file in the 'data' folder\n",
    "with open('data/unique_data.json', 'w') as json_file:\n",
    "    json.dump(unique_data, json_file, indent=4)\n",
    "\n",
    "print(\"Unique frequencies, periods, and languages have been saved to 'data/unique_data.json'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appendix 2 - extracting SBI data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the identifiers from the filtered_data list\n",
    "identifiers = [entry[0] for entry in filtered_data]  # entry[0] corresponds to the identifier in the tuple\n",
    "\n",
    "# Function to fetch SBI code information for a single identifier\n",
    "def fetch_sbi_code(identifier):\n",
    "    url = f\"https://opendata.cbs.nl/ODataApi/OData/{identifier}/BedrijfstakkenBranchesSBI2008\"\n",
    "    \n",
    "    try:\n",
    "        # Send a GET request to the constructed URL\n",
    "        response = requests.get(url)\n",
    "        \n",
    "        # Check if the request was successful (HTTP status code 200)\n",
    "        if response.status_code == 200:\n",
    "            # Convert the response to JSON format\n",
    "            data = response.json()\n",
    "\n",
    "            # Check if the 'value' key contains SBI data\n",
    "            if 'value' in data and data['value']:\n",
    "                return (identifier, data['value'])  # Return identifier with SBI data\n",
    "            else:\n",
    "                return (identifier, 'No SBI information available')  # No data available\n",
    "        else:\n",
    "            return (identifier, f\"Request failed with status code {response.status_code}\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        return (identifier, f\"Error occurred: {str(e)}\")\n",
    "\n",
    "# Function to extract SBI code information using concurrent requests\n",
    "def extract_sbi_codes_concurrent(identifiers):\n",
    "    sbi_data_dict = {}\n",
    "    \n",
    "    # Use ThreadPoolExecutor to send requests concurrently\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=10) as executor:\n",
    "        # Submit all the fetch_sbi_code tasks\n",
    "        future_to_identifier = {executor.submit(fetch_sbi_code, identifier): identifier for identifier in identifiers}\n",
    "        \n",
    "        # As each request finishes, process the result\n",
    "        for future in concurrent.futures.as_completed(future_to_identifier):\n",
    "            identifier, result = future.result()  # Get the result from the future\n",
    "            sbi_data_dict[identifier] = result  # Store in the dictionary\n",
    "\n",
    "    return sbi_data_dict\n",
    "\n",
    "# Call the concurrent version of the SBI code extraction function\n",
    "sbi_data = extract_sbi_codes_concurrent(identifiers)\n",
    "\n",
    "# Save the dictionary to a file\n",
    "with open('data/sbi_data.json', 'w') as f:\n",
    "    json.dump(sbi_data, f, indent=4)\n",
    "    \n",
    "print(\"SBI data has been saved to 'data/sbi_data.json'.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
