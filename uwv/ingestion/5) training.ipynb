{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Preprocessing and Scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Linear Models\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import ElasticNet\n",
    "\n",
    "# Tree-Based and Ensemble Models\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "\n",
    "# Support Vector Machines\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "# Nearest Neighbors\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "# Neural Networks\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "# Metrics and Validation\n",
    "from sklearn.metrics import mean_absolute_error, root_mean_squared_error, mean_absolute_percentage_error\n",
    "\n",
    "# Pretty Table for Logging Results\n",
    "from prettytable import PrettyTable\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model selection based on complete dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load csv into a dataframe\n",
    "df = pd.read_csv(\"data/merged_table.csv\")\n",
    "\n",
    "# Set the Year_Quarter column as the index for easy operations\n",
    "df.set_index('Year_Quarter', inplace=True)\n",
    "\n",
    "# Filter the index to include only values between 2008 and 2021 (inclusive)\n",
    "df_filtered = df[(df.index >= '2008') & (df.index <= '2022')]\n",
    "\n",
    "df_filtered.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_timeseries = df_filtered[['BedrijfstakkenBranchesSBI2008'] + [\"covid_19\"] + [col for col in df_filtered.columns if '80072ned_Ziekteverzuimpercentage_1' in col]]\n",
    "df_timeseries.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring models (only time series and COVID-19 data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to perform training/validation and save results\n",
    "def train_and_validate(df, target_column, model, model_name, save_csv=False, compute_feature_importance=False):\n",
    "    \"\"\"\n",
    "    Perform time-series cross-validation using the specified model and optionally compute feature importance.\n",
    "    \n",
    "    Parameters:\n",
    "        df (DataFrame): Time-series data for all industries.\n",
    "        target_column (str): Target column for prediction.\n",
    "        model: A scikit-learn-compatible model instance (e.g., LinearRegression, RandomForest).\n",
    "        model_name (str): Name of the model to use in file naming.\n",
    "        save_csv (bool): Whether to save the results to a CSV file (default is False).\n",
    "        compute_feature_importance (bool): Whether to compute feature importance for linear models (default is False).\n",
    "    \"\"\"\n",
    "    industries = df['BedrijfstakkenBranchesSBI2008'].unique()\n",
    "\n",
    "    # Placeholder for storing results\n",
    "    cv_results = []\n",
    "\n",
    "    # Perform the analysis for each industry\n",
    "    for industry in industries:\n",
    "        result, X, fitted_model = perform_time_series_cv(df, target_column, industry, model)\n",
    "        cv_results.append(result)\n",
    "\n",
    "        # Compute feature importance if requested\n",
    "        if compute_feature_importance and isinstance(fitted_model, LinearRegression):\n",
    "            feature_importance = compute_feature_importance_linear(X, fitted_model)\n",
    "            print(f\"Feature importance for {industry}:\\n{feature_importance}\\n\")\n",
    "\n",
    "    # Prepare the results for saving to CSV\n",
    "    if save_csv:\n",
    "        output_rows = []\n",
    "        for result in cv_results:\n",
    "            for res in result[\"results\"]:\n",
    "                output_rows.append({\n",
    "                    \"Industry\": result[\"industry\"],\n",
    "                    \"Train Start\": res[\"train_range\"][0],\n",
    "                    \"Train End\": res[\"train_range\"][1],\n",
    "                    \"Validation Start\": res[\"validation_range\"][0],\n",
    "                    \"Validation End\": res[\"validation_range\"][1],\n",
    "                    \"MAE\": res[\"mae\"],\n",
    "                    \"Actual Values\": res[\"actual_values\"],\n",
    "                    \"Predicted Values\": res[\"predicted_values\"]\n",
    "                })\n",
    "\n",
    "        # Convert to DataFrame for saving\n",
    "        output_df = pd.DataFrame(output_rows)\n",
    "\n",
    "        # Save to CSV\n",
    "        output_folder = \"data\"\n",
    "        os.makedirs(output_folder, exist_ok=True)\n",
    "        output_path = os.path.join(output_folder, f\"{model_name}_training_results.csv\")\n",
    "        output_df.to_csv(output_path, index=False)\n",
    "\n",
    "    # Log the results in table format\n",
    "    log_results(cv_results, model_name)\n",
    "\n",
    "def perform_time_series_cv(df, target_column, industry, model):\n",
    "    \"\"\"\n",
    "    Perform time-series cross-validation using the specified model.\n",
    "    \n",
    "    Parameters:\n",
    "        df (DataFrame): Time-series data for all industries.\n",
    "        target_column (str): Target column for prediction.\n",
    "        industry (str): Specific industry to filter data for.\n",
    "        model: A scikit-learn-compatible model instance.\n",
    "    \n",
    "    Returns:\n",
    "        dict: Results including average MAE, predictions, and actual values per fold.\n",
    "        DataFrame: Features (X) used for training.\n",
    "        object: The fitted model.\n",
    "    \"\"\"\n",
    "    # Filter for the specific industry\n",
    "    industry_data = df[df['BedrijfstakkenBranchesSBI2008'] == industry].copy()\n",
    "\n",
    "    # Ensure the index is in Period format\n",
    "    industry_data.index = pd.PeriodIndex(industry_data.index, freq='Q')\n",
    "\n",
    "    # Define X (features) and y (target)\n",
    "    X = industry_data.drop(columns=[target_column, 'BedrijfstakkenBranchesSBI2008'])\n",
    "    y = industry_data[target_column]\n",
    "\n",
    "    # Generate train-validation splits\n",
    "    def generate_splits():\n",
    "        train_start = pd.Period(\"2008Q1\", freq=\"Q\")\n",
    "        train_end = pd.Period(\"2010Q4\", freq=\"Q\")\n",
    "        validation_start = pd.Period(\"2011Q1\", freq=\"Q\")\n",
    "        validation_end = pd.Period(\"2021Q4\", freq=\"Q\")  # Ensure four-quarter validation remains in range\n",
    "\n",
    "        splits = []\n",
    "\n",
    "        while validation_start + 3 <= validation_end:\n",
    "            splits.append({\n",
    "                \"train_start\": train_start,\n",
    "                \"train_end\": train_end,\n",
    "                \"validation_start\": validation_start,\n",
    "                \"validation_end\": validation_start + 3  # Four quarters ahead\n",
    "            })\n",
    "\n",
    "            train_end += 1\n",
    "            validation_start += 1\n",
    "\n",
    "        return splits\n",
    "\n",
    "    splits = generate_splits()\n",
    "\n",
    "    # Perform cross-validation\n",
    "    results = []\n",
    "    quarterly_mae = {f\"Q{i}\": [] for i in range(1, 5)}  # Track MAEs by quarter for this industry\n",
    "\n",
    "    for split in splits:\n",
    "        # Identify train and validation indices\n",
    "        train_index = (industry_data.index >= split[\"train_start\"]) & (industry_data.index <= split[\"train_end\"])\n",
    "        validation_index = (industry_data.index >= split[\"validation_start\"]) & (industry_data.index <= split[\"validation_end\"])\n",
    "\n",
    "        # Ensure there is data in both sets\n",
    "        if train_index.sum() == 0 or validation_index.sum() == 0:\n",
    "            print(f\"Skipping split: Train ({split['train_start']} to {split['train_end']}), Validation ({split['validation_start']} to {split['validation_end']})\")\n",
    "            continue\n",
    "\n",
    "        # Extract train and validation sets\n",
    "        X_train, X_validation = X[train_index], X[validation_index]\n",
    "        y_train, y_validation = y[train_index], y[validation_index]\n",
    "\n",
    "        # Fit the model\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        # Predict on validation set\n",
    "        y_pred = model.predict(X_validation)\n",
    "\n",
    "        # Store actual and predicted values\n",
    "        actual_values = [float(round(val, 2)) for val in y_validation.values.tolist()]\n",
    "        predicted_values = [float(round(pred, 2)) for pred in y_pred]  # Explicitly cast to float\n",
    "\n",
    "        # Calculate MAE for each quarter in the validation period\n",
    "        validation_periods = industry_data.index[validation_index]\n",
    "        quarter_mae = {\n",
    "            str(period): float(round(mean_absolute_error([y_validation.loc[period]], [y_pred[i]]), 2))\n",
    "            for i, period in enumerate(validation_periods)\n",
    "        }\n",
    "\n",
    "        # Append MAE to quarterly tracking\n",
    "        for period, mae in quarter_mae.items():\n",
    "            quarter = int(period[-1])  # Extract quarter from \"YYYYQx\"\n",
    "            quarterly_mae[f\"Q{quarter}\"].append(mae)\n",
    "\n",
    "        results.append({\n",
    "            \"train_range\": (split[\"train_start\"], split[\"train_end\"]),\n",
    "            \"validation_range\": (split[\"validation_start\"], split[\"validation_end\"]),\n",
    "            \"mae\": quarter_mae,\n",
    "            \"actual_values\": actual_values,\n",
    "            \"predicted_values\": predicted_values\n",
    "        })\n",
    "\n",
    "    # Calculate average MAE for this industry by quarter\n",
    "    avg_mae_by_quarter = {q: float(round(np.mean(maes), 2)) if maes else None for q, maes in quarterly_mae.items()}\n",
    "    return {\"industry\": industry, \"avg_mae\": avg_mae_by_quarter, \"results\": results}, X, model\n",
    "\n",
    "def log_results(cv_results, model_name):\n",
    "    \"\"\"\n",
    "    Logs and formats the results of cross-validation.\n",
    "    \n",
    "    Parameters:\n",
    "        cv_results (list): Results of the cross-validation for each industry.\n",
    "        model_name (str): Name of the model used.\n",
    "    \"\"\"\n",
    "    # Initialize accumulators for overall metrics\n",
    "    total_mae = 0\n",
    "    total_rmse = 0\n",
    "    total_mape = 0\n",
    "    count = 0\n",
    "\n",
    "    # Create a table for formatted results\n",
    "    table = PrettyTable()\n",
    "    table.field_names = [\"Industry\", \"Q1 MAE\", \"Q2 MAE\", \"Q3 MAE\", \"Q4 MAE\", \"Avg MAE\", \"Avg RMSE\", \"Avg MAPE\"]\n",
    "\n",
    "    # Add each industry's results to the table\n",
    "    for result in cv_results:\n",
    "        industry = result[\"industry\"]\n",
    "        avg_mae_by_quarter = result[\"avg_mae\"]\n",
    "        all_actuals = []\n",
    "        all_predictions = []\n",
    "\n",
    "        # Collect all actual and predicted values across all folds for this industry\n",
    "        for res in result[\"results\"]:\n",
    "            all_actuals.extend(res[\"actual_values\"])\n",
    "            all_predictions.extend(res[\"predicted_values\"])\n",
    "\n",
    "        # Calculate overall metrics for this industry\n",
    "        industry_mae = mean_absolute_error(all_actuals, all_predictions)\n",
    "        industry_rmse = root_mean_squared_error(all_actuals, all_predictions)\n",
    "        industry_mape = mean_absolute_percentage_error(all_actuals, all_predictions)\n",
    "\n",
    "        # Update accumulators\n",
    "        total_mae += industry_mae\n",
    "        total_rmse += industry_rmse\n",
    "        total_mape += industry_mape\n",
    "        count += 1\n",
    "\n",
    "        # Add row to table\n",
    "        table.add_row([\n",
    "            industry,\n",
    "            avg_mae_by_quarter.get(\"Q1\", \"N/A\"),\n",
    "            avg_mae_by_quarter.get(\"Q2\", \"N/A\"),\n",
    "            avg_mae_by_quarter.get(\"Q3\", \"N/A\"),\n",
    "            avg_mae_by_quarter.get(\"Q4\", \"N/A\"),\n",
    "            round(industry_mae, 3),\n",
    "            round(industry_rmse, 3),\n",
    "            round(industry_mape, 3)\n",
    "        ])\n",
    "\n",
    "    # Calculate overall averages\n",
    "    overall_avg_mae = total_mae / count if count else float('nan')\n",
    "    overall_avg_rmse = total_rmse / count if count else float('nan')\n",
    "    overall_avg_mape = total_mape / count if count else float('nan')\n",
    "\n",
    "    # Print the overall average metrics\n",
    "    print(f\"Model: {model_name}\")\n",
    "    print(f\"Overall Average MAE: {overall_avg_mae:.3f}\")\n",
    "    print(f\"Overall Average RMSE: {overall_avg_rmse:.3f}\")\n",
    "    print(f\"Overall Average MAPE: {overall_avg_mape:.3f}\")\n",
    "    print()\n",
    "\n",
    "    # Print the formatted table\n",
    "    print(\"Cross-Validation Results:\")\n",
    "    print(table)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_and_validate(df_timeseries, target_column='80072ned_Ziekteverzuimpercentage_1', model=LinearRegression(), model_name=\"LinearRegression\", save_csv=True, compute_feature_importance=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_and_validate(df_timeseries, target_column='80072ned_Ziekteverzuimpercentage_1', model=Ridge(), model_name=\"Ridge\", save_csv=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_and_validate(df_timeseries, target_column='80072ned_Ziekteverzuimpercentage_1', model=Lasso(), model_name=\"Lasso\", save_csv=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_and_validate(df_timeseries, target_column='80072ned_Ziekteverzuimpercentage_1', model=ElasticNet(), model_name=\"ElasticNet\", save_csv=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tree-Based and Ensemble Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_and_validate(df_timeseries, target_column='80072ned_Ziekteverzuimpercentage_1', model=DecisionTreeRegressor(), model_name=\"DecisionTreeRegressor\", save_csv=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_and_validate(df_timeseries, target_column='80072ned_Ziekteverzuimpercentage_1', model=GradientBoostingRegressor(), model_name=\"GradientBoostingRegressor\", save_csv=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_and_validate(df_timeseries, target_column='80072ned_Ziekteverzuimpercentage_1', model=RandomForestRegressor(), model_name=\"RandomForestRegressor\", save_csv=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_and_validate(df_timeseries, target_column='80072ned_Ziekteverzuimpercentage_1', model=AdaBoostRegressor(), model_name=\"AdaBoostRegressor\", save_csv=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_and_validate(df_timeseries, target_column='80072ned_Ziekteverzuimpercentage_1', model=HistGradientBoostingRegressor(), model_name=\"HistGradientBoostingRegressor\", save_csv=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_and_validate(df_timeseries, target_column='80072ned_Ziekteverzuimpercentage_1', model=SVR(), model_name=\"SVR\", save_csv=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_and_validate(df_timeseries, target_column='80072ned_Ziekteverzuimpercentage_1', model=KNeighborsRegressor(), model_name=\"KNeighborsRegressor\", save_csv=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_and_validate(df_timeseries, target_column='80072ned_Ziekteverzuimpercentage_1', model=MLPRegressor(), model_name=\"MLPRegressor\", save_csv=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring models with external data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_and_validate(df_filtered, target_column='80072ned_Ziekteverzuimpercentage_1', model=LinearRegression(), model_name=\"LinearRegression\", save_csv=True, compute_feature_importance=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_and_validate(df_filtered, target_column='80072ned_Ziekteverzuimpercentage_1', model=Ridge(), model_name=\"Ridge\", save_csv=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_and_validate(df_filtered, target_column='80072ned_Ziekteverzuimpercentage_1', model=Lasso(), model_name=\"Lasso\", save_csv=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_and_validate(df_filtered, target_column='80072ned_Ziekteverzuimpercentage_1', model=ElasticNet(), model_name=\"ElasticNet\", save_csv=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tree-Basead and Ensemble Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_and_validate(df_filtered, target_column='80072ned_Ziekteverzuimpercentage_1', model=DecisionTreeRegressor(), model_name=\"DecisionTreeRegressor\", save_csv=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_and_validate(df_filtered, target_column='80072ned_Ziekteverzuimpercentage_1', model=GradientBoostingRegressor(), model_name=\"GradientBoostingRegressor\", save_csv=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_and_validate(df_filtered, target_column='80072ned_Ziekteverzuimpercentage_1', model=RandomForestRegressor(), model_name=\"RandomForestRegressor\", save_csv=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_and_validate(df_filtered, target_column='80072ned_Ziekteverzuimpercentage_1', model=AdaBoostRegressor(), model_name=\"AdaBoostRegressor\", save_csv=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_and_validate(df_filtered, target_column='80072ned_Ziekteverzuimpercentage_1', model=HistGradientBoostingRegressor(), model_name=\"HistGradientBoostingRegressor\", save_csv=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_and_validate(df_filtered, target_column='80072ned_Ziekteverzuimpercentage_1', model=SVR(), model_name=\"SVR\", save_csv=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_and_validate(df_filtered, target_column='80072ned_Ziekteverzuimpercentage_1', model=KNeighborsRegressor(), model_name=\"KNeighborsRegressor\", save_csv=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_and_validate(df_filtered, target_column='80072ned_Ziekteverzuimpercentage_1', model=MLPRegressor(), model_name=\"MLPRegressor\", save_csv=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model development"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Other stuff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Met crossfall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.impute import SimpleImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to perform cross-validation and hyperparameter tuning\n",
    "def perform_tuning(df, target_column, lead, industry):\n",
    "    # Filter data for the specific industry\n",
    "    df = df[df['BedrijfstakkenBranchesSBI2008'] == industry].copy()\n",
    "\n",
    "    # Convert year_quarter to a proper format\n",
    "    df.loc[:, 'Year_Quarter'] = pd.PeriodIndex(df['Year_Quarter'], freq='Q')\n",
    "\n",
    "    year_quarter = df['Year_Quarter']\n",
    "\n",
    "    # Ensure alignment of indices\n",
    "    X = df.drop(columns=[target_column, 'Year_Quarter', 'BedrijfstakkenBranchesSBI2008']).reset_index(drop=True)\n",
    "    y = df[target_column].reset_index(drop=True)\n",
    "    year_quarter = year_quarter.reset_index(drop=True)\n",
    "\n",
    "    # Generate train/validation splits\n",
    "    def generate_splits():\n",
    "        train_start = pd.Period(\"2008Q1\", freq=\"Q\")\n",
    "        train_end = pd.Period(\"2010Q4\", freq=\"Q\")\n",
    "        validation_start = pd.Period(\"2011Q1\", freq=\"Q\")\n",
    "        validation_end = pd.Period(\"2021Q4\", freq=\"Q\")\n",
    "\n",
    "        splits = []\n",
    "\n",
    "        while validation_start <= validation_end:\n",
    "            splits.append({\n",
    "                \"train_start\": \"2008Q1\",  # Always start training from 2008Q1\n",
    "                \"train_end\": str(train_end),\n",
    "                \"validation\": str(validation_start)\n",
    "            })\n",
    "\n",
    "            train_end += 1\n",
    "            validation_start += 1\n",
    "\n",
    "        return splits\n",
    "\n",
    "    splits = generate_splits()\n",
    "\n",
    "    # Hyperparameter grid\n",
    "    alphas = [0.1, 1.0, 10.0, 100.0, 10000.0, 100000.0, 1000000.0, 10000000.0, 100000000.0]\n",
    "    tuning_results = []\n",
    "\n",
    "    print(f\"Time Series Cross-Validation with Hyperparameter Tuning for Q+{lead} ({industry}):\")\n",
    "\n",
    "    # Perform cross-validation with hyperparameter tuning\n",
    "    for alpha in alphas:\n",
    "        fold_results = []\n",
    "        print(f\"Testing alpha: {alpha}\\n\")\n",
    "\n",
    "        for fold, split in enumerate(splits, 1):\n",
    "            # Convert string dates to Period\n",
    "            train_start = pd.Period(split[\"train_start\"], freq='Q')\n",
    "            train_end = pd.Period(split[\"train_end\"], freq='Q')\n",
    "            validation_date = pd.Period(split[\"validation\"], freq='Q')\n",
    "\n",
    "            # Get train and validation indices\n",
    "            train_index = year_quarter[(year_quarter >= train_start) & (year_quarter <= train_end)].index\n",
    "            validation_index = year_quarter[year_quarter == validation_date].index\n",
    "\n",
    "            # Extract train and validation sets\n",
    "            X_train, X_validation = X.iloc[train_index], X.iloc[validation_index]\n",
    "            y_train, y_validation = y.iloc[train_index], y.iloc[validation_index]\n",
    "            train_dates, validation_dates = year_quarter.iloc[train_index], year_quarter.iloc[validation_index]\n",
    "\n",
    "            # Train the model with the current alpha\n",
    "            model = Ridge(alpha=alpha)\n",
    "            model.fit(X_train, y_train)\n",
    "\n",
    "            # Predict and evaluate\n",
    "            y_pred = model.predict(X_validation)\n",
    "            mae = mean_absolute_error(y_validation, y_pred)\n",
    "\n",
    "            # Save results for this fold\n",
    "            fold_results.append(mae)\n",
    "\n",
    "            print(f\"Fold {fold}:\")\n",
    "            print(f\"Train Date Range: {train_dates.min()} to {train_dates.max()}\")\n",
    "            print(f\"Validation Date: {validation_dates.iloc[0]}\")\n",
    "            print(f\"MAE: {mae:.4f}\")\n",
    "\n",
    "        # Calculate average MAE for this alpha\n",
    "        avg_mae = np.mean(fold_results) if fold_results else float('inf')\n",
    "        tuning_results.append({\"alpha\": alpha, \"average_mae\": avg_mae})\n",
    "        print(f\"\\nAverage MAE for alpha {alpha}: {avg_mae:.4f}\\n\")\n",
    "\n",
    "    # Find the best alpha\n",
    "    best_result = min(tuning_results, key=lambda x: x[\"average_mae\"])\n",
    "\n",
    "    # Summary of all hyperparameters\n",
    "    print(f\"\\nHyperparameter Tuning Summary for Q+{lead} ({industry}):\")\n",
    "    for result in tuning_results:\n",
    "        print(f\"Alpha: {result['alpha']}, Average MAE: {result['average_mae']:.4f}\")\n",
    "\n",
    "    print(f\"\\nBest alpha for Q+{lead} ({industry}): {best_result['alpha']} with Average MAE: {best_result['average_mae']:.4f}\\n\")\n",
    "\n",
    "    return tuning_results, best_result\n",
    "\n",
    "# Initialize variables for industries and data files\n",
    "industries = ['C Industrie', 'G Handel', 'Q Gezondheids- en welzijnszorg']\n",
    "\n",
    "# Data files for Q+1 to Q+4\n",
    "data_files = [\n",
    "    ('data/80072ned_Ziekteverzuimpercentage_1_lead_1.csv', '80072ned_Ziekteverzuimpercentage_1_lead_1', 1),\n",
    "    ('data/80072ned_Ziekteverzuimpercentage_1_lead_2.csv', '80072ned_Ziekteverzuimpercentage_1_lead_2', 2),\n",
    "    ('data/80072ned_Ziekteverzuimpercentage_1_lead_3.csv', '80072ned_Ziekteverzuimpercentage_1_lead_3', 3),\n",
    "    ('data/80072ned_Ziekteverzuimpercentage_1_lead_4.csv', '80072ned_Ziekteverzuimpercentage_1_lead_4', 4)\n",
    "]\n",
    "\n",
    "# Placeholder for all summaries\n",
    "all_summaries = []\n",
    "\n",
    "# Perform tuning for each lead and each industry\n",
    "for file_path, target_column, lead in data_files:\n",
    "    print(f\"Running tuning for Q+{lead}\")\n",
    "    df_lead = pd.read_csv(file_path)\n",
    "    for industry in industries:\n",
    "        print(f\"\\nIndustry: {industry}\")\n",
    "        tuning_results, best_result = perform_tuning(df_lead, target_column, lead, industry)\n",
    "        all_summaries.append({\n",
    "            \"lead\": lead,\n",
    "            \"industry\": industry,\n",
    "            \"tuning_results\": tuning_results,\n",
    "            \"best_result\": best_result\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to apply the best model to the test set\n",
    "def apply_best_model(df, target_column, best_alpha, industry, lead):\n",
    "    # Filter data for the specific industry and create a copy\n",
    "    df = df[df['BedrijfstakkenBranchesSBI2008'] == industry].copy()\n",
    "\n",
    "    # Convert 'Year_Quarter' to PeriodIndex\n",
    "    df['Year_Quarter'] = pd.PeriodIndex(df['Year_Quarter'], freq='Q')\n",
    "\n",
    "    # Define the test period\n",
    "    test_start = pd.Period(\"2022Q1\", freq=\"Q\")\n",
    "    test_end = pd.Period(\"2023Q4\", freq=\"Q\")\n",
    "\n",
    "    results = []\n",
    "\n",
    "    # Apply models for each quarter in the test period\n",
    "    while test_start <= test_end:\n",
    "        # The Prediction Period is the current `test_start`\n",
    "        prediction_period = test_start\n",
    "\n",
    "        # Train data up to the current `test_start - lead`\n",
    "        train_end = prediction_period - lead\n",
    "        if train_end < pd.Period(\"2008Q1\", freq=\"Q\"):\n",
    "            print(f\"Skipping {prediction_period} as training period {train_end} is out of range.\")\n",
    "            test_start += 1\n",
    "            continue\n",
    "\n",
    "        train_data = df[df['Year_Quarter'] <= train_end]\n",
    "\n",
    "        # Test data corresponds to the `prediction_period`\n",
    "        test_data = df[df['Year_Quarter'] == prediction_period]\n",
    "\n",
    "        if test_data.empty:\n",
    "            print(f\"No test data available for {prediction_period}. Skipping.\")\n",
    "            test_start += 1\n",
    "            continue\n",
    "\n",
    "        # Ensure alignment of indices\n",
    "        X_train = train_data.drop(columns=[target_column, 'Year_Quarter', 'BedrijfstakkenBranchesSBI2008'])\n",
    "        y_train = train_data[target_column]\n",
    "        X_test = test_data.drop(columns=[target_column, 'Year_Quarter', 'BedrijfstakkenBranchesSBI2008'])\n",
    "        y_test = test_data[target_column]  # Actual values for `prediction_period`\n",
    "\n",
    "        # Handle missing values\n",
    "        imputer = SimpleImputer(strategy='mean')\n",
    "        X_train = pd.DataFrame(imputer.fit_transform(X_train), columns=X_train.columns)\n",
    "        y_train = y_train.fillna(y_train.mean())  # Fill missing target values in training set\n",
    "        X_test = pd.DataFrame(imputer.transform(X_test), columns=X_test.columns)\n",
    "\n",
    "        # Train the model with the best alpha\n",
    "        model = Ridge(alpha=best_alpha)\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        # Predict on the test set\n",
    "        y_pred = model.predict(X_test)\n",
    "\n",
    "        # Evaluate the model\n",
    "        mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "        # Append results for this period\n",
    "        results.append({\n",
    "            \"Industry\": industry,\n",
    "            \"Model\": f\"Q+{lead}\",\n",
    "            \"Input Period\": f\"2008Q1 to {train_end}\",\n",
    "            \"Prediction Period\": str(prediction_period),\n",
    "            \"Predicted Value\": y_pred.tolist(),\n",
    "            \"Actual Value\": y_test.tolist(),  # Actual values match the prediction period\n",
    "            \"MAE\": mae\n",
    "        })\n",
    "\n",
    "        # Move to the next test period\n",
    "        test_start += 1\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "# Updated script to include Q+1 and ensure testing works as expected\n",
    "summaries = []\n",
    "industries = ['C Industrie', 'G Handel', 'Q Gezondheids- en welzijnszorg']\n",
    "\n",
    "# Perform tuning for Q+1 for each industry\n",
    "df_lead_1 = pd.read_csv('data/80072ned_Ziekteverzuimpercentage_1_lead_1.csv')\n",
    "for industry in industries:\n",
    "    summary_q1, best_result_q1 = perform_tuning(df_lead_1, '80072ned_Ziekteverzuimpercentage_1_lead_1', lead=1, industry=industry)\n",
    "    summaries.append({\"lead\": 1, \"industry\": industry, \"summary\": summary_q1, \"best_result\": best_result_q1})\n",
    "\n",
    "# Perform tuning for Q+2, Q+3, and Q+4 for each industry\n",
    "data_files = [\n",
    "    ('data/80072ned_Ziekteverzuimpercentage_1_lead_2.csv', '80072ned_Ziekteverzuimpercentage_1_lead_2', 2),\n",
    "    ('data/80072ned_Ziekteverzuimpercentage_1_lead_3.csv', '80072ned_Ziekteverzuimpercentage_1_lead_3', 3),\n",
    "    ('data/80072ned_Ziekteverzuimpercentage_1_lead_4.csv', '80072ned_Ziekteverzuimpercentage_1_lead_4', 4)\n",
    "]\n",
    "\n",
    "for file_path, target_column, lead in data_files:\n",
    "    df_lead = pd.read_csv(file_path)\n",
    "    for industry in industries:\n",
    "        summary, best_result = perform_tuning(df_lead, target_column, lead=lead, industry=industry)\n",
    "        summaries.append({\"lead\": lead, \"industry\": industry, \"summary\": summary, \"best_result\": best_result})\n",
    "\n",
    "# Apply best models to the test set\n",
    "final_results = []\n",
    "\n",
    "# Include Q+1 predictions explicitly\n",
    "data_files.insert(0, ('data/80072ned_Ziekteverzuimpercentage_1_lead_1.csv', '80072ned_Ziekteverzuimpercentage_1_lead_1', 1))\n",
    "\n",
    "for file_path, target_column, lead in data_files:\n",
    "    df_lead = pd.read_csv(file_path)\n",
    "    for summary in summaries:\n",
    "        if summary['lead'] == lead:\n",
    "            industry = summary['industry']\n",
    "            best_alpha = summary['best_result']['alpha']\n",
    "            results = apply_best_model(df_lead, target_column, best_alpha, industry, lead)\n",
    "            final_results.extend(results)\n",
    "\n",
    "# Store final results in a DataFrame for analysis\n",
    "results_df = pd.DataFrame(final_results)\n",
    "\n",
    "# Save results to CSV\n",
    "results_df.to_csv('test_results.csv', index=False)\n",
    "\n",
    "# Calculate and display average MAE per industry and model\n",
    "average_mae_summary = results_df.groupby(['Industry', 'Model'])['MAE'].mean().reset_index()\n",
    "print(\"\\nAverage MAE per Industry and Model:\")\n",
    "print(average_mae_summary)\n",
    "\n",
    "print(\"\\nTest results saved to 'test_results.csv'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Initialize the start and end points for training and validation\n",
    "train_start = pd.Period(\"2008Q1\", freq=\"Q\")\n",
    "train_end = pd.Period(\"2010Q4\", freq=\"Q\")\n",
    "validation_start = pd.Period(\"2011Q1\", freq=\"Q\")\n",
    "validation_end = pd.Period(\"2022Q4\", freq=\"Q\")\n",
    "\n",
    "# List to store the splits\n",
    "splits = []\n",
    "\n",
    "# Loop until validation exceeds the desired end date\n",
    "while validation_start <= validation_end:\n",
    "    splits.append({\n",
    "        \"train_start\": str(train_start),\n",
    "        \"train_end\": str(train_end),\n",
    "        \"validation\": str(validation_start)\n",
    "    })\n",
    "\n",
    "    # Move the train_end and validation forward by one quarter\n",
    "    train_end += 1\n",
    "    validation_start += 1\n",
    "\n",
    "# Print the splits\n",
    "for split in splits:\n",
    "    print(split)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Fold {fold}: train_index = {train_index}, test_index = {test_index}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hieronder een test zonder Crossval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = df[df['Year_Quarter'] < '2021-Q4']\n",
    "test_df = df[df['Year_Quarter'] == '2021-Q4']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the model\n",
    "model = Ridge()  # Or use another model like RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the test data\n",
    "X_test = test_df.drop(columns=['80072ned_Ziekteverzuimpercentage_1_lead_1', 'Year_Quarter'])\n",
    "y_test = test_df['80072ned_Ziekteverzuimpercentage_1_lead_1']\n",
    "\n",
    "# Train the model on the training data\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate RMSE\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "print(f\"RMSE: {rmse}\")\n",
    "\n",
    "# Combine actual vs predicted into a DataFrame for comparison\n",
    "comparison_df = test_df[['Year_Quarter']].copy()\n",
    "comparison_df['Actual'] = y_test.values\n",
    "comparison_df['Predicted'] = y_pred\n",
    "\n",
    "# Print the comparison DataFrame\n",
    "print(\"Actual vs Predicted:\")\n",
    "print(comparison_df)\n",
    "\n",
    "# Optional: Save the comparison to a CSV for review\n",
    "comparison_df.to_csv('actual_vs_predicted.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lead_2 = df_lead_2.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_lead_2 = df_lead_2[df_lead_2['Year_Quarter'] < '2021-Q4']\n",
    "test_df_lead_2 = df_lead_2[df_lead_2['Year_Quarter'] == '2021-Q4']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_lead_2.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df_lead_2.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_df_lead_2 = train_df_lead_2.drop(columns=['80072ned_Ziekteverzuimpercentage_1_lead_2', 'Year_Quarter'])\n",
    "y_train_df_lead_2 = train_df_lead_2['80072ned_Ziekteverzuimpercentage_1_lead_2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the model\n",
    "model = Ridge()  # Or use another model like RandomForestRegressor\n",
    "\n",
    "# Train the model on the training data\n",
    "model.fit(X_train_df_lead_2, y_train_df_lead_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the test data\n",
    "X_test_df_lead_2 = test_df_lead_2.drop(columns=['80072ned_Ziekteverzuimpercentage_1_lead_2', 'Year_Quarter'])\n",
    "y_test_df_lead_2 = test_df_lead_2['80072ned_Ziekteverzuimpercentage_1_lead_2']\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_df_lead_2 = model.predict(X_test_df_lead_2)\n",
    "\n",
    "# Calculate RMSE\n",
    "rmse = np.sqrt(mean_squared_error(y_test_df_lead_2, y_pred_df_lead_2))\n",
    "print(f\"RMSE: {rmse}\")\n",
    "\n",
    "# Combine actual vs predicted into a DataFrame for comparison\n",
    "comparison_df_lead_2 = test_df[['Year_Quarter']].copy()\n",
    "comparison_df_lead_2['Actual'] = y_test_df_lead_2.values\n",
    "comparison_df_lead_2['Predicted'] = y_pred_df_lead_2\n",
    "\n",
    "# Print the comparison DataFrame\n",
    "print(\"Actual vs Predicted:\")\n",
    "print(comparison_df_lead_2)\n",
    "\n",
    "# Optional: Save the comparison to a CSV for review\n",
    "comparison_df_lead_2.to_csv('actual_vs_predicted_lead_2.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lead_3 = df_lead_3.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_lead_3 = df_lead_3[df_lead_3['Year_Quarter'] < '2021-Q4']\n",
    "test_df_lead_3 = df_lead_3[df_lead_3['Year_Quarter'] == '2021-Q4']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_lead_3.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df_lead_3.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_df_lead_3 = train_df_lead_3.drop(columns=['80072ned_Ziekteverzuimpercentage_1_lead_3', 'Year_Quarter'])\n",
    "y_train_df_lead_3 = train_df_lead_3['80072ned_Ziekteverzuimpercentage_1_lead_3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the model\n",
    "model = Ridge()  # Or use another model like RandomForestRegressor\n",
    "\n",
    "# Train the model on the training data\n",
    "model.fit(X_train_df_lead_3, y_train_df_lead_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the test data\n",
    "X_test_df_lead_3 = test_df_lead_3.drop(columns=['80072ned_Ziekteverzuimpercentage_1_lead_3', 'Year_Quarter'])\n",
    "y_test_df_lead_3 = test_df_lead_3['80072ned_Ziekteverzuimpercentage_1_lead_3']\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_df_lead_3 = model.predict(X_test_df_lead_3)\n",
    "\n",
    "# Calculate RMSE\n",
    "rmse = np.sqrt(mean_squared_error(y_test_df_lead_3, y_pred_df_lead_3))\n",
    "print(f\"RMSE: {rmse}\")\n",
    "\n",
    "# Combine actual vs predicted into a DataFrame for comparison\n",
    "comparison_df_lead_3 = test_df[['Year_Quarter']].copy()\n",
    "comparison_df_lead_3['Actual'] = y_test_df_lead_3.values\n",
    "comparison_df_lead_3['Predicted'] = y_pred_df_lead_3\n",
    "\n",
    "# Print the comparison DataFrame\n",
    "print(\"Actual vs Predicted:\")\n",
    "print(comparison_df_lead_3)\n",
    "\n",
    "# Optional: Save the comparison to a CSV for review\n",
    "comparison_df_lead_3.to_csv('actual_vs_predicted_lead_3.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lead_4 = df_lead_4.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_lead_4 = df_lead_4[df_lead_4['Year_Quarter'] < '2021-Q4']\n",
    "test_df_lead_4 = df_lead_4[df_lead_4['Year_Quarter'] == '2021-Q4']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_lead_4.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df_lead_4.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_df_lead_4 = train_df_lead_4.drop(columns=['80072ned_Ziekteverzuimpercentage_1_lead_4', 'Year_Quarter'])\n",
    "y_train_df_lead_4 = train_df_lead_4['80072ned_Ziekteverzuimpercentage_1_lead_4']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the model\n",
    "model = Ridge()  # Or use another model like RandomForestRegressor\n",
    "\n",
    "# Train the model on the training data\n",
    "model.fit(X_train_df_lead_4, y_train_df_lead_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the test data\n",
    "X_test_df_lead_4 = test_df_lead_4.drop(columns=['80072ned_Ziekteverzuimpercentage_1_lead_4', 'Year_Quarter'])\n",
    "y_test_df_lead_4 = test_df_lead_4['80072ned_Ziekteverzuimpercentage_1_lead_4']\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_df_lead_4 = model.predict(X_test_df_lead_4)\n",
    "\n",
    "# Calculate RMSE\n",
    "rmse = np.sqrt(mean_squared_error(y_test_df_lead_4, y_pred_df_lead_4))\n",
    "print(f\"RMSE: {rmse}\")\n",
    "\n",
    "# Combine actual vs predicted into a DataFrame for comparison\n",
    "comparison_df_lead_4 = test_df[['Year_Quarter']].copy()\n",
    "comparison_df_lead_4['Actual'] = y_test_df_lead_4.values\n",
    "comparison_df_lead_4['Predicted'] = y_pred_df_lead_4\n",
    "\n",
    "# Print the comparison DataFrame\n",
    "print(\"Actual vs Predicted:\")\n",
    "print(comparison_df_lead_4)\n",
    "\n",
    "# Optional: Save the comparison to a CSV for review\n",
    "comparison_df_lead_4.to_csv('actual_vs_predicted_lead_4.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verder gaan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the dataset for \"C Industrie\"\n",
    "industry = 'C Industrie'\n",
    "industry_df = df[df['BedrijfstakkenBranchesSBI2008'] == industry]\n",
    "\n",
    "# Split into training and testing based on 'Year_Quarter'\n",
    "train_df = industry_df[industry_df['Year_Quarter'] < '2022-Q1']\n",
    "test_df = industry_df[industry_df['Year_Quarter'] >= '2022-Q1']\n",
    "\n",
    "# Separate features and target for training\n",
    "X_train = train_df.drop(columns=['80072ned_Ziekteverzuimpercentage_1', 'Year_Quarter', 'BedrijfstakkenBranchesSBI2008'])\n",
    "y_train = train_df['80072ned_Ziekteverzuimpercentage_1']\n",
    "\n",
    "# Separate the initial features and target for testing\n",
    "# We’ll use X_test_initial for recursive predictions\n",
    "X_test_initial = train_df.drop(columns=['80072ned_Ziekteverzuimpercentage_1', 'Year_Quarter', 'BedrijfstakkenBranchesSBI2008']).iloc[-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Set display options for Pandas to show all columns if it's a DataFrame or Series\n",
    "pd.set_option('display.max_rows', None)  # Show all rows\n",
    "pd.set_option('display.max_columns', None)  # Show all columns\n",
    "\n",
    "# Print the full content of X_test_initial\n",
    "print(X_test_initial)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Initialize the model\n",
    "model = Ridge()  # Or use another model like RandomForestRegressor\n",
    "\n",
    "# Train the model on the training data\n",
    "model.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create lagged features for the target variable\n",
    "for lag in [1, 2, 3, 4]:  # Create lags for the last 4 quarters\n",
    "    df[f'80072ned_Ziekteverzuimpercentage_1_lag_{lag}'] = df['80072ned_Ziekteverzuimpercentage_1'].shift(lag)\n",
    "\n",
    "# Drop rows with missing values due to lagging\n",
    "df = df.dropna().reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define features and target for training\n",
    "X_train = train_df.drop(columns=['80072ned_Ziekteverzuimpercentage_1', 'Year_Quarter', 'BedrijfstakkenBranchesSBI2008'])\n",
    "y_train = train_df['80072ned_Ziekteverzuimpercentage_1']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the initial data for recursive forecasting\n",
    "X_test_initial = X_train.iloc[-1].copy()  # Use the last row of training data as the starting point\n",
    "X_test_initial = pd.DataFrame([X_test_initial], columns=X_train.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Placeholder to store predictions for each quarter in 2022\n",
    "predictions = []\n",
    "\n",
    "# Number of future quarters we want to predict (e.g., all quarters in 2022)\n",
    "future_periods = 4\n",
    "\n",
    "# Start with a copy of the initial test data for recursive predictions\n",
    "X_current = X_test_initial.copy()\n",
    "\n",
    "# Ensure X_current is a DataFrame with the correct feature names\n",
    "X_current = pd.DataFrame([X_current], columns=X_train.columns)\n",
    "\n",
    "for i in range(future_periods):\n",
    "    # Predict for the next quarter\n",
    "    y_pred = model.predict(X_current)[0]\n",
    "    predictions.append(y_pred)\n",
    "    \n",
    "    # Update lag features for the next prediction\n",
    "    for lag in range(4, 1, -1):  # Update lags 4 -> 3 -> 2 -> 1\n",
    "        X_current.loc[:, f'80072ned_Ziekteverzuimpercentage_1_lag_{lag}'] = X_current[f'80072ned_Ziekteverzuimpercentage_1_lag_{lag-1}']\n",
    "    X_current.loc[:, '80072ned_Ziekteverzuimpercentage_1_lag_1'] = y_pred  # Set lag 1 to the current prediction\n",
    "\n",
    "# Display predictions for each quarter in 2022\n",
    "print(\"Predicted sick leave percentages for 'C Industrie' in 2022:\", predictions)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Samenvoegen modellen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of unique industries\n",
    "industries = df['BedrijfstakkenBranchesSBI2008'].unique()\n",
    "\n",
    "# Dictionary to store train and test sets for each industry\n",
    "industry_splits = {}\n",
    "\n",
    "for industry in industries:\n",
    "    # Filter data for the specific industry\n",
    "    industry_df = df[df['BedrijfstakkenBranchesSBI2008'] == industry]\n",
    "    \n",
    "    # Split into train and test based on Year_Quarter\n",
    "    train_df = industry_df[industry_df['Year_Quarter'] < '2022-Q1']\n",
    "    test_df = industry_df[industry_df['Year_Quarter'] >= '2022-Q1']\n",
    "    \n",
    "    # Separate features and target for training and testing\n",
    "    X_train = train_df.drop(columns=['80072ned_Ziekteverzuimpercentage_1'])\n",
    "    y_train = train_df['80072ned_Ziekteverzuimpercentage_1']\n",
    "    X_test = test_df.drop(columns=['80072ned_Ziekteverzuimpercentage_1'])\n",
    "    y_test = test_df['80072ned_Ziekteverzuimpercentage_1']\n",
    "    \n",
    "    # Store train and test sets in the dictionary\n",
    "    industry_splits[industry] = {\n",
    "        'X_train': X_train,\n",
    "        'y_train': y_train,\n",
    "        'X_test': X_test,\n",
    "        'y_test': y_test\n",
    "    }\n",
    "\n",
    "    print(f\"Data for {industry}:\")\n",
    "    print(\"  Training data:\", X_train.shape, y_train.shape)\n",
    "    print(\"  Testing data:\", X_test.shape, y_test.shape)\n",
    "\n",
    "# First, select numeric columns for grouping\n",
    "df_numeric = df.select_dtypes(include=[float, int])\n",
    "\n",
    "# Group by 'Year_Quarter' and calculate the mean only for numeric columns\n",
    "df_grouped = df_numeric.groupby(df['Year_Quarter']).mean().reset_index()\n",
    "\n",
    "# Now split into train and test based on 'Year_Quarter'\n",
    "train_df = df_grouped[df_grouped['Year_Quarter'] < '2022-Q1']\n",
    "test_df = df_grouped[df_grouped['Year_Quarter'] >= '2022-Q1']\n",
    "\n",
    "# Separate features and target for the combined dataset\n",
    "X_train_combined = train_df.drop(columns=['80072ned_Ziekteverzuimpercentage_1'])\n",
    "y_train_combined = train_df['80072ned_Ziekteverzuimpercentage_1']\n",
    "X_test_combined = test_df.drop(columns=['80072ned_Ziekteverzuimpercentage_1'])\n",
    "y_test_combined = test_df['80072ned_Ziekteverzuimpercentage_1']\n",
    "\n",
    "print(\"\\nCombined data (after grouping by Year_Quarter):\")\n",
    "print(\"  Training data:\", X_train_combined.shape, y_train_combined.shape)\n",
    "print(\"  Testing data:\", X_test_combined.shape, y_test_combined.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "industry_splits['C Industrie']['X_train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "industry_splits['C Industrie']['y_train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "# Define function to train and evaluate a model, and capture predictions vs actuals\n",
    "def train_and_evaluate(X_train, y_train, X_test, y_test, industry_name):\n",
    "    model = LinearRegression()  # Initialize the model\n",
    "    model.fit(X_train, y_train)  # Train the model\n",
    "    \n",
    "    # Predictions\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Evaluation metrics\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    rmse = mse ** 0.5\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    \n",
    "    print(f\"\\n{industry_name} Model Evaluation:\")\n",
    "    print(f\"  Mean Absolute Error (MAE): {mae}\")\n",
    "    print(f\"  Mean Squared Error (MSE): {mse}\")\n",
    "    print(f\"  Root Mean Squared Error (RMSE): {rmse}\")\n",
    "    print(f\"  R-squared (R2): {r2}\")\n",
    "    \n",
    "    # Create a DataFrame with predictions and actuals for comparison\n",
    "    results_df = pd.DataFrame({\n",
    "        'Actual': y_test,\n",
    "        'Predicted': y_pred\n",
    "    })\n",
    "    \n",
    "    return model, results_df\n",
    "\n",
    "# Dictionary to store models and results for each industry\n",
    "industry_models = {}\n",
    "industry_results = {}\n",
    "\n",
    "# 1. Train and evaluate models for each industry and store results\n",
    "for industry, data in industry_splits.items():\n",
    "    print(f\"\\nTraining model for industry: {industry}\")\n",
    "    \n",
    "    # Ensure only numeric columns are used\n",
    "    X_train = data['X_train'].copy().select_dtypes(include=[float, int])\n",
    "    y_train = data['y_train']\n",
    "    X_test = data['X_test'].copy().select_dtypes(include=[float, int])\n",
    "    y_test = data['y_test']\n",
    "    \n",
    "    # Train and evaluate model for this industry\n",
    "    model, results_df = train_and_evaluate(X_train, y_train, X_test, y_test, industry)\n",
    "    industry_models[industry] = model\n",
    "    industry_results[industry] = results_df\n",
    "\n",
    "# 2. Train and evaluate the combined model\n",
    "print(\"\\nTraining combined model:\")\n",
    "\n",
    "# Ensure only numeric columns are in combined training and testing sets\n",
    "X_train_combined = X_train_combined.select_dtypes(include=[float, int])\n",
    "X_test_combined = X_test_combined.select_dtypes(include=[float, int])\n",
    "\n",
    "combined_model, combined_results_df = train_and_evaluate(X_train_combined, y_train_combined, X_test_combined, y_test_combined, \"Combined\")\n",
    "\n",
    "# Store the combined model and results separately for easy reference\n",
    "industry_models[\"Combined\"] = combined_model\n",
    "industry_results[\"Combined\"] = combined_results_df\n",
    "\n",
    "# Display results for each industry\n",
    "for industry, results_df in industry_results.items():\n",
    "    print(f\"\\nPredictions and Actuals for {industry}:\\n\", results_df)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
