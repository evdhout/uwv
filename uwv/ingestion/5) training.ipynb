{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display\n",
    "\n",
    "# Preprocessing and Scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Real, Integer\n",
    "\n",
    "# Linear Models\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import ElasticNet\n",
    "\n",
    "# Tree-Based and Ensemble Models\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "\n",
    "# Support Vector Machines\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "# Nearest Neighbors\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "# Neural Networks\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "# Metrics and Validation\n",
    "from sklearn.metrics import mean_absolute_error, root_mean_squared_error, mean_absolute_percentage_error\n",
    "\n",
    "# Pretty Table for Logging Results\n",
    "from prettytable import PrettyTable\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model selection based on complete dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load csv into a dataframe\n",
    "df = pd.read_csv(\"data/merged_table.csv\")\n",
    "\n",
    "# Set the Year_Quarter column as the index for easy operations\n",
    "df.set_index('Year_Quarter', inplace=True)\n",
    "\n",
    "# Filter the index to include only values between 2008 and 2021 (inclusive)\n",
    "df_filtered = df[(df.index >= '2008') & (df.index <= '2022')]\n",
    "df_filtered_test = df[(df.index >= '2008') & (df.index <= '2024')]\n",
    "\n",
    "display(df_filtered.tail(), df_filtered_test.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_timeseries = df_filtered[['BedrijfstakkenBranchesSBI2008'] + [\"covid_19\"] + [col for col in df_filtered.columns if '80072ned_Ziekteverzuimpercentage_1' in col]]\n",
    "df_timeseries_test = df_filtered_test[['BedrijfstakkenBranchesSBI2008'] + [\"covid_19\"] + [col for col in df_filtered_test.columns if '80072ned_Ziekteverzuimpercentage_1' in col]]\n",
    "display(df_timeseries.tail(), df_timeseries_test.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring models (only time series and COVID-19 data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to perform training/validation and save results\n",
    "def train_and_validate(df, target_column, model, model_name, save_csv=False, compute_feature_importance=False):\n",
    "    \"\"\"\n",
    "    Perform time-series cross-validation using the specified model and optionally compute feature importance.\n",
    "    \n",
    "    Parameters:\n",
    "        df (DataFrame): Time-series data for all industries.\n",
    "        target_column (str): Target column for prediction.\n",
    "        model: A scikit-learn-compatible model instance (e.g., LinearRegression, RandomForest).\n",
    "        model_name (str): Name of the model to use in file naming.\n",
    "        save_csv (bool): Whether to save the results to a CSV file (default is False).\n",
    "        compute_feature_importance (bool): Whether to compute feature importance for linear models (default is False).\n",
    "    \"\"\"\n",
    "    industries = df['BedrijfstakkenBranchesSBI2008'].unique()\n",
    "\n",
    "    # Placeholder for storing results\n",
    "    cv_results = []\n",
    "\n",
    "    # Perform the analysis for each industry\n",
    "    for industry in industries:\n",
    "        result, X, fitted_model = perform_time_series_cv(df, target_column, industry, model)\n",
    "        cv_results.append(result)\n",
    "\n",
    "        # Compute feature importance if requested\n",
    "        if compute_feature_importance and isinstance(fitted_model, LinearRegression):\n",
    "            feature_importance = compute_feature_importance_linear(X, fitted_model)\n",
    "            print(f\"Feature importance for {industry}:\\n{feature_importance}\\n\")\n",
    "\n",
    "    # Prepare the results for saving to CSV\n",
    "    if save_csv:\n",
    "        output_rows = []\n",
    "        for result in cv_results:\n",
    "            for res in result[\"results\"]:\n",
    "                output_rows.append({\n",
    "                    \"Industry\": result[\"industry\"],\n",
    "                    \"Train Start\": res[\"train_range\"][0],\n",
    "                    \"Train End\": res[\"train_range\"][1],\n",
    "                    \"Validation Start\": res[\"validation_range\"][0],\n",
    "                    \"Validation End\": res[\"validation_range\"][1],\n",
    "                    \"MAE\": res[\"mae\"],\n",
    "                    \"Actual Values\": res[\"actual_values\"],\n",
    "                    \"Predicted Values\": res[\"predicted_values\"]\n",
    "                })\n",
    "\n",
    "        # Convert to DataFrame for saving\n",
    "        output_df = pd.DataFrame(output_rows)\n",
    "\n",
    "        # Save to CSV\n",
    "        output_folder = \"data\"\n",
    "        os.makedirs(output_folder, exist_ok=True)\n",
    "        output_path = os.path.join(output_folder, f\"{model_name}_training_results.csv\")\n",
    "        output_df.to_csv(output_path, index=False)\n",
    "\n",
    "    # Log the results in table format\n",
    "    log_results(cv_results, model_name)\n",
    "\n",
    "def perform_time_series_cv(df, target_column, industry, model):\n",
    "    \"\"\"\n",
    "    Perform time-series cross-validation using the specified model.\n",
    "    \n",
    "    Parameters:\n",
    "        df (DataFrame): Time-series data for all industries.\n",
    "        target_column (str): Target column for prediction.\n",
    "        industry (str): Specific industry to filter data for.\n",
    "        model: A scikit-learn-compatible model instance.\n",
    "    \n",
    "    Returns:\n",
    "        dict: Results including average MAE, predictions, and actual values per fold.\n",
    "        DataFrame: Features (X) used for training.\n",
    "        object: The fitted model.\n",
    "    \"\"\"\n",
    "    # Filter for the specific industry\n",
    "    industry_data = df[df['BedrijfstakkenBranchesSBI2008'] == industry].copy()\n",
    "\n",
    "    # Ensure the index is in Period format\n",
    "    industry_data.index = pd.PeriodIndex(industry_data.index, freq='Q')\n",
    "\n",
    "    # Define X (features) and y (target)\n",
    "    X = industry_data.drop(columns=[target_column, 'BedrijfstakkenBranchesSBI2008'])\n",
    "    y = industry_data[target_column]\n",
    "\n",
    "    # Generate train-validation splits\n",
    "    def generate_splits():\n",
    "        train_start = pd.Period(\"2008Q1\", freq=\"Q\")\n",
    "        train_end = pd.Period(\"2010Q4\", freq=\"Q\")\n",
    "        validation_start = pd.Period(\"2011Q1\", freq=\"Q\")\n",
    "        validation_end = pd.Period(\"2021Q4\", freq=\"Q\")  # Ensure four-quarter validation remains in range\n",
    "\n",
    "        splits = []\n",
    "\n",
    "        while validation_start + 3 <= validation_end:\n",
    "            splits.append({\n",
    "                \"train_start\": train_start,\n",
    "                \"train_end\": train_end,\n",
    "                \"validation_start\": validation_start,\n",
    "                \"validation_end\": validation_start + 3  # Four quarters ahead\n",
    "            })\n",
    "\n",
    "            train_end += 1\n",
    "            validation_start += 1\n",
    "\n",
    "        return splits\n",
    "\n",
    "    splits = generate_splits()\n",
    "\n",
    "    # Perform cross-validation\n",
    "    results = []\n",
    "    quarterly_mae = {f\"Q{i}\": [] for i in range(1, 5)}  # Track MAEs by quarter for this industry\n",
    "\n",
    "    for split in splits:\n",
    "        # Identify train and validation indices\n",
    "        train_index = (industry_data.index >= split[\"train_start\"]) & (industry_data.index <= split[\"train_end\"])\n",
    "        validation_index = (industry_data.index >= split[\"validation_start\"]) & (industry_data.index <= split[\"validation_end\"])\n",
    "\n",
    "        # Ensure there is data in both sets\n",
    "        if train_index.sum() == 0 or validation_index.sum() == 0:\n",
    "            print(f\"Skipping split: Train ({split['train_start']} to {split['train_end']}), Validation ({split['validation_start']} to {split['validation_end']})\")\n",
    "            continue\n",
    "\n",
    "        # Extract train and validation sets\n",
    "        X_train, X_validation = X[train_index], X[validation_index]\n",
    "        y_train, y_validation = y[train_index], y[validation_index]\n",
    "\n",
    "        # Fit the model\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        # Predict on validation set\n",
    "        y_pred = model.predict(X_validation)\n",
    "\n",
    "        # Store actual and predicted values\n",
    "        actual_values = [float(round(val, 2)) for val in y_validation.values.tolist()]\n",
    "        predicted_values = [float(round(pred, 2)) for pred in y_pred]  # Explicitly cast to float\n",
    "\n",
    "        # Calculate MAE for each quarter in the validation period\n",
    "        validation_periods = industry_data.index[validation_index]\n",
    "        quarter_mae = {\n",
    "            str(period): float(round(mean_absolute_error([y_validation.loc[period]], [y_pred[i]]), 2))\n",
    "            for i, period in enumerate(validation_periods)\n",
    "        }\n",
    "\n",
    "        # Append MAE to quarterly tracking\n",
    "        for period, mae in quarter_mae.items():\n",
    "            quarter = int(period[-1])  # Extract quarter from \"YYYYQx\"\n",
    "            quarterly_mae[f\"Q{quarter}\"].append(mae)\n",
    "\n",
    "        results.append({\n",
    "            \"train_range\": (split[\"train_start\"], split[\"train_end\"]),\n",
    "            \"validation_range\": (split[\"validation_start\"], split[\"validation_end\"]),\n",
    "            \"mae\": quarter_mae,\n",
    "            \"actual_values\": actual_values,\n",
    "            \"predicted_values\": predicted_values\n",
    "        })\n",
    "\n",
    "    # Calculate average MAE for this industry by quarter\n",
    "    avg_mae_by_quarter = {q: float(round(np.mean(maes), 2)) if maes else None for q, maes in quarterly_mae.items()}\n",
    "    return {\"industry\": industry, \"avg_mae\": avg_mae_by_quarter, \"results\": results}, X, model\n",
    "\n",
    "def log_results(cv_results, model_name):\n",
    "    \"\"\"\n",
    "    Logs and formats the results of cross-validation.\n",
    "    \n",
    "    Parameters:\n",
    "        cv_results (list): Results of the cross-validation for each industry.\n",
    "        model_name (str): Name of the model used.\n",
    "    \"\"\"\n",
    "    # Initialize accumulators for overall metrics\n",
    "    total_mae = 0\n",
    "    total_rmse = 0\n",
    "    total_mape = 0\n",
    "    count = 0\n",
    "\n",
    "    # Create a table for formatted results\n",
    "    table = PrettyTable()\n",
    "    table.field_names = [\"Industry\", \"Q1 MAE\", \"Q2 MAE\", \"Q3 MAE\", \"Q4 MAE\", \"Avg MAE\", \"Avg RMSE\", \"Avg MAPE\"]\n",
    "\n",
    "    # Add each industry's results to the table\n",
    "    for result in cv_results:\n",
    "        industry = result[\"industry\"]\n",
    "        avg_mae_by_quarter = result[\"avg_mae\"]\n",
    "        all_actuals = []\n",
    "        all_predictions = []\n",
    "\n",
    "        # Collect all actual and predicted values across all folds for this industry\n",
    "        for res in result[\"results\"]:\n",
    "            all_actuals.extend(res[\"actual_values\"])\n",
    "            all_predictions.extend(res[\"predicted_values\"])\n",
    "\n",
    "        # Calculate overall metrics for this industry\n",
    "        industry_mae = mean_absolute_error(all_actuals, all_predictions)\n",
    "        industry_rmse = root_mean_squared_error(all_actuals, all_predictions)\n",
    "        industry_mape = mean_absolute_percentage_error(all_actuals, all_predictions)\n",
    "\n",
    "        # Update accumulators\n",
    "        total_mae += industry_mae\n",
    "        total_rmse += industry_rmse\n",
    "        total_mape += industry_mape\n",
    "        count += 1\n",
    "\n",
    "        # Add row to table\n",
    "        table.add_row([\n",
    "            industry,\n",
    "            avg_mae_by_quarter.get(\"Q1\", \"N/A\"),\n",
    "            avg_mae_by_quarter.get(\"Q2\", \"N/A\"),\n",
    "            avg_mae_by_quarter.get(\"Q3\", \"N/A\"),\n",
    "            avg_mae_by_quarter.get(\"Q4\", \"N/A\"),\n",
    "            round(industry_mae, 3),\n",
    "            round(industry_rmse, 3),\n",
    "            round(industry_mape, 3)\n",
    "        ])\n",
    "\n",
    "    # Calculate overall averages\n",
    "    overall_avg_mae = total_mae / count if count else float('nan')\n",
    "    overall_avg_rmse = total_rmse / count if count else float('nan')\n",
    "    overall_avg_mape = total_mape / count if count else float('nan')\n",
    "\n",
    "    # Print the overall average metrics\n",
    "    print(f\"Model: {model_name}\")\n",
    "    print(f\"Overall Average MAE: {overall_avg_mae:.3f}\")\n",
    "    print(f\"Overall Average RMSE: {overall_avg_rmse:.3f}\")\n",
    "    print(f\"Overall Average MAPE: {overall_avg_mape:.3f}\")\n",
    "    print()\n",
    "\n",
    "    # Print the formatted table\n",
    "    print(\"Cross-Validation Results:\")\n",
    "    print(table)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_and_validate(df_timeseries, target_column='80072ned_Ziekteverzuimpercentage_1', model=LinearRegression(), model_name=\"LinearRegression\", save_csv=True, compute_feature_importance=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_and_validate(df_timeseries, target_column='80072ned_Ziekteverzuimpercentage_1', model=Ridge(), model_name=\"Ridge\", save_csv=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_and_validate(df_timeseries, target_column='80072ned_Ziekteverzuimpercentage_1', model=Lasso(), model_name=\"Lasso\", save_csv=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_and_validate(df_timeseries, target_column='80072ned_Ziekteverzuimpercentage_1', model=ElasticNet(), model_name=\"ElasticNet\", save_csv=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tree-Based and Ensemble Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_and_validate(df_timeseries, target_column='80072ned_Ziekteverzuimpercentage_1', model=DecisionTreeRegressor(), model_name=\"DecisionTreeRegressor\", save_csv=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_and_validate(df_timeseries, target_column='80072ned_Ziekteverzuimpercentage_1', model=GradientBoostingRegressor(), model_name=\"GradientBoostingRegressor\", save_csv=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_and_validate(df_timeseries, target_column='80072ned_Ziekteverzuimpercentage_1', model=RandomForestRegressor(), model_name=\"RandomForestRegressor\", save_csv=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_and_validate(df_timeseries, target_column='80072ned_Ziekteverzuimpercentage_1', model=AdaBoostRegressor(), model_name=\"AdaBoostRegressor\", save_csv=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_and_validate(df_timeseries, target_column='80072ned_Ziekteverzuimpercentage_1', model=HistGradientBoostingRegressor(), model_name=\"HistGradientBoostingRegressor\", save_csv=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_and_validate(df_timeseries, target_column='80072ned_Ziekteverzuimpercentage_1', model=SVR(), model_name=\"SVR\", save_csv=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_and_validate(df_timeseries, target_column='80072ned_Ziekteverzuimpercentage_1', model=KNeighborsRegressor(), model_name=\"KNeighborsRegressor\", save_csv=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_and_validate(df_timeseries, target_column='80072ned_Ziekteverzuimpercentage_1', model=MLPRegressor(), model_name=\"MLPRegressor\", save_csv=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring models with external data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_and_validate(df_filtered, target_column='80072ned_Ziekteverzuimpercentage_1', model=LinearRegression(), model_name=\"LinearRegression\", save_csv=True, compute_feature_importance=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_and_validate(df_filtered, target_column='80072ned_Ziekteverzuimpercentage_1', model=Ridge(), model_name=\"Ridge\", save_csv=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_and_validate(df_filtered, target_column='80072ned_Ziekteverzuimpercentage_1', model=Lasso(), model_name=\"Lasso\", save_csv=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_and_validate(df_filtered, target_column='80072ned_Ziekteverzuimpercentage_1', model=ElasticNet(), model_name=\"ElasticNet\", save_csv=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tree-Basead and Ensemble Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_and_validate(df_filtered, target_column='80072ned_Ziekteverzuimpercentage_1', model=DecisionTreeRegressor(), model_name=\"DecisionTreeRegressor\", save_csv=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_and_validate(df_filtered, target_column='80072ned_Ziekteverzuimpercentage_1', model=GradientBoostingRegressor(), model_name=\"GradientBoostingRegressor\", save_csv=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_and_validate(df_filtered, target_column='80072ned_Ziekteverzuimpercentage_1', model=RandomForestRegressor(), model_name=\"RandomForestRegressor\", save_csv=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_and_validate(df_filtered, target_column='80072ned_Ziekteverzuimpercentage_1', model=AdaBoostRegressor(), model_name=\"AdaBoostRegressor\", save_csv=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_and_validate(df_filtered, target_column='80072ned_Ziekteverzuimpercentage_1', model=HistGradientBoostingRegressor(), model_name=\"HistGradientBoostingRegressor\", save_csv=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_and_validate(df_filtered, target_column='80072ned_Ziekteverzuimpercentage_1', model=SVR(), model_name=\"SVR\", save_csv=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_and_validate(df_filtered, target_column='80072ned_Ziekteverzuimpercentage_1', model=KNeighborsRegressor(), model_name=\"KNeighborsRegressor\", save_csv=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_and_validate(df_filtered, target_column='80072ned_Ziekteverzuimpercentage_1', model=MLPRegressor(), model_name=\"MLPRegressor\", save_csv=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model development\n",
    "Conclusion is to continue development with \n",
    "- Linear regression - not a lot of performance loss and the most interpretable\n",
    "- RandomForestRegressor\n",
    "- GradientBoostingRegreessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, mean_absolute_percentage_error\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Integer, Real\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import warnings\n",
    "import json\n",
    "\n",
    "# Define parameter spaces\n",
    "param_spaces = {\n",
    "    \"RandomForestRegressor\": {\n",
    "        'n_estimators': Integer(50, 300),\n",
    "        'max_depth': Integer(3, 20),\n",
    "        'min_samples_split': Integer(2, 15),\n",
    "        'min_samples_leaf': Integer(1, 8),\n",
    "        'bootstrap': [True, False]\n",
    "    },\n",
    "    \"GradientBoostingRegressor\": {\n",
    "        'n_estimators': Integer(50, 300),\n",
    "        'learning_rate': Real(0.01, 0.2, prior='log-uniform'),\n",
    "        'max_depth': Integer(3, 8),\n",
    "        'subsample': Real(0.7, 0.9),\n",
    "        'min_samples_split': Integer(2, 10),\n",
    "        'min_samples_leaf': Integer(1, 8)\n",
    "    }\n",
    "}\n",
    "\n",
    "def generate_splits():\n",
    "    \"\"\"\n",
    "    Generate train-validation splits for time-series cross-validation.\n",
    "\n",
    "    Returns:\n",
    "        splits (list): A list of dictionaries containing train and validation periods.\n",
    "    \"\"\"\n",
    "    train_start = pd.Period(\"2008Q1\", freq=\"Q\")\n",
    "    train_end = pd.Period(\"2010Q4\", freq=\"Q\")\n",
    "    validation_start = pd.Period(\"2011Q1\", freq=\"Q\")\n",
    "    validation_end = pd.Period(\"2021Q4\", freq=\"Q\")\n",
    "\n",
    "    splits = []\n",
    "\n",
    "    while validation_start + 3 <= validation_end:\n",
    "        splits.append({\n",
    "            \"train_start\": train_start,\n",
    "            \"train_end\": train_end,\n",
    "            \"validation_start\": validation_start,\n",
    "            \"validation_end\": validation_start + 3  # Four quarters ahead\n",
    "        })\n",
    "\n",
    "        train_end += 1\n",
    "        validation_start += 1\n",
    "\n",
    "    return splits\n",
    "\n",
    "def train_and_validate(df, target_column, model, model_name, param_space=None, tune_hyperparameters=False):\n",
    "    industries = df['BedrijfstakkenBranchesSBI2008'].unique()\n",
    "    splits = generate_splits()\n",
    "    all_results = []\n",
    "    best_hyperparameters = {}\n",
    "\n",
    "    for industry in industries:\n",
    "        industry_data = df[df['BedrijfstakkenBranchesSBI2008'] == industry].copy()\n",
    "        industry_data.index = pd.PeriodIndex(industry_data.index, freq='Q')\n",
    "\n",
    "        X = industry_data.drop(columns=[target_column, 'BedrijfstakkenBranchesSBI2008'])\n",
    "        y = industry_data[target_column]\n",
    "\n",
    "        custom_split_indices = []\n",
    "        for split in splits:\n",
    "            train_index = (industry_data.index >= split[\"train_start\"]) & (industry_data.index <= split[\"train_end\"])\n",
    "            validation_index = (industry_data.index >= split[\"validation_start\"]) & (industry_data.index <= split[\"validation_end\"])\n",
    "            custom_split_indices.append((np.where(train_index)[0], np.where(validation_index)[0]))\n",
    "\n",
    "        if tune_hyperparameters and param_space:\n",
    "            search = BayesSearchCV(\n",
    "                model, param_space, scoring='neg_mean_absolute_error',\n",
    "                n_iter=50, cv=custom_split_indices, n_jobs=-1, random_state=42\n",
    "            )\n",
    "            search.fit(X, y)\n",
    "\n",
    "            # Logging average MAE across splits per iteration\n",
    "            for i, params in enumerate(search.cv_results_[\"params\"]):\n",
    "                avg_mae = -search.cv_results_[\"mean_test_score\"][i]  # Convert negative MAE back to positive\n",
    "                print(f\"Industry: {industry}, Iteration: {i + 1}, Hyperparameters: {params}, Average MAE across splits: {avg_mae:.4f}\")\n",
    "\n",
    "            best_model = search.best_estimator_\n",
    "            best_params = search.best_params_\n",
    "            avg_mae_best_params = -search.best_score_  # Convert negative MAE back to positive\n",
    "\n",
    "            # Store the best parameters and MAE for the current industry and model\n",
    "            best_hyperparameters.setdefault(model_name, {})[industry] = {\n",
    "                \"best_hyperparameters\": best_params,\n",
    "                \"lowest_mae\": avg_mae_best_params\n",
    "            }\n",
    "\n",
    "            print(f\"Best parameters for {industry}: {best_params}\\nAverage MAE for best parameters: {avg_mae_best_params:.4f}\")\n",
    "        else:\n",
    "            best_model = model\n",
    "\n",
    "        # Standard cross-validation logging (split-level MAE)\n",
    "        for split_num, split in enumerate(splits):\n",
    "            train_index = (industry_data.index >= split[\"train_start\"]) & (industry_data.index <= split[\"train_end\"])\n",
    "            validation_index = (industry_data.index >= split[\"validation_start\"]) & (industry_data.index <= split[\"validation_end\"])\n",
    "\n",
    "            if train_index.sum() == 0 or validation_index.sum() == 0:\n",
    "                continue\n",
    "\n",
    "            X_train, X_validation = X[train_index], X[validation_index]\n",
    "            y_train, y_validation = y[train_index], y[validation_index]\n",
    "\n",
    "            best_model.fit(X_train, y_train)\n",
    "            y_pred = best_model.predict(X_validation)\n",
    "\n",
    "            mae = mean_absolute_error(y_validation, y_pred)\n",
    "\n",
    "            # Collect validation details\n",
    "            validation_details = [\n",
    "                {\n",
    "                    \"Validation period\": str(period),\n",
    "                    \"Predicted\": float(pred),\n",
    "                    \"Actual\": float(actual)\n",
    "                }\n",
    "                for period, pred, actual in zip(y_validation.index, y_pred, y_validation)\n",
    "            ]\n",
    "\n",
    "            # Append results with detailed information\n",
    "            all_results.append({\n",
    "                \"industry\": industry,\n",
    "                \"split\": split_num,\n",
    "                \"mae\": mae,\n",
    "                \"train_start\": str(split[\"train_start\"]),\n",
    "                \"train_end\": str(split[\"train_end\"]),\n",
    "                \"validation_start\": str(split[\"validation_start\"]),\n",
    "                \"validation_end\": str(split[\"validation_end\"]),\n",
    "                \"validation_details\": validation_details\n",
    "            })\n",
    "\n",
    "            print(f\"Industry: {industry}, Split: {split_num}, \"\n",
    "                  f\"Train Period: {split['train_start']} to {split['train_end']}, \"\n",
    "                  f\"Validation Period: {split['validation_start']} to {split['validation_end']}, \"\n",
    "                  f\"MAE: {mae:.4f}\")\n",
    "\n",
    "    if tune_hyperparameters and param_space:\n",
    "        # Save best hyperparameters to a model-specific JSON file\n",
    "        filename = f\"hyperparameter_config_{model_name}.json\"\n",
    "        with open(filename, \"w\") as f:\n",
    "            json.dump(best_hyperparameters, f, indent=4)\n",
    "        print(f\"\\nBest hyperparameters and MAE saved to '{filename}'.\")\n",
    "\n",
    "    return pd.DataFrame(all_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"PYDEVD_DISABLE_FILE_VALIDATION\"] = \"1\"  # Removes warnings related to debugging\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"skopt\")  # Suppress BayesSearchCV warnings\n",
    "\n",
    "target_column = \"80072ned_Ziekteverzuimpercentage_1\"\n",
    "results_summary = []\n",
    "\n",
    "for model_name, param_space in param_spaces.items():\n",
    "    print(f\"\\nRunning {model_name} {'with' if param_space else 'without'} hyperparameter tuning.\")\n",
    "    if model_name == \"LinearRegression\":\n",
    "        model = LinearRegression()\n",
    "    elif model_name == \"RandomForestRegressor\":\n",
    "        model = RandomForestRegressor()\n",
    "    elif model_name == \"GradientBoostingRegressor\":\n",
    "        model = GradientBoostingRegressor()\n",
    "\n",
    "    tune_hyperparameters = bool(param_space)\n",
    "    all_results = train_and_validate(\n",
    "        df=df_filtered,\n",
    "        target_column=target_column,\n",
    "        model=model,\n",
    "        model_name=model_name,\n",
    "        param_space=param_space,\n",
    "        tune_hyperparameters=tune_hyperparameters\n",
    "    )\n",
    "\n",
    "    # Convert results to a DataFrame\n",
    "    results_df = pd.DataFrame(all_results)\n",
    "\n",
    "    # Calculate average MAE across splits for each industry\n",
    "    avg_mae_by_industry = results_df.groupby(\"industry\")[\"mae\"].mean()\n",
    "\n",
    "    # Save to summary\n",
    "    results_summary.append({\n",
    "        \"model\": model_name,\n",
    "        \"avg_mae_by_industry\": avg_mae_by_industry.to_dict(),  # Save as a dictionary\n",
    "        \"results\": results_df\n",
    "    })\n",
    "\n",
    "    # Log summary for this model\n",
    "    print(f\"\\nSummary for {model_name}:\")\n",
    "    for industry, avg_mae in avg_mae_by_industry.items():\n",
    "        print(f\"Industry: {industry}, Average MAE: {avg_mae:.4f}\")\n",
    "\n",
    "# Save detailed results to CSV\n",
    "final_results_df = pd.concat([res[\"results\"] for res in results_summary])\n",
    "final_results_df.to_csv(\"model_results_summary.csv\", index=False)\n",
    "print(\"\\nDetailed results saved to 'model_results_summary.csv'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import pandas as pd\n",
    "\n",
    "# Load hyperparameter configuration files and apply models to the test set\n",
    "best_hyperparameters = {}\n",
    "test_results = []\n",
    "\n",
    "for model_name in [\"LinearRegression\", \"RandomForestRegressor\", \"GradientBoostingRegressor\"]:\n",
    "    if model_name == \"LinearRegression\":\n",
    "        print(f\"Testing {model_name} without hyperparameters...\")\n",
    "        best_hyperparameters[model_name] = {}  # No hyperparameters for LinearRegression\n",
    "    else:\n",
    "        try:\n",
    "            with open(f\"hyperparameter_config_{model_name}.json\", \"r\") as f:\n",
    "                best_hyperparameters[model_name] = json.load(f)\n",
    "        except FileNotFoundError:\n",
    "            print(f\"Hyperparameter configuration for {model_name} not found.\")\n",
    "            continue\n",
    "\n",
    "    model_config = best_hyperparameters[model_name]\n",
    "    \n",
    "    for industry in df_filtered_test['BedrijfstakkenBranchesSBI2008'].unique():\n",
    "        # Access 'best_hyperparameters' for non-LinearRegression models\n",
    "        if model_name != \"LinearRegression\":\n",
    "            if model_name not in model_config:\n",
    "                raise ValueError(f\"Expected '{model_name}' as a key in its own configuration, but it is missing.\")\n",
    "            best_config = model_config.get(model_name, {}).get(industry, {})\n",
    "            best_hyperparameters_industry = best_config.get('best_hyperparameters', {})\n",
    "            if not best_hyperparameters_industry:\n",
    "                print(f\"No hyperparameters found for {industry} in {model_name}. Skipping...\")\n",
    "                continue\n",
    "            print(f\"\\nIndustry: {industry}, Model: {model_name}, Best Hyperparameters: {best_hyperparameters_industry}\")\n",
    "        else:\n",
    "            print(f\"\\nIndustry: {industry}, Model: {model_name}\")\n",
    "\n",
    "        # Filter data for this industry\n",
    "        industry_data_test = df_filtered_test[df_filtered_test['BedrijfstakkenBranchesSBI2008'] == industry].copy()\n",
    "        industry_data_test.index = pd.PeriodIndex(industry_data_test.index, freq='Q')\n",
    "\n",
    "        X_test = industry_data_test.drop(columns=['80072ned_Ziekteverzuimpercentage_1', 'BedrijfstakkenBranchesSBI2008'])\n",
    "        y_test = industry_data_test['80072ned_Ziekteverzuimpercentage_1']\n",
    "\n",
    "        # Initialize the model\n",
    "        if model_name == \"LinearRegression\":\n",
    "            model = LinearRegression()\n",
    "        elif model_name == \"RandomForestRegressor\":\n",
    "            model = RandomForestRegressor(**best_hyperparameters_industry)\n",
    "        elif model_name == \"GradientBoostingRegressor\":\n",
    "            model = GradientBoostingRegressor(**best_hyperparameters_industry)\n",
    "        else:\n",
    "            raise ValueError(f\"Model '{model_name}' is not supported.\")\n",
    "\n",
    "        # Perform testing based on the defined criteria\n",
    "        splits_test = []\n",
    "        train_start_test = pd.Period(\"2008Q1\", freq=\"Q\")\n",
    "        train_end_test = pd.Period(\"2021Q4\", freq=\"Q\")\n",
    "        validation_start_test = pd.Period(\"2022Q1\", freq=\"Q\")\n",
    "        validation_end_test = pd.Period(\"2023Q4\", freq=\"Q\")\n",
    "\n",
    "        while validation_start_test + 3 <= validation_end_test:\n",
    "            splits_test.append({\n",
    "                \"train_start\": train_start_test,\n",
    "                \"train_end\": train_end_test,\n",
    "                \"validation_start\": validation_start_test,\n",
    "                \"validation_end\": validation_start_test + 3  # Four quarters ahead\n",
    "            })\n",
    "\n",
    "            train_end_test += 1\n",
    "            validation_start_test += 1\n",
    "\n",
    "        for split_test_num, split_test in enumerate(splits_test):\n",
    "            # Define train and validation periods\n",
    "            train_index_test = (industry_data_test.index >= split_test[\"train_start\"]) & (industry_data_test.index <= split_test[\"train_end\"])\n",
    "            validation_index_test = (industry_data_test.index >= split_test[\"validation_start\"]) & (industry_data_test.index <= split_test[\"validation_end\"])\n",
    "\n",
    "            if train_index_test.sum() == 0 or validation_index_test.sum() == 0:\n",
    "                print(f\"Skipping Split {split_test_num} for Industry: {industry} due to empty training or validation data.\")\n",
    "                continue\n",
    "\n",
    "            X_train_test, X_validation_test = X_test[train_index_test], X_test[validation_index_test]\n",
    "            y_train_test, y_validation_test = y_test[train_index_test], y_test[validation_index_test]\n",
    "\n",
    "            # Fit the model and predict\n",
    "            try:\n",
    "                model.fit(X_train_test, y_train_test)\n",
    "                y_pred_test = model.predict(X_validation_test)\n",
    "            except ValueError as e:\n",
    "                print(f\"Error in model fitting for Industry: {industry}, Split: {split_test_num}. Error: {e}\")\n",
    "                continue\n",
    "\n",
    "            # Collect results\n",
    "            mae_test = mean_absolute_error(y_validation_test, y_pred_test)\n",
    "            test_results.append({\n",
    "                \"industry\": industry,\n",
    "                \"model\": model_name,\n",
    "                \"split_test\": split_test_num,\n",
    "                \"train_start\": str(split_test[\"train_start\"]),\n",
    "                \"train_end\": str(split_test[\"train_end\"]),\n",
    "                \"validation_start\": str(split_test[\"validation_start\"]),\n",
    "                \"validation_end\": str(split_test[\"validation_end\"]),\n",
    "                \"mae_test\": mae_test,\n",
    "                \"validation_details\": [\n",
    "                    {\"Validation period\": str(period), \"Predicted\": float(pred), \"Actual\": float(actual)}\n",
    "                    for period, pred, actual in zip(y_validation_test.index, y_pred_test, y_validation_test)\n",
    "                ]\n",
    "            })\n",
    "\n",
    "            # Log testing details\n",
    "            print(f\"Industry: {industry}, Split: {split_test_num}, \"\n",
    "                  f\"Train Period: {split_test['train_start']} to {split_test['train_end']}, \"\n",
    "                  f\"Validation Period: {split_test['validation_start']} to {split_test['validation_end']}, \"\n",
    "                  f\"MAE: {mae_test:.4f}\")\n",
    "\n",
    "# Save test results to a DataFrame\n",
    "test_results_df = pd.DataFrame(test_results)\n",
    "\n",
    "# Save test results to CSV\n",
    "test_results_df.to_csv(\"test_results_summary.csv\", index=False)\n",
    "print(\"\\nDetailed test results saved to 'test_results_summary.csv'.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Other stuff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Met crossfall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.impute import SimpleImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to perform cross-validation and hyperparameter tuning\n",
    "def perform_tuning(df, target_column, lead, industry):\n",
    "    # Filter data for the specific industry\n",
    "    df = df[df['BedrijfstakkenBranchesSBI2008'] == industry].copy()\n",
    "\n",
    "    # Convert year_quarter to a proper format\n",
    "    df.loc[:, 'Year_Quarter'] = pd.PeriodIndex(df['Year_Quarter'], freq='Q')\n",
    "\n",
    "    year_quarter = df['Year_Quarter']\n",
    "\n",
    "    # Ensure alignment of indices\n",
    "    X = df.drop(columns=[target_column, 'Year_Quarter', 'BedrijfstakkenBranchesSBI2008']).reset_index(drop=True)\n",
    "    y = df[target_column].reset_index(drop=True)\n",
    "    year_quarter = year_quarter.reset_index(drop=True)\n",
    "\n",
    "    # Generate train/validation splits\n",
    "    def generate_splits():\n",
    "        train_start = pd.Period(\"2008Q1\", freq=\"Q\")\n",
    "        train_end = pd.Period(\"2010Q4\", freq=\"Q\")\n",
    "        validation_start = pd.Period(\"2011Q1\", freq=\"Q\")\n",
    "        validation_end = pd.Period(\"2021Q4\", freq=\"Q\")\n",
    "\n",
    "        splits = []\n",
    "\n",
    "        while validation_start <= validation_end:\n",
    "            splits.append({\n",
    "                \"train_start\": \"2008Q1\",  # Always start training from 2008Q1\n",
    "                \"train_end\": str(train_end),\n",
    "                \"validation\": str(validation_start)\n",
    "            })\n",
    "\n",
    "            train_end += 1\n",
    "            validation_start += 1\n",
    "\n",
    "        return splits\n",
    "\n",
    "    splits = generate_splits()\n",
    "\n",
    "    # Hyperparameter grid\n",
    "    alphas = [0.1, 1.0, 10.0, 100.0, 10000.0, 100000.0, 1000000.0, 10000000.0, 100000000.0]\n",
    "    tuning_results = []\n",
    "\n",
    "    print(f\"Time Series Cross-Validation with Hyperparameter Tuning for Q+{lead} ({industry}):\")\n",
    "\n",
    "    # Perform cross-validation with hyperparameter tuning\n",
    "    for alpha in alphas:\n",
    "        fold_results = []\n",
    "        print(f\"Testing alpha: {alpha}\\n\")\n",
    "\n",
    "        for fold, split in enumerate(splits, 1):\n",
    "            # Convert string dates to Period\n",
    "            train_start = pd.Period(split[\"train_start\"], freq='Q')\n",
    "            train_end = pd.Period(split[\"train_end\"], freq='Q')\n",
    "            validation_date = pd.Period(split[\"validation\"], freq='Q')\n",
    "\n",
    "            # Get train and validation indices\n",
    "            train_index = year_quarter[(year_quarter >= train_start) & (year_quarter <= train_end)].index\n",
    "            validation_index = year_quarter[year_quarter == validation_date].index\n",
    "\n",
    "            # Extract train and validation sets\n",
    "            X_train, X_validation = X.iloc[train_index], X.iloc[validation_index]\n",
    "            y_train, y_validation = y.iloc[train_index], y.iloc[validation_index]\n",
    "            train_dates, validation_dates = year_quarter.iloc[train_index], year_quarter.iloc[validation_index]\n",
    "\n",
    "            # Train the model with the current alpha\n",
    "            model = Ridge(alpha=alpha)\n",
    "            model.fit(X_train, y_train)\n",
    "\n",
    "            # Predict and evaluate\n",
    "            y_pred = model.predict(X_validation)\n",
    "            mae = mean_absolute_error(y_validation, y_pred)\n",
    "\n",
    "            # Save results for this fold\n",
    "            fold_results.append(mae)\n",
    "\n",
    "            print(f\"Fold {fold}:\")\n",
    "            print(f\"Train Date Range: {train_dates.min()} to {train_dates.max()}\")\n",
    "            print(f\"Validation Date: {validation_dates.iloc[0]}\")\n",
    "            print(f\"MAE: {mae:.4f}\")\n",
    "\n",
    "        # Calculate average MAE for this alpha\n",
    "        avg_mae = np.mean(fold_results) if fold_results else float('inf')\n",
    "        tuning_results.append({\"alpha\": alpha, \"average_mae\": avg_mae})\n",
    "        print(f\"\\nAverage MAE for alpha {alpha}: {avg_mae:.4f}\\n\")\n",
    "\n",
    "    # Find the best alpha\n",
    "    best_result = min(tuning_results, key=lambda x: x[\"average_mae\"])\n",
    "\n",
    "    # Summary of all hyperparameters\n",
    "    print(f\"\\nHyperparameter Tuning Summary for Q+{lead} ({industry}):\")\n",
    "    for result in tuning_results:\n",
    "        print(f\"Alpha: {result['alpha']}, Average MAE: {result['average_mae']:.4f}\")\n",
    "\n",
    "    print(f\"\\nBest alpha for Q+{lead} ({industry}): {best_result['alpha']} with Average MAE: {best_result['average_mae']:.4f}\\n\")\n",
    "\n",
    "    return tuning_results, best_result\n",
    "\n",
    "# Initialize variables for industries and data files\n",
    "industries = ['C Industrie', 'G Handel', 'Q Gezondheids- en welzijnszorg']\n",
    "\n",
    "# Data files for Q+1 to Q+4\n",
    "data_files = [\n",
    "    ('data/80072ned_Ziekteverzuimpercentage_1_lead_1.csv', '80072ned_Ziekteverzuimpercentage_1_lead_1', 1),\n",
    "    ('data/80072ned_Ziekteverzuimpercentage_1_lead_2.csv', '80072ned_Ziekteverzuimpercentage_1_lead_2', 2),\n",
    "    ('data/80072ned_Ziekteverzuimpercentage_1_lead_3.csv', '80072ned_Ziekteverzuimpercentage_1_lead_3', 3),\n",
    "    ('data/80072ned_Ziekteverzuimpercentage_1_lead_4.csv', '80072ned_Ziekteverzuimpercentage_1_lead_4', 4)\n",
    "]\n",
    "\n",
    "# Placeholder for all summaries\n",
    "all_summaries = []\n",
    "\n",
    "# Perform tuning for each lead and each industry\n",
    "for file_path, target_column, lead in data_files:\n",
    "    print(f\"Running tuning for Q+{lead}\")\n",
    "    df_lead = pd.read_csv(file_path)\n",
    "    for industry in industries:\n",
    "        print(f\"\\nIndustry: {industry}\")\n",
    "        tuning_results, best_result = perform_tuning(df_lead, target_column, lead, industry)\n",
    "        all_summaries.append({\n",
    "            \"lead\": lead,\n",
    "            \"industry\": industry,\n",
    "            \"tuning_results\": tuning_results,\n",
    "            \"best_result\": best_result\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to apply the best model to the test set\n",
    "def apply_best_model(df, target_column, best_alpha, industry, lead):\n",
    "    # Filter data for the specific industry and create a copy\n",
    "    df = df[df['BedrijfstakkenBranchesSBI2008'] == industry].copy()\n",
    "\n",
    "    # Convert 'Year_Quarter' to PeriodIndex\n",
    "    df['Year_Quarter'] = pd.PeriodIndex(df['Year_Quarter'], freq='Q')\n",
    "\n",
    "    # Define the test period\n",
    "    test_start = pd.Period(\"2022Q1\", freq=\"Q\")\n",
    "    test_end = pd.Period(\"2023Q4\", freq=\"Q\")\n",
    "\n",
    "    results = []\n",
    "\n",
    "    # Apply models for each quarter in the test period\n",
    "    while test_start <= test_end:\n",
    "        # The Prediction Period is the current `test_start`\n",
    "        prediction_period = test_start\n",
    "\n",
    "        # Train data up to the current `test_start - lead`\n",
    "        train_end = prediction_period - lead\n",
    "        if train_end < pd.Period(\"2008Q1\", freq=\"Q\"):\n",
    "            print(f\"Skipping {prediction_period} as training period {train_end} is out of range.\")\n",
    "            test_start += 1\n",
    "            continue\n",
    "\n",
    "        train_data = df[df['Year_Quarter'] <= train_end]\n",
    "\n",
    "        # Test data corresponds to the `prediction_period`\n",
    "        test_data = df[df['Year_Quarter'] == prediction_period]\n",
    "\n",
    "        if test_data.empty:\n",
    "            print(f\"No test data available for {prediction_period}. Skipping.\")\n",
    "            test_start += 1\n",
    "            continue\n",
    "\n",
    "        # Ensure alignment of indices\n",
    "        X_train = train_data.drop(columns=[target_column, 'Year_Quarter', 'BedrijfstakkenBranchesSBI2008'])\n",
    "        y_train = train_data[target_column]\n",
    "        X_test = test_data.drop(columns=[target_column, 'Year_Quarter', 'BedrijfstakkenBranchesSBI2008'])\n",
    "        y_test = test_data[target_column]  # Actual values for `prediction_period`\n",
    "\n",
    "        # Handle missing values\n",
    "        imputer = SimpleImputer(strategy='mean')\n",
    "        X_train = pd.DataFrame(imputer.fit_transform(X_train), columns=X_train.columns)\n",
    "        y_train = y_train.fillna(y_train.mean())  # Fill missing target values in training set\n",
    "        X_test = pd.DataFrame(imputer.transform(X_test), columns=X_test.columns)\n",
    "\n",
    "        # Train the model with the best alpha\n",
    "        model = Ridge(alpha=best_alpha)\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        # Predict on the test set\n",
    "        y_pred = model.predict(X_test)\n",
    "\n",
    "        # Evaluate the model\n",
    "        mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "        # Append results for this period\n",
    "        results.append({\n",
    "            \"Industry\": industry,\n",
    "            \"Model\": f\"Q+{lead}\",\n",
    "            \"Input Period\": f\"2008Q1 to {train_end}\",\n",
    "            \"Prediction Period\": str(prediction_period),\n",
    "            \"Predicted Value\": y_pred.tolist(),\n",
    "            \"Actual Value\": y_test.tolist(),  # Actual values match the prediction period\n",
    "            \"MAE\": mae\n",
    "        })\n",
    "\n",
    "        # Move to the next test period\n",
    "        test_start += 1\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "# Updated script to include Q+1 and ensure testing works as expected\n",
    "summaries = []\n",
    "industries = ['C Industrie', 'G Handel', 'Q Gezondheids- en welzijnszorg']\n",
    "\n",
    "# Perform tuning for Q+1 for each industry\n",
    "df_lead_1 = pd.read_csv('data/80072ned_Ziekteverzuimpercentage_1_lead_1.csv')\n",
    "for industry in industries:\n",
    "    summary_q1, best_result_q1 = perform_tuning(df_lead_1, '80072ned_Ziekteverzuimpercentage_1_lead_1', lead=1, industry=industry)\n",
    "    summaries.append({\"lead\": 1, \"industry\": industry, \"summary\": summary_q1, \"best_result\": best_result_q1})\n",
    "\n",
    "# Perform tuning for Q+2, Q+3, and Q+4 for each industry\n",
    "data_files = [\n",
    "    ('data/80072ned_Ziekteverzuimpercentage_1_lead_2.csv', '80072ned_Ziekteverzuimpercentage_1_lead_2', 2),\n",
    "    ('data/80072ned_Ziekteverzuimpercentage_1_lead_3.csv', '80072ned_Ziekteverzuimpercentage_1_lead_3', 3),\n",
    "    ('data/80072ned_Ziekteverzuimpercentage_1_lead_4.csv', '80072ned_Ziekteverzuimpercentage_1_lead_4', 4)\n",
    "]\n",
    "\n",
    "for file_path, target_column, lead in data_files:\n",
    "    df_lead = pd.read_csv(file_path)\n",
    "    for industry in industries:\n",
    "        summary, best_result = perform_tuning(df_lead, target_column, lead=lead, industry=industry)\n",
    "        summaries.append({\"lead\": lead, \"industry\": industry, \"summary\": summary, \"best_result\": best_result})\n",
    "\n",
    "# Apply best models to the test set\n",
    "final_results = []\n",
    "\n",
    "# Include Q+1 predictions explicitly\n",
    "data_files.insert(0, ('data/80072ned_Ziekteverzuimpercentage_1_lead_1.csv', '80072ned_Ziekteverzuimpercentage_1_lead_1', 1))\n",
    "\n",
    "for file_path, target_column, lead in data_files:\n",
    "    df_lead = pd.read_csv(file_path)\n",
    "    for summary in summaries:\n",
    "        if summary['lead'] == lead:\n",
    "            industry = summary['industry']\n",
    "            best_alpha = summary['best_result']['alpha']\n",
    "            results = apply_best_model(df_lead, target_column, best_alpha, industry, lead)\n",
    "            final_results.extend(results)\n",
    "\n",
    "# Store final results in a DataFrame for analysis\n",
    "results_df = pd.DataFrame(final_results)\n",
    "\n",
    "# Save results to CSV\n",
    "results_df.to_csv('test_results.csv', index=False)\n",
    "\n",
    "# Calculate and display average MAE per industry and model\n",
    "average_mae_summary = results_df.groupby(['Industry', 'Model'])['MAE'].mean().reset_index()\n",
    "print(\"\\nAverage MAE per Industry and Model:\")\n",
    "print(average_mae_summary)\n",
    "\n",
    "print(\"\\nTest results saved to 'test_results.csv'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Initialize the start and end points for training and validation\n",
    "train_start = pd.Period(\"2008Q1\", freq=\"Q\")\n",
    "train_end = pd.Period(\"2010Q4\", freq=\"Q\")\n",
    "validation_start = pd.Period(\"2011Q1\", freq=\"Q\")\n",
    "validation_end = pd.Period(\"2022Q4\", freq=\"Q\")\n",
    "\n",
    "# List to store the splits\n",
    "splits = []\n",
    "\n",
    "# Loop until validation exceeds the desired end date\n",
    "while validation_start <= validation_end:\n",
    "    splits.append({\n",
    "        \"train_start\": str(train_start),\n",
    "        \"train_end\": str(train_end),\n",
    "        \"validation\": str(validation_start)\n",
    "    })\n",
    "\n",
    "    # Move the train_end and validation forward by one quarter\n",
    "    train_end += 1\n",
    "    validation_start += 1\n",
    "\n",
    "# Print the splits\n",
    "for split in splits:\n",
    "    print(split)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Fold {fold}: train_index = {train_index}, test_index = {test_index}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hieronder een test zonder Crossval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = df[df['Year_Quarter'] < '2021-Q4']\n",
    "test_df = df[df['Year_Quarter'] == '2021-Q4']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the model\n",
    "model = Ridge()  # Or use another model like RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the test data\n",
    "X_test = test_df.drop(columns=['80072ned_Ziekteverzuimpercentage_1_lead_1', 'Year_Quarter'])\n",
    "y_test = test_df['80072ned_Ziekteverzuimpercentage_1_lead_1']\n",
    "\n",
    "# Train the model on the training data\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate RMSE\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "print(f\"RMSE: {rmse}\")\n",
    "\n",
    "# Combine actual vs predicted into a DataFrame for comparison\n",
    "comparison_df = test_df[['Year_Quarter']].copy()\n",
    "comparison_df['Actual'] = y_test.values\n",
    "comparison_df['Predicted'] = y_pred\n",
    "\n",
    "# Print the comparison DataFrame\n",
    "print(\"Actual vs Predicted:\")\n",
    "print(comparison_df)\n",
    "\n",
    "# Optional: Save the comparison to a CSV for review\n",
    "comparison_df.to_csv('actual_vs_predicted.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lead_2 = df_lead_2.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_lead_2 = df_lead_2[df_lead_2['Year_Quarter'] < '2021-Q4']\n",
    "test_df_lead_2 = df_lead_2[df_lead_2['Year_Quarter'] == '2021-Q4']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_lead_2.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df_lead_2.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_df_lead_2 = train_df_lead_2.drop(columns=['80072ned_Ziekteverzuimpercentage_1_lead_2', 'Year_Quarter'])\n",
    "y_train_df_lead_2 = train_df_lead_2['80072ned_Ziekteverzuimpercentage_1_lead_2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the model\n",
    "model = Ridge()  # Or use another model like RandomForestRegressor\n",
    "\n",
    "# Train the model on the training data\n",
    "model.fit(X_train_df_lead_2, y_train_df_lead_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the test data\n",
    "X_test_df_lead_2 = test_df_lead_2.drop(columns=['80072ned_Ziekteverzuimpercentage_1_lead_2', 'Year_Quarter'])\n",
    "y_test_df_lead_2 = test_df_lead_2['80072ned_Ziekteverzuimpercentage_1_lead_2']\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_df_lead_2 = model.predict(X_test_df_lead_2)\n",
    "\n",
    "# Calculate RMSE\n",
    "rmse = np.sqrt(mean_squared_error(y_test_df_lead_2, y_pred_df_lead_2))\n",
    "print(f\"RMSE: {rmse}\")\n",
    "\n",
    "# Combine actual vs predicted into a DataFrame for comparison\n",
    "comparison_df_lead_2 = test_df[['Year_Quarter']].copy()\n",
    "comparison_df_lead_2['Actual'] = y_test_df_lead_2.values\n",
    "comparison_df_lead_2['Predicted'] = y_pred_df_lead_2\n",
    "\n",
    "# Print the comparison DataFrame\n",
    "print(\"Actual vs Predicted:\")\n",
    "print(comparison_df_lead_2)\n",
    "\n",
    "# Optional: Save the comparison to a CSV for review\n",
    "comparison_df_lead_2.to_csv('actual_vs_predicted_lead_2.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lead_3 = df_lead_3.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_lead_3 = df_lead_3[df_lead_3['Year_Quarter'] < '2021-Q4']\n",
    "test_df_lead_3 = df_lead_3[df_lead_3['Year_Quarter'] == '2021-Q4']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_lead_3.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df_lead_3.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_df_lead_3 = train_df_lead_3.drop(columns=['80072ned_Ziekteverzuimpercentage_1_lead_3', 'Year_Quarter'])\n",
    "y_train_df_lead_3 = train_df_lead_3['80072ned_Ziekteverzuimpercentage_1_lead_3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the model\n",
    "model = Ridge()  # Or use another model like RandomForestRegressor\n",
    "\n",
    "# Train the model on the training data\n",
    "model.fit(X_train_df_lead_3, y_train_df_lead_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the test data\n",
    "X_test_df_lead_3 = test_df_lead_3.drop(columns=['80072ned_Ziekteverzuimpercentage_1_lead_3', 'Year_Quarter'])\n",
    "y_test_df_lead_3 = test_df_lead_3['80072ned_Ziekteverzuimpercentage_1_lead_3']\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_df_lead_3 = model.predict(X_test_df_lead_3)\n",
    "\n",
    "# Calculate RMSE\n",
    "rmse = np.sqrt(mean_squared_error(y_test_df_lead_3, y_pred_df_lead_3))\n",
    "print(f\"RMSE: {rmse}\")\n",
    "\n",
    "# Combine actual vs predicted into a DataFrame for comparison\n",
    "comparison_df_lead_3 = test_df[['Year_Quarter']].copy()\n",
    "comparison_df_lead_3['Actual'] = y_test_df_lead_3.values\n",
    "comparison_df_lead_3['Predicted'] = y_pred_df_lead_3\n",
    "\n",
    "# Print the comparison DataFrame\n",
    "print(\"Actual vs Predicted:\")\n",
    "print(comparison_df_lead_3)\n",
    "\n",
    "# Optional: Save the comparison to a CSV for review\n",
    "comparison_df_lead_3.to_csv('actual_vs_predicted_lead_3.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lead_4 = df_lead_4.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_lead_4 = df_lead_4[df_lead_4['Year_Quarter'] < '2021-Q4']\n",
    "test_df_lead_4 = df_lead_4[df_lead_4['Year_Quarter'] == '2021-Q4']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_lead_4.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df_lead_4.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_df_lead_4 = train_df_lead_4.drop(columns=['80072ned_Ziekteverzuimpercentage_1_lead_4', 'Year_Quarter'])\n",
    "y_train_df_lead_4 = train_df_lead_4['80072ned_Ziekteverzuimpercentage_1_lead_4']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the model\n",
    "model = Ridge()  # Or use another model like RandomForestRegressor\n",
    "\n",
    "# Train the model on the training data\n",
    "model.fit(X_train_df_lead_4, y_train_df_lead_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the test data\n",
    "X_test_df_lead_4 = test_df_lead_4.drop(columns=['80072ned_Ziekteverzuimpercentage_1_lead_4', 'Year_Quarter'])\n",
    "y_test_df_lead_4 = test_df_lead_4['80072ned_Ziekteverzuimpercentage_1_lead_4']\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_df_lead_4 = model.predict(X_test_df_lead_4)\n",
    "\n",
    "# Calculate RMSE\n",
    "rmse = np.sqrt(mean_squared_error(y_test_df_lead_4, y_pred_df_lead_4))\n",
    "print(f\"RMSE: {rmse}\")\n",
    "\n",
    "# Combine actual vs predicted into a DataFrame for comparison\n",
    "comparison_df_lead_4 = test_df[['Year_Quarter']].copy()\n",
    "comparison_df_lead_4['Actual'] = y_test_df_lead_4.values\n",
    "comparison_df_lead_4['Predicted'] = y_pred_df_lead_4\n",
    "\n",
    "# Print the comparison DataFrame\n",
    "print(\"Actual vs Predicted:\")\n",
    "print(comparison_df_lead_4)\n",
    "\n",
    "# Optional: Save the comparison to a CSV for review\n",
    "comparison_df_lead_4.to_csv('actual_vs_predicted_lead_4.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verder gaan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the dataset for \"C Industrie\"\n",
    "industry = 'C Industrie'\n",
    "industry_df = df[df['BedrijfstakkenBranchesSBI2008'] == industry]\n",
    "\n",
    "# Split into training and testing based on 'Year_Quarter'\n",
    "train_df = industry_df[industry_df['Year_Quarter'] < '2022-Q1']\n",
    "test_df = industry_df[industry_df['Year_Quarter'] >= '2022-Q1']\n",
    "\n",
    "# Separate features and target for training\n",
    "X_train = train_df.drop(columns=['80072ned_Ziekteverzuimpercentage_1', 'Year_Quarter', 'BedrijfstakkenBranchesSBI2008'])\n",
    "y_train = train_df['80072ned_Ziekteverzuimpercentage_1']\n",
    "\n",
    "# Separate the initial features and target for testing\n",
    "# We’ll use X_test_initial for recursive predictions\n",
    "X_test_initial = train_df.drop(columns=['80072ned_Ziekteverzuimpercentage_1', 'Year_Quarter', 'BedrijfstakkenBranchesSBI2008']).iloc[-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Set display options for Pandas to show all columns if it's a DataFrame or Series\n",
    "pd.set_option('display.max_rows', None)  # Show all rows\n",
    "pd.set_option('display.max_columns', None)  # Show all columns\n",
    "\n",
    "# Print the full content of X_test_initial\n",
    "print(X_test_initial)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Initialize the model\n",
    "model = Ridge()  # Or use another model like RandomForestRegressor\n",
    "\n",
    "# Train the model on the training data\n",
    "model.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create lagged features for the target variable\n",
    "for lag in [1, 2, 3, 4]:  # Create lags for the last 4 quarters\n",
    "    df[f'80072ned_Ziekteverzuimpercentage_1_lag_{lag}'] = df['80072ned_Ziekteverzuimpercentage_1'].shift(lag)\n",
    "\n",
    "# Drop rows with missing values due to lagging\n",
    "df = df.dropna().reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define features and target for training\n",
    "X_train = train_df.drop(columns=['80072ned_Ziekteverzuimpercentage_1', 'Year_Quarter', 'BedrijfstakkenBranchesSBI2008'])\n",
    "y_train = train_df['80072ned_Ziekteverzuimpercentage_1']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the initial data for recursive forecasting\n",
    "X_test_initial = X_train.iloc[-1].copy()  # Use the last row of training data as the starting point\n",
    "X_test_initial = pd.DataFrame([X_test_initial], columns=X_train.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Placeholder to store predictions for each quarter in 2022\n",
    "predictions = []\n",
    "\n",
    "# Number of future quarters we want to predict (e.g., all quarters in 2022)\n",
    "future_periods = 4\n",
    "\n",
    "# Start with a copy of the initial test data for recursive predictions\n",
    "X_current = X_test_initial.copy()\n",
    "\n",
    "# Ensure X_current is a DataFrame with the correct feature names\n",
    "X_current = pd.DataFrame([X_current], columns=X_train.columns)\n",
    "\n",
    "for i in range(future_periods):\n",
    "    # Predict for the next quarter\n",
    "    y_pred = model.predict(X_current)[0]\n",
    "    predictions.append(y_pred)\n",
    "    \n",
    "    # Update lag features for the next prediction\n",
    "    for lag in range(4, 1, -1):  # Update lags 4 -> 3 -> 2 -> 1\n",
    "        X_current.loc[:, f'80072ned_Ziekteverzuimpercentage_1_lag_{lag}'] = X_current[f'80072ned_Ziekteverzuimpercentage_1_lag_{lag-1}']\n",
    "    X_current.loc[:, '80072ned_Ziekteverzuimpercentage_1_lag_1'] = y_pred  # Set lag 1 to the current prediction\n",
    "\n",
    "# Display predictions for each quarter in 2022\n",
    "print(\"Predicted sick leave percentages for 'C Industrie' in 2022:\", predictions)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Samenvoegen modellen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of unique industries\n",
    "industries = df['BedrijfstakkenBranchesSBI2008'].unique()\n",
    "\n",
    "# Dictionary to store train and test sets for each industry\n",
    "industry_splits = {}\n",
    "\n",
    "for industry in industries:\n",
    "    # Filter data for the specific industry\n",
    "    industry_df = df[df['BedrijfstakkenBranchesSBI2008'] == industry]\n",
    "    \n",
    "    # Split into train and test based on Year_Quarter\n",
    "    train_df = industry_df[industry_df['Year_Quarter'] < '2022-Q1']\n",
    "    test_df = industry_df[industry_df['Year_Quarter'] >= '2022-Q1']\n",
    "    \n",
    "    # Separate features and target for training and testing\n",
    "    X_train = train_df.drop(columns=['80072ned_Ziekteverzuimpercentage_1'])\n",
    "    y_train = train_df['80072ned_Ziekteverzuimpercentage_1']\n",
    "    X_test = test_df.drop(columns=['80072ned_Ziekteverzuimpercentage_1'])\n",
    "    y_test = test_df['80072ned_Ziekteverzuimpercentage_1']\n",
    "    \n",
    "    # Store train and test sets in the dictionary\n",
    "    industry_splits[industry] = {\n",
    "        'X_train': X_train,\n",
    "        'y_train': y_train,\n",
    "        'X_test': X_test,\n",
    "        'y_test': y_test\n",
    "    }\n",
    "\n",
    "    print(f\"Data for {industry}:\")\n",
    "    print(\"  Training data:\", X_train.shape, y_train.shape)\n",
    "    print(\"  Testing data:\", X_test.shape, y_test.shape)\n",
    "\n",
    "# First, select numeric columns for grouping\n",
    "df_numeric = df.select_dtypes(include=[float, int])\n",
    "\n",
    "# Group by 'Year_Quarter' and calculate the mean only for numeric columns\n",
    "df_grouped = df_numeric.groupby(df['Year_Quarter']).mean().reset_index()\n",
    "\n",
    "# Now split into train and test based on 'Year_Quarter'\n",
    "train_df = df_grouped[df_grouped['Year_Quarter'] < '2022-Q1']\n",
    "test_df = df_grouped[df_grouped['Year_Quarter'] >= '2022-Q1']\n",
    "\n",
    "# Separate features and target for the combined dataset\n",
    "X_train_combined = train_df.drop(columns=['80072ned_Ziekteverzuimpercentage_1'])\n",
    "y_train_combined = train_df['80072ned_Ziekteverzuimpercentage_1']\n",
    "X_test_combined = test_df.drop(columns=['80072ned_Ziekteverzuimpercentage_1'])\n",
    "y_test_combined = test_df['80072ned_Ziekteverzuimpercentage_1']\n",
    "\n",
    "print(\"\\nCombined data (after grouping by Year_Quarter):\")\n",
    "print(\"  Training data:\", X_train_combined.shape, y_train_combined.shape)\n",
    "print(\"  Testing data:\", X_test_combined.shape, y_test_combined.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "industry_splits['C Industrie']['X_train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "industry_splits['C Industrie']['y_train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "# Define function to train and evaluate a model, and capture predictions vs actuals\n",
    "def train_and_evaluate(X_train, y_train, X_test, y_test, industry_name):\n",
    "    model = LinearRegression()  # Initialize the model\n",
    "    model.fit(X_train, y_train)  # Train the model\n",
    "    \n",
    "    # Predictions\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Evaluation metrics\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    rmse = mse ** 0.5\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    \n",
    "    print(f\"\\n{industry_name} Model Evaluation:\")\n",
    "    print(f\"  Mean Absolute Error (MAE): {mae}\")\n",
    "    print(f\"  Mean Squared Error (MSE): {mse}\")\n",
    "    print(f\"  Root Mean Squared Error (RMSE): {rmse}\")\n",
    "    print(f\"  R-squared (R2): {r2}\")\n",
    "    \n",
    "    # Create a DataFrame with predictions and actuals for comparison\n",
    "    results_df = pd.DataFrame({\n",
    "        'Actual': y_test,\n",
    "        'Predicted': y_pred\n",
    "    })\n",
    "    \n",
    "    return model, results_df\n",
    "\n",
    "# Dictionary to store models and results for each industry\n",
    "industry_models = {}\n",
    "industry_results = {}\n",
    "\n",
    "# 1. Train and evaluate models for each industry and store results\n",
    "for industry, data in industry_splits.items():\n",
    "    print(f\"\\nTraining model for industry: {industry}\")\n",
    "    \n",
    "    # Ensure only numeric columns are used\n",
    "    X_train = data['X_train'].copy().select_dtypes(include=[float, int])\n",
    "    y_train = data['y_train']\n",
    "    X_test = data['X_test'].copy().select_dtypes(include=[float, int])\n",
    "    y_test = data['y_test']\n",
    "    \n",
    "    # Train and evaluate model for this industry\n",
    "    model, results_df = train_and_evaluate(X_train, y_train, X_test, y_test, industry)\n",
    "    industry_models[industry] = model\n",
    "    industry_results[industry] = results_df\n",
    "\n",
    "# 2. Train and evaluate the combined model\n",
    "print(\"\\nTraining combined model:\")\n",
    "\n",
    "# Ensure only numeric columns are in combined training and testing sets\n",
    "X_train_combined = X_train_combined.select_dtypes(include=[float, int])\n",
    "X_test_combined = X_test_combined.select_dtypes(include=[float, int])\n",
    "\n",
    "combined_model, combined_results_df = train_and_evaluate(X_train_combined, y_train_combined, X_test_combined, y_test_combined, \"Combined\")\n",
    "\n",
    "# Store the combined model and results separately for easy reference\n",
    "industry_models[\"Combined\"] = combined_model\n",
    "industry_results[\"Combined\"] = combined_results_df\n",
    "\n",
    "# Display results for each industry\n",
    "for industry, results_df in industry_results.items():\n",
    "    print(f\"\\nPredictions and Actuals for {industry}:\\n\", results_df)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
