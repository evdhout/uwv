{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import cbsodata\n",
    "import json\n",
    "import re\n",
    "import os\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the excluded table identifiers\n",
    "excluded_identifiers = ['85663NED'] # Only has quarterly data since 2020 \n",
    "\n",
    "# Load the data from the JSON file\n",
    "with open('data/table_selection.json', 'r', encoding='utf-8') as json_file:\n",
    "    table_data = json.load(json_file)\n",
    "\n",
    "# Create a dictionary to store the identifiers and their frequencies\n",
    "identifier_freq_dict = {}\n",
    "\n",
    "# Loop through the data and extract the identifier and frequency for each entry\n",
    "for entry in table_data:\n",
    "    identifier = entry.get('Identifier', 'N/A')\n",
    "    frequency = entry.get('Frequency', 'N/A')\n",
    "    \n",
    "    # Skip identifiers that are in the excluded_identifiers list\n",
    "    if identifier in excluded_identifiers:\n",
    "        continue\n",
    "    \n",
    "    # Add the identifier and frequency to the dictionary\n",
    "    identifier_freq_dict[identifier] = frequency\n",
    "\n",
    "# Print the dictionary of identifiers and their frequencies\n",
    "print(\"Dictionary of Identifiers and Frequencies:\")\n",
    "for identifier, frequency in identifier_freq_dict.items():\n",
    "    print(f\"Identifier: {identifier}, Frequency: {frequency}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_and_save_tables(identifiers, output_folder='data'):\n",
    "    \"\"\"\n",
    "    Fetches data for each table identifier using `cbsodata.get_data()` and saves it to a CSV file,\n",
    "    skipping files that already exist.\n",
    "    \n",
    "    Parameters:\n",
    "        identifiers (list): List of table identifiers to fetch data for.\n",
    "        output_folder (str): The folder where the CSV files will be saved (default is 'data').\n",
    "    \n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    # Ensure the output folder exists\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "\n",
    "    for identifier in identifiers:\n",
    "        # Define the output CSV file path\n",
    "        output_file = f'{output_folder}/{identifier}.csv'\n",
    "        \n",
    "        # Check if the file already exists\n",
    "        if os.path.exists(output_file):\n",
    "            print(f\"Skipping {output_file} because it already exists.\")\n",
    "            continue\n",
    "        \n",
    "        # Fetch data for the current table identifier\n",
    "        print(f\"Fetching data for table identifier: {identifier}\")\n",
    "        data = pd.DataFrame(cbsodata.get_data(identifier))\n",
    "        \n",
    "        # Save the DataFrame to CSV\n",
    "        data.to_csv(output_file, index=False)\n",
    "        \n",
    "        # Print success message\n",
    "        print(f\"Data for {identifier} saved to {output_file}\")\n",
    "\n",
    "# Example usage\n",
    "fetch_and_save_tables(identifier_freq_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_csv_files(file_paths, identifier_dict, excluded_identifiers):\n",
    "    \"\"\"\n",
    "    Load multiple CSV files into DataFrames, prefix column names with the file name, \n",
    "    and convert monthly tables to quarterly, excluding specific identifiers.\n",
    "    \n",
    "    Parameters:\n",
    "        file_paths (list): List of file paths to CSV files.\n",
    "        identifier_dict (dict): Dictionary of identifiers and their frequencies.\n",
    "        excluded_identifiers (list): List of identifiers to exclude.\n",
    "    \n",
    "    Returns:\n",
    "        list: List of DataFrames with prefixed column names.\n",
    "    \"\"\"\n",
    "    dataframes = []\n",
    "    \n",
    "    for file_path in file_paths:\n",
    "        file_name = file_path.split('/')[-1].split('.')[0]\n",
    "        \n",
    "        # Skip files with identifiers in the excluded list\n",
    "        if file_name in excluded_identifiers:\n",
    "            print(f\"Skipping excluded file: {file_name}\")\n",
    "            continue\n",
    "        \n",
    "        frequency = identifier_dict.get(file_name, 'Kwartaal')  # Default to 'Kwartaal' if not specified\n",
    "\n",
    "        # Load CSV file\n",
    "        df = pd.read_csv(file_path)\n",
    "        \n",
    "        # Prefix column names with filename\n",
    "        df = df.add_prefix(f\"{file_name}_\")\n",
    "        \n",
    "        # Rename specific columns to prevent prefixing\n",
    "        for col in ['Perioden', 'BedrijfstakkenBranchesSBI2008', 'ID', 'Jaar', 'Kwartaal']:\n",
    "            if f\"{file_name}_{col}\" in df.columns:\n",
    "                df = df.rename(columns={f\"{file_name}_{col}\": col})\n",
    "                \n",
    "        # If the frequency is monthly, convert it to quarterly\n",
    "        if frequency == 'Maandelijks':\n",
    "            print(f\"Converting monthly data to quarterly for file: {file_name}\")\n",
    "            df = monthly_to_quarterly(df)\n",
    "\n",
    "        # Append to list\n",
    "        dataframes.append(df)\n",
    "    \n",
    "    return dataframes\n",
    "\n",
    "# Function to process the 'Perioden' column\n",
    "def process_period_column(df, perioden_column='Perioden', year_column='Year', quarter_column='Quarter'):\n",
    "    \"\"\"\n",
    "    Process the 'Perioden' column to extract the latest year and quarter.\n",
    "    \n",
    "    Parameters:\n",
    "        df (DataFrame): DataFrame with 'Perioden' column.\n",
    "        perioden_column (str): Name of the period column.\n",
    "        year_column (str): Name of the column for extracted year.\n",
    "        quarter_column (str): Name of the column for extracted quarter.\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame: DataFrame with new 'Year' and 'Quarter' columns.\n",
    "    \"\"\"\n",
    "    # Extract latest year and quarter from 'Perioden' column\n",
    "    df[[year_column, quarter_column]] = df[perioden_column].apply(lambda x: pd.Series(extract_latest_year_and_quarter(x)))\n",
    "    return df\n",
    "\n",
    "# Helper function to extract latest year and quarter\n",
    "def extract_latest_year_and_quarter(period_text):\n",
    "    \"\"\"\n",
    "    Extracts the latest year and quarter from a period that may contain a date range (e.g., \"2023 april - 2024 maart\").\n",
    "    \n",
    "    Parameters:\n",
    "        period_text (str): The period string to process.\n",
    "    \n",
    "    Returns:\n",
    "        tuple: A tuple containing the latest year and quarter.\n",
    "    \"\"\"\n",
    "    # Regular expression to capture year and month/quarter references\n",
    "    match = re.findall(r'(\\d{4})\\s*(\\w+)', period_text)\n",
    "    \n",
    "    if match:\n",
    "        # Take the last match in the range (latest part of the period)\n",
    "        latest_year, latest_period_part = match[-1]\n",
    "        latest_year = int(latest_year)\n",
    "        \n",
    "        # Determine the corresponding quarter for the latest period part (month or quarter)\n",
    "        latest_quarter = extract_quarter(latest_period_part)\n",
    "        \n",
    "        return latest_year, latest_quarter\n",
    "    else:\n",
    "        # Return None if no valid year/quarter is found\n",
    "        return None, None\n",
    "\n",
    "# Helper function to determine the quarter based on months or quarter phrases like '3e kwartaal'\n",
    "def extract_quarter(period_part):\n",
    "    \"\"\"\n",
    "    Extracts the quarter from the period part (e.g., based on months or quarter keywords).\n",
    "    \n",
    "    Parameters:\n",
    "        period_part (str): The part of the period string after the year.\n",
    "    \n",
    "    Returns:\n",
    "        int: The corresponding quarter (1 to 4), or None if no valid quarter is found.\n",
    "    \"\"\"\n",
    "    # Handle month-based quarters\n",
    "    if any(month in period_part for month in ['januari', 'februari', 'maart']):\n",
    "        return 1\n",
    "    elif any(month in period_part for month in ['april', 'mei', 'juni']):\n",
    "        return 2\n",
    "    elif any(month in period_part for month in ['juli', 'augustus', 'september']):\n",
    "        return 3\n",
    "    elif any(month in period_part for month in ['oktober', 'november', 'december']):\n",
    "        return 4\n",
    "    \n",
    "    # Handle phrases like '1e kwartaal', '2e kwartaal', etc.\n",
    "    if '1e' in period_part:\n",
    "        return 1\n",
    "    elif '2e' in period_part:\n",
    "        return 2\n",
    "    elif '3e' in period_part:\n",
    "        return 3\n",
    "    elif '4e' in period_part:\n",
    "        return 4\n",
    "    \n",
    "    # Return None if no valid quarter is found\n",
    "    return None\n",
    "\n",
    "def monthly_to_quarterly(df, period_column='Perioden', value_columns=None):\n",
    "    \"\"\"\n",
    "    Convert monthly data to quarterly by summing up the data for each quarter.\n",
    "    \n",
    "    Parameters:\n",
    "        df (DataFrame): The DataFrame with monthly data.\n",
    "        period_column (str): Name of the column containing period information.\n",
    "        value_columns (list): List of columns to sum (numeric columns).\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame: DataFrame with quarterly data.\n",
    "    \"\"\"\n",
    "    if value_columns is None:\n",
    "        value_columns = df.select_dtypes(include=[float, int]).columns.tolist()\n",
    "    \n",
    "    # Extract year and month from 'Perioden'\n",
    "    df['Year'] = df[period_column].apply(lambda x: int(re.search(r'(\\d{4})', x).group()))\n",
    "    df['Month'] = df[period_column].apply(lambda x: extract_month(x))\n",
    "    \n",
    "    # Create a 'Quarter' column based on the month\n",
    "    df['Quarter'] = df['Month'].apply(lambda x: (x - 1) // 3 + 1)\n",
    "    \n",
    "    # Group by 'Year' and 'Quarter' and sum the value columns\n",
    "    quarterly_df = df.groupby(['Year', 'Quarter'])[value_columns].sum().reset_index()\n",
    "    \n",
    "    return quarterly_df\n",
    "\n",
    "# Helper function to extract the month number from a period string\n",
    "def extract_month(period_text):\n",
    "    \"\"\"\n",
    "    Extracts the month number from the period string.\n",
    "    \n",
    "    Parameters:\n",
    "        period_text (str): The period string to process (e.g., \"2023 januari\").\n",
    "    \n",
    "    Returns:\n",
    "        int: The month number (1 for January, 2 for February, etc.).\n",
    "    \"\"\"\n",
    "    months = {\n",
    "        'januari': 1, 'februari': 2, 'maart': 3,\n",
    "        'april': 4, 'mei': 5, 'juni': 6,\n",
    "        'juli': 7, 'augustus': 8, 'september': 9,\n",
    "        'oktober': 10, 'november': 11, 'december': 12\n",
    "    }\n",
    "    \n",
    "    for month_name, month_num in months.items():\n",
    "        if month_name in period_text.lower():\n",
    "            return month_num\n",
    "    \n",
    "    return None  # Return None if no valid month is found\n",
    "\n",
    "def rename_sbi_column(df, primary_sbi_column='BedrijfstakkenBranchesSBI2008', backup_sbi_column='BedrijfskenmerkenSBI2008'):\n",
    "    \"\"\"\n",
    "    Renames the 'BedrijfskenmerkenSBI2008' column to 'BedrijfstakkenBranchesSBI2008' if the primary column does not exist.\n",
    "    \n",
    "    Parameters:\n",
    "        df (DataFrame): The DataFrame to process.\n",
    "        primary_sbi_column (str): The desired primary SBI column name. Default is 'BedrijfstakkenBranchesSBI2008'.\n",
    "        backup_sbi_column (str): The backup SBI column to rename. Default is 'BedrijfskenmerkenSBI2008'.\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame: Updated DataFrame with the renamed column.\n",
    "    \"\"\"\n",
    "    # Check if the primary column does not exist and the backup column does exist\n",
    "    if primary_sbi_column not in df.columns and backup_sbi_column in df.columns:\n",
    "        # Rename 'BedrijfskenmerkenSBI2008' to 'BedrijfstakkenBranchesSBI2008'\n",
    "        df = df.rename(columns={backup_sbi_column: primary_sbi_column})\n",
    "        print(f\"Renamed '{backup_sbi_column}' to '{primary_sbi_column}'\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Function to filter by industry\n",
    "def filter_by_industry(df, industry_column='BedrijfstakkenBranchesSBI2008', valid_industries=None):\n",
    "    \"\"\"\n",
    "    Filter the DataFrame by specific industries.\n",
    "    \n",
    "    Parameters:\n",
    "        df (DataFrame): The DataFrame to filter.\n",
    "        industry_column (str): Name of the industry column.\n",
    "        valid_industries (list): List of valid industries to keep.\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame: Filtered DataFrame.\n",
    "    \"\"\"\n",
    "    if valid_industries is None:\n",
    "        valid_industries = [\n",
    "            \"Q Gezondheids- en welzijnszorg\", \n",
    "            \"G Handel\", \n",
    "            \"C Industrie\", \n",
    "            # \"M Specialistische zakelijke diensten\", \n",
    "            # \"N Verhuur en overige zakelijke diensten\", \n",
    "            # \"O Openbaar bestuur en overheidsdiensten\"\n",
    "        ]\n",
    "    return df[df[industry_column].isin(valid_industries)]\n",
    "\n",
    "# Function to filter by year range\n",
    "def filter_by_year(df, year_column='Year', start_year=2006, end_year=2024):\n",
    "    \"\"\"\n",
    "    Filter the DataFrame by a range of years.\n",
    "    \n",
    "    Parameters:\n",
    "        df (DataFrame): The DataFrame to filter.\n",
    "        year_column (str): Name of the year column.\n",
    "        start_year (int): The start year (inclusive).\n",
    "        end_year (int): The end year (inclusive).\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame: Filtered DataFrame.\n",
    "    \"\"\"\n",
    "    return df[(df[year_column] >= start_year) & (df[year_column] <= end_year)]\n",
    "\n",
    "def clean_dataframe(df, id_column='ID', year_column='Year', quarter_column='Quarter', sbi_column='BedrijfstakkenBranchesSBI2008', sick_leave_column='80072ned_Ziekteverzuimpercentage_1', columns_to_drop=None):\n",
    "    \"\"\"\n",
    "    Cleans the DataFrame by reordering columns to have 'Year', 'Quarter', 'BedrijfstakkenBranchesSBI2008', and '80072ned_Ziekteverzuimpercentage_1' as the first four columns,\n",
    "    dropping specified columns, and removing duplicate rows.\n",
    "    \n",
    "    Parameters:\n",
    "        df (DataFrame): The DataFrame to clean.\n",
    "        year_column (str): The year column name. Default is 'Year'.\n",
    "        quarter_column (str): The quarter column name. Default is 'Quarter'.\n",
    "        sbi_column (str): The column name for SBI. Default is 'BedrijfstakkenBranchesSBI2008'.\n",
    "        sick_leave_column (str): The sick leave column name. Default is '80072ned_Ziekteverzuimpercentage_1'.\n",
    "        columns_to_drop (list): List of column names to drop. Default is ['ID', 'Perioden'].\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame: Cleaned DataFrame with reordered columns, specified columns dropped, and duplicates removed.\n",
    "    \"\"\"\n",
    "    if columns_to_drop is None:\n",
    "        columns_to_drop = ['ID', 'Perioden', 'Jaar', 'Kwartaal']\n",
    "\n",
    "    # Drop the specified columns\n",
    "    df = df.drop(columns=columns_to_drop, errors='ignore')\n",
    "\n",
    "    # Remove duplicate rows\n",
    "    df = df.drop_duplicates()\n",
    "\n",
    "    return df\n",
    "\n",
    "def group_and_sum(df, group_by_columns):\n",
    "    \"\"\"\n",
    "    Group the DataFrame by specified columns and sum the numeric values.\n",
    "    \n",
    "    Parameters:\n",
    "        df (DataFrame): The DataFrame to group.\n",
    "        group_by_columns (list): List of columns to group by (e.g., ['Year', 'Quarter', 'BedrijfstakkenBranchesSBI2008']).\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame: Grouped and summed DataFrame.\n",
    "    \"\"\"\n",
    "    # Group by the specified columns and sum the numeric columns\n",
    "    df = df.groupby(group_by_columns).sum(numeric_only=True).reset_index()\n",
    "    \n",
    "    return df\n",
    "\n",
    "def reorder_columns(df, year_column='Year', quarter_column='Quarter', \n",
    "                    sbi_column='BedrijfstakkenBranchesSBI2008', sick_leave_column='80072ned_Ziekteverzuimpercentage_1'):\n",
    "    \"\"\"\n",
    "    Reorders the DataFrame columns to place 'Year', 'Quarter', 'BedrijfstakkenBranchesSBI2008', \n",
    "    and '80072ned_Ziekteverzuimpercentage_1' as the first four columns, keeping remaining columns in their original order.\n",
    "    \n",
    "    Parameters:\n",
    "        df (DataFrame): The DataFrame to reorder.\n",
    "        year_column (str): The year column name.\n",
    "        quarter_column (str): The quarter column name.\n",
    "        sbi_column (str): The SBI column name.\n",
    "        sick_leave_column (str): The sick leave column name.\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame: DataFrame with reordered columns.\n",
    "    \"\"\"\n",
    "    # Define the preferred order of the first four columns\n",
    "    preferred_columns = [year_column, quarter_column, sbi_column, sick_leave_column]\n",
    "\n",
    "    # Collect remaining columns in their original order (excluding the preferred ones)\n",
    "    remaining_columns = [col for col in df.columns if col not in preferred_columns]\n",
    "\n",
    "    # Combine the preferred columns with the remaining ones\n",
    "    ordered_columns = preferred_columns + remaining_columns\n",
    "\n",
    "    # Reorder DataFrame\n",
    "    return df[ordered_columns]\n",
    "\n",
    "\n",
    "# Function to create lagged features\n",
    "def create_lagged_columns(df, column, lags, group_by='BedrijfstakkenBranchesSBI2008'):\n",
    "    \"\"\"\n",
    "    Creates lagged columns for the specified column in the DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "        df (DataFrame): Input DataFrame.\n",
    "        column (str): Column name to create lags for.\n",
    "        lags (int): Number of lagged columns to create.\n",
    "        group_by (str): Column name to group by before creating lags (default: 'BedrijfstakkenBranchesSBI2008').\n",
    "\n",
    "    Returns:\n",
    "        DataFrame: DataFrame with new lagged columns added.\n",
    "    \"\"\"\n",
    "    df = df.copy()  # Avoid modifying the original DataFrame\n",
    "    for lag in range(1, lags + 1):\n",
    "        lagged_col_name = f\"{column}_lag_{lag}\"\n",
    "        # Use .loc[] to assign the shifted values explicitly\n",
    "        df[lagged_col_name] = (\n",
    "            df.groupby(group_by)[column]\n",
    "            .shift(lag)\n",
    "            .reset_index(drop=True)  # Reset index to match df\n",
    "        )\n",
    "    return df\n",
    "\n",
    "\n",
    "# Modify the process_tables function to handle monthly data conversion and create lagged columns\n",
    "def process_tables_with_lags(tables, identifier_dict, lags=8):\n",
    "    \"\"\"\n",
    "    Process and combine multiple tables into a single DataFrame, and create lagged columns.\n",
    "\n",
    "    Parameters:\n",
    "        tables (list): List of DataFrames.\n",
    "        identifier_dict (dict): Dictionary of identifiers and their frequencies.\n",
    "        lags (int): Number of lagged columns to create for '80072ned_Ziekteverzuimpercentage_1'.\n",
    "\n",
    "    Returns:\n",
    "        DataFrame: The final combined DataFrame with lagged columns.\n",
    "    \"\"\"\n",
    "    processed_tables = []\n",
    "    \n",
    "    for i, table in enumerate(tables):\n",
    "        identifier = list(identifier_dict.keys())[i]\n",
    "        frequency = identifier_dict[identifier]\n",
    "\n",
    "        # If the frequency is monthly, convert the data to quarterly\n",
    "        if frequency == 'Maandelijks':\n",
    "            print(f\"Converting monthly data to quarterly for identifier: {identifier}\")\n",
    "            table = monthly_to_quarterly(table)\n",
    "\n",
    "        # Step 1: Process the 'Perioden' column\n",
    "        period_df = process_period_column(table)\n",
    "        \n",
    "        # Step 2: Fill missing 'BedrijfstakkenBranchesSBI2008' with 'BedrijfskenmerkenSBI2008'\n",
    "        sbi_df = rename_sbi_column(period_df)\n",
    "        \n",
    "        # Step 3: Filter by industry\n",
    "        industry_df = filter_by_industry(sbi_df)\n",
    "        \n",
    "        # Step 4: Filter by year range\n",
    "        year_df = filter_by_year(industry_df)\n",
    "        \n",
    "        # Step 5: Clean the DataFrame: reorder columns, drop unnecessary ones, and remove duplicates\n",
    "        clean_df = clean_dataframe(year_df)\n",
    "        \n",
    "        processed_tables.append(clean_df)\n",
    "    \n",
    "    # Concatenate all processed tables\n",
    "    concat_df = pd.concat(processed_tables, ignore_index=True)\n",
    "    \n",
    "    # Step 6: Group by 'Year', 'Quarter', and 'BedrijfstakkenBranchesSBI2008' and sum the numeric columns\n",
    "    grouped_df = group_and_sum(concat_df, ['Year', 'Quarter', 'BedrijfstakkenBranchesSBI2008'])\n",
    "    \n",
    "    # Step 7: Reorder columns for consistency\n",
    "    final_df = reorder_columns(grouped_df)\n",
    "\n",
    "    # Step 8: Create lagged columns for '80072ned_Ziekteverzuimpercentage_1'\n",
    "    final_df = create_lagged_columns(final_df, '80072ned_Ziekteverzuimpercentage_1', lags)\n",
    "\n",
    "    return final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load identifiers and frequencies from the JSON file\n",
    "with open('data/table_selection.json', 'r', encoding='utf-8') as json_file:\n",
    "    table_data = json.load(json_file)\n",
    "    identifier_dict = {entry['Identifier']: entry['Frequency'] for entry in table_data}\n",
    "\n",
    "# Generate file paths based on identifiers\n",
    "file_paths = [f'data/{identifier}.csv' for identifier in identifier_dict.keys()]\n",
    "\n",
    "# Excluded identifiers (if applicable)\n",
    "excluded_identifiers = []  # Define any identifiers you want to exclude\n",
    "\n",
    "# Load and process data, including creating lagged columns\n",
    "tables = load_csv_files(file_paths, identifier_dict, excluded_identifiers)\n",
    "final_df = process_tables_with_lags(tables, identifier_dict)\n",
    "\n",
    "# Display the first few rows of the final DataFrame\n",
    "final_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNMI & Covid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load KNMI data\n",
    "knmi_df = pd.read_csv('data/knmi_data.csv')\n",
    "\n",
    "# Define helper functions for adding Year_Quarter and merging KNMI data\n",
    "def add_year_quarter_column(df):\n",
    "    \"\"\"\n",
    "    Adds a 'Year_Quarter' column to the DataFrame in the format 'YYYY-QX' and removes 'Year' and 'Quarter'.\n",
    "    \n",
    "    Parameters:\n",
    "        df (DataFrame): Input DataFrame with 'Year' and 'Quarter' columns.\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame: Modified DataFrame with 'Year_Quarter' and without 'Year' and 'Quarter' columns.\n",
    "    \"\"\"\n",
    "    df['Year_Quarter'] = df['Year'].astype(int).astype(str) + '-Q' + df['Quarter'].astype(int).astype(str)\n",
    "    return df.drop(columns=['Year', 'Quarter'])\n",
    "\n",
    "# Define a function to label COVID-19 years\n",
    "def label_covid_period(row):\n",
    "    \"\"\"\n",
    "    Labels rows as part of the COVID-19 period based on the 'Year_Quarter' column.\n",
    "    \n",
    "    Parameters:\n",
    "        row (Series): A row of the DataFrame.\n",
    "    \n",
    "    Returns:\n",
    "        int: 1 if the row belongs to the COVID-19 period, 0 otherwise.\n",
    "    \"\"\"\n",
    "    if row['Year_Quarter'].startswith('2020') or \\\n",
    "       row['Year_Quarter'].startswith('2021') or \\\n",
    "       row['Year_Quarter'] == '2022-Q1':\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def merge_with_knmi_data(main_df, knmi_df):\n",
    "    \"\"\"\n",
    "    Merges the main DataFrame with KNMI weather data on 'Year_Quarter' and 'BedrijfstakkenBranchesSBI2008'.\n",
    "    \n",
    "    Parameters:\n",
    "        main_df (DataFrame): The primary DataFrame with 'Year_Quarter' and industry data.\n",
    "        knmi_df (DataFrame): The KNMI data with weather details by 'Year_Quarter'.\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame: The merged DataFrame with KNMI data.\n",
    "    \"\"\"\n",
    "    # Step 1: Create a DataFrame of unique industries from the main DataFrame\n",
    "    industries = main_df[['BedrijfstakkenBranchesSBI2008']].drop_duplicates()\n",
    "\n",
    "    # Step 2: Perform a Cartesian product to expand knmi_df across all industries\n",
    "    expanded_knmi = knmi_df.merge(industries, how='cross')\n",
    "\n",
    "    # Step 3: Merge the expanded knmi_df with the main DataFrame based on 'Year_Quarter' and industry\n",
    "    merged_df = main_df.merge(expanded_knmi, on=['Year_Quarter', 'BedrijfstakkenBranchesSBI2008'], how='left')\n",
    "    \n",
    "    return merged_df\n",
    "\n",
    "# Add Year_Quarter column to final_df\n",
    "final_df = add_year_quarter_column(final_df)\n",
    "\n",
    "# Apply the function to create the covid_19 column\n",
    "final_df['covid_19'] = final_df.apply(label_covid_period, axis=1)\n",
    "\n",
    "# Merge final_df with KNMI data\n",
    "final_df_with_knmi = merge_with_knmi_data(final_df, knmi_df)\n",
    "\n",
    "# Save the final DataFrame with KNMI data to a CSV file or display the head for verification\n",
    "final_df_with_knmi.to_csv('data/merged_table.csv', index=False)\n",
    "final_df_with_knmi.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
