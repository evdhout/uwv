{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import cbsodata\n",
    "import json\n",
    "import re\n",
    "import os\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary of Identifiers and Frequencies:\n",
      "Identifier: 85928NED, Frequency: Perkwartaal\n",
      "Identifier: 80072ned, Frequency: Perkwartaal\n",
      "Identifier: 81589NED, Frequency: Perkwartaal\n",
      "Identifier: 83147NED, Frequency: Perkwartaal\n",
      "Identifier: 81588NED, Frequency: Perkwartaal\n",
      "Identifier: 83149NED, Frequency: Perkwartaal\n",
      "Identifier: 83148NED, Frequency: Perkwartaal\n"
     ]
    }
   ],
   "source": [
    "# Load the data from the JSON file\n",
    "with open('data/table_selection.json', 'r', encoding='utf-8') as json_file:\n",
    "    table_data = json.load(json_file)\n",
    "\n",
    "# Create a dictionary to store the identifiers and their frequencies\n",
    "identifier_freq_dict = {}\n",
    "\n",
    "# Loop through the data and extract the identifier and frequency for each entry\n",
    "for entry in table_data:\n",
    "    identifier = entry.get('Identifier', 'N/A')\n",
    "    frequency = entry.get('Frequency', 'N/A')\n",
    "    \n",
    "    # Add the identifier and frequency to the dictionary\n",
    "    identifier_freq_dict[identifier] = frequency\n",
    "\n",
    "# Print the dictionary of identifiers and their frequencies\n",
    "print(\"Dictionary of Identifiers and Frequencies:\")\n",
    "for identifier, frequency in identifier_freq_dict.items():\n",
    "    print(f\"Identifier: {identifier}, Frequency: {frequency}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping data/85928NED.csv because it already exists.\n",
      "Skipping data/80072ned.csv because it already exists.\n",
      "Skipping data/81589NED.csv because it already exists.\n",
      "Skipping data/83147NED.csv because it already exists.\n",
      "Skipping data/81588NED.csv because it already exists.\n",
      "Skipping data/83149NED.csv because it already exists.\n",
      "Skipping data/83148NED.csv because it already exists.\n"
     ]
    }
   ],
   "source": [
    "def fetch_and_save_tables(identifiers, output_folder='data'):\n",
    "    \"\"\"\n",
    "    Fetches data for each table identifier using `cbsodata.get_data()` and saves it to a CSV file,\n",
    "    skipping files that already exist.\n",
    "    \n",
    "    Parameters:\n",
    "        identifiers (list): List of table identifiers to fetch data for.\n",
    "        output_folder (str): The folder where the CSV files will be saved (default is 'data').\n",
    "    \n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    # Ensure the output folder exists\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "\n",
    "    for identifier in identifiers:\n",
    "        # Define the output CSV file path\n",
    "        output_file = f'{output_folder}/{identifier}.csv'\n",
    "        \n",
    "        # Check if the file already exists\n",
    "        if os.path.exists(output_file):\n",
    "            print(f\"Skipping {output_file} because it already exists.\")\n",
    "            continue\n",
    "        \n",
    "        # Fetch data for the current table identifier\n",
    "        print(f\"Fetching data for table identifier: {identifier}\")\n",
    "        data = pd.DataFrame(cbsodata.get_data(identifier))\n",
    "        \n",
    "        # Save the DataFrame to CSV\n",
    "        data.to_csv(output_file, index=False)\n",
    "        \n",
    "        # Print success message\n",
    "        print(f\"Data for {identifier} saved to {output_file}\")\n",
    "\n",
    "# Example usage\n",
    "fetch_and_save_tables(identifier_freq_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load CSV files\n",
    "def load_csv_files(file_paths):\n",
    "    \"\"\"\n",
    "    Load multiple CSV files into DataFrames and prefix the column names with the file name.\n",
    "    \n",
    "    Parameters:\n",
    "        file_paths (list): List of file paths to CSV files.\n",
    "    \n",
    "    Returns:\n",
    "        list: List of DataFrames with prefixed column names.\n",
    "    \"\"\"\n",
    "    dataframes = []\n",
    "    \n",
    "    for file_path in file_paths:\n",
    "        # Extract the filename without the extension to use as a prefix\n",
    "        file_name = file_path.split('/')[-1].split('.')[0]\n",
    "        \n",
    "        # Load the CSV file into a DataFrame\n",
    "        df = pd.read_csv(file_path)\n",
    "        \n",
    "        # Prefix the column names with the filename\n",
    "        df = df.add_prefix(f\"{file_name}_\")\n",
    "        \n",
    "        # Special handling for 'Perioden' and 'SBI' columns, which shouldn't be prefixed\n",
    "        if f\"{file_name}_Perioden\" in df.columns:\n",
    "            df = df.rename(columns={f\"{file_name}_Perioden\": 'Perioden'})  # Keep 'Perioden' without prefix\n",
    "        if f\"{file_name}_BedrijfstakkenBranchesSBI2008\" in df.columns:\n",
    "            df = df.rename(columns={f\"{file_name}_BedrijfstakkenBranchesSBI2008\": 'BedrijfstakkenBranchesSBI2008'})  # Keep 'BedrijfstakkenBranchesSBI2008' without prefix\n",
    "        if f\"{file_name}_ID\" in df.columns:\n",
    "            df = df.rename(columns={f\"{file_name}_ID\": 'ID'})  # Keep 'ID' without prefix\n",
    "        if f\"{file_name}_Jaar\" in df.columns:\n",
    "            df = df.rename(columns={f\"{file_name}_Jaar\": 'Jaar'})  # Keep 'Jaar' without prefix\n",
    "        if f\"{file_name}_Kwartaal\" in df.columns:\n",
    "            df = df.rename(columns={f\"{file_name}_Kwartaal\": 'Kwartaal'})  # Keep 'Kwartaal' without prefix\n",
    "        \n",
    "        # Append to the list of DataFrames\n",
    "        dataframes.append(df)\n",
    "    \n",
    "    return dataframes\n",
    "\n",
    "# Function to process the 'Perioden' column\n",
    "def process_period_column(df, perioden_column='Perioden', year_column='Year', quarter_column='Quarter'):\n",
    "    \"\"\"\n",
    "    Process the 'Perioden' column to extract the latest year and quarter.\n",
    "    \n",
    "    Parameters:\n",
    "        df (DataFrame): DataFrame with 'Perioden' column.\n",
    "        perioden_column (str): Name of the period column.\n",
    "        year_column (str): Name of the column for extracted year.\n",
    "        quarter_column (str): Name of the column for extracted quarter.\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame: DataFrame with new 'Year' and 'Quarter' columns.\n",
    "    \"\"\"\n",
    "    # Extract latest year and quarter from 'Perioden' column\n",
    "    df[[year_column, quarter_column]] = df[perioden_column].apply(lambda x: pd.Series(extract_latest_year_and_quarter(x)))\n",
    "    return df\n",
    "\n",
    "# Helper function to extract latest year and quarter\n",
    "def extract_latest_year_and_quarter(period_text):\n",
    "    \"\"\"\n",
    "    Extracts the latest year and quarter from a period that may contain a date range (e.g., \"2023 april - 2024 maart\").\n",
    "    \n",
    "    Parameters:\n",
    "        period_text (str): The period string to process.\n",
    "    \n",
    "    Returns:\n",
    "        tuple: A tuple containing the latest year and quarter.\n",
    "    \"\"\"\n",
    "    # Regular expression to capture year and month/quarter references\n",
    "    match = re.findall(r'(\\d{4})\\s*(\\w+)', period_text)\n",
    "    \n",
    "    if match:\n",
    "        # Take the last match in the range (latest part of the period)\n",
    "        latest_year, latest_period_part = match[-1]\n",
    "        latest_year = int(latest_year)\n",
    "        \n",
    "        # Determine the corresponding quarter for the latest period part (month or quarter)\n",
    "        latest_quarter = extract_quarter(latest_period_part)\n",
    "        \n",
    "        return latest_year, latest_quarter\n",
    "    else:\n",
    "        # Return None if no valid year/quarter is found\n",
    "        return None, None\n",
    "\n",
    "# Helper function to determine the quarter based on months or quarter phrases like '3e kwartaal'\n",
    "def extract_quarter(period_part):\n",
    "    \"\"\"\n",
    "    Extracts the quarter from the period part (e.g., based on months or quarter keywords).\n",
    "    \n",
    "    Parameters:\n",
    "        period_part (str): The part of the period string after the year.\n",
    "    \n",
    "    Returns:\n",
    "        int: The corresponding quarter (1 to 4), or None if no valid quarter is found.\n",
    "    \"\"\"\n",
    "    # Handle month-based quarters\n",
    "    if any(month in period_part for month in ['januari', 'februari', 'maart']):\n",
    "        return 1\n",
    "    elif any(month in period_part for month in ['april', 'mei', 'juni']):\n",
    "        return 2\n",
    "    elif any(month in period_part for month in ['juli', 'augustus', 'september']):\n",
    "        return 3\n",
    "    elif any(month in period_part for month in ['oktober', 'november', 'december']):\n",
    "        return 4\n",
    "    \n",
    "    # Handle phrases like '1e kwartaal', '2e kwartaal', etc.\n",
    "    if '1e' in period_part:\n",
    "        return 1\n",
    "    elif '2e' in period_part:\n",
    "        return 2\n",
    "    elif '3e' in period_part:\n",
    "        return 3\n",
    "    elif '4e' in period_part:\n",
    "        return 4\n",
    "    \n",
    "    # Return None if no valid quarter is found\n",
    "    return None\n",
    "\n",
    "def rename_sbi_column(df, primary_sbi_column='BedrijfstakkenBranchesSBI2008', backup_sbi_column='BedrijfskenmerkenSBI2008'):\n",
    "    \"\"\"\n",
    "    Renames the 'BedrijfskenmerkenSBI2008' column to 'BedrijfstakkenBranchesSBI2008' if the primary column does not exist.\n",
    "    \n",
    "    Parameters:\n",
    "        df (DataFrame): The DataFrame to process.\n",
    "        primary_sbi_column (str): The desired primary SBI column name. Default is 'BedrijfstakkenBranchesSBI2008'.\n",
    "        backup_sbi_column (str): The backup SBI column to rename. Default is 'BedrijfskenmerkenSBI2008'.\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame: Updated DataFrame with the renamed column.\n",
    "    \"\"\"\n",
    "    # Check if the primary column does not exist and the backup column does exist\n",
    "    if primary_sbi_column not in df.columns and backup_sbi_column in df.columns:\n",
    "        # Rename 'BedrijfskenmerkenSBI2008' to 'BedrijfstakkenBranchesSBI2008'\n",
    "        df = df.rename(columns={backup_sbi_column: primary_sbi_column})\n",
    "        print(f\"Renamed '{backup_sbi_column}' to '{primary_sbi_column}'\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Function to filter by industry\n",
    "def filter_by_industry(df, industry_column='BedrijfstakkenBranchesSBI2008', valid_industries=None):\n",
    "    \"\"\"\n",
    "    Filter the DataFrame by specific industries.\n",
    "    \n",
    "    Parameters:\n",
    "        df (DataFrame): The DataFrame to filter.\n",
    "        industry_column (str): Name of the industry column.\n",
    "        valid_industries (list): List of valid industries to keep.\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame: Filtered DataFrame.\n",
    "    \"\"\"\n",
    "    if valid_industries is None:\n",
    "        valid_industries = [\n",
    "            \"Q Gezondheids- en welzijnszorg\", \n",
    "            \"G Handel\", \n",
    "            \"C Industrie\", \n",
    "            \"M Specialistische zakelijke diensten\", \n",
    "            \"N Verhuur en overige zakelijke diensten\", \n",
    "            \"O Openbaar bestuur en overheidsdiensten\"\n",
    "        ]\n",
    "    return df[df[industry_column].isin(valid_industries)]\n",
    "\n",
    "# Function to filter by year range\n",
    "def filter_by_year(df, year_column='Year', start_year=2008, end_year=2022):\n",
    "    \"\"\"\n",
    "    Filter the DataFrame by a range of years.\n",
    "    \n",
    "    Parameters:\n",
    "        df (DataFrame): The DataFrame to filter.\n",
    "        year_column (str): Name of the year column.\n",
    "        start_year (int): The start year (inclusive).\n",
    "        end_year (int): The end year (inclusive).\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame: Filtered DataFrame.\n",
    "    \"\"\"\n",
    "    return df[(df[year_column] >= start_year) & (df[year_column] <= end_year)]\n",
    "\n",
    "def clean_dataframe(df, id_column='ID', year_column='Year', quarter_column='Quarter', sbi_column='BedrijfstakkenBranchesSBI2008', sick_leave_column='80072ned_Ziekteverzuimpercentage_1', columns_to_drop=None):\n",
    "    \"\"\"\n",
    "    Cleans the DataFrame by reordering columns to have 'Year', 'Quarter', 'BedrijfstakkenBranchesSBI2008', and '80072ned_Ziekteverzuimpercentage_1' as the first four columns,\n",
    "    dropping specified columns, and removing duplicate rows.\n",
    "    \n",
    "    Parameters:\n",
    "        df (DataFrame): The DataFrame to clean.\n",
    "        year_column (str): The year column name. Default is 'Year'.\n",
    "        quarter_column (str): The quarter column name. Default is 'Quarter'.\n",
    "        sbi_column (str): The column name for SBI. Default is 'BedrijfstakkenBranchesSBI2008'.\n",
    "        sick_leave_column (str): The sick leave column name. Default is '80072ned_Ziekteverzuimpercentage_1'.\n",
    "        columns_to_drop (list): List of column names to drop. Default is ['ID', 'Perioden'].\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame: Cleaned DataFrame with reordered columns, specified columns dropped, and duplicates removed.\n",
    "    \"\"\"\n",
    "    if columns_to_drop is None:\n",
    "        columns_to_drop = ['ID', 'Perioden', 'Jaar', 'Kwartaal']\n",
    "\n",
    "    # Define the preferred order of the first four columns\n",
    "    preferred_columns = [year_column, quarter_column, sbi_column, sick_leave_column]\n",
    "\n",
    "    # Collect remaining columns in their original order (excluding the preferred ones)\n",
    "    remaining_columns = [col for col in df.columns if col not in preferred_columns]\n",
    "\n",
    "    # Combine the preferred columns with the remaining ones\n",
    "    ordered_columns = preferred_columns + remaining_columns\n",
    "\n",
    "    # Reorder DataFrame\n",
    "    df = df[ordered_columns]\n",
    "\n",
    "    # Drop the specified columns\n",
    "    df = df.drop(columns=columns_to_drop, errors='ignore')\n",
    "\n",
    "    # Remove duplicate rows\n",
    "    df = df.drop_duplicates()\n",
    "\n",
    "    return df\n",
    "\n",
    "def group_and_sum(df, group_by_columns):\n",
    "    \"\"\"\n",
    "    Group the DataFrame by specified columns and sum the numeric values.\n",
    "    \n",
    "    Parameters:\n",
    "        df (DataFrame): The DataFrame to group.\n",
    "        group_by_columns (list): List of columns to group by (e.g., ['Year', 'Quarter', 'BedrijfstakkenBranchesSBI2008']).\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame: Grouped and summed DataFrame.\n",
    "    \"\"\"\n",
    "    # Group by the specified columns and sum the numeric columns\n",
    "    df = df.groupby(group_by_columns).sum(numeric_only=True).reset_index()\n",
    "    \n",
    "    return df\n",
    "\n",
    "def process_tables(tables):\n",
    "    \"\"\"\n",
    "    Process and combine multiple tables into a single DataFrame by:\n",
    "    - Processing the 'Perioden' column to extract 'Year' and 'Quarter'\n",
    "    - Filtering by specific industries and year range\n",
    "    - Reordering columns to have 'Year' and 'Quarter' after 'ID'\n",
    "    - Dropping unnecessary columns\n",
    "    - Removing duplicates\n",
    "    - Grouping by 'Year', 'Quarter', and 'BedrijfstakkenBranchesSBI2008' and summing the data\n",
    "    \n",
    "    Parameters:\n",
    "        tables (list): List of DataFrames.\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame: The final combined DataFrame.\n",
    "    \"\"\"\n",
    "    # Concatenate the list of tables into one DataFrame\n",
    "    concat_df = pd.concat(tables, ignore_index=True)\n",
    "    \n",
    "    # Step 1: Process the 'Perioden' column\n",
    "    period_df = process_period_column(concat_df)\n",
    "    \n",
    "    # Step 2: Fill missing 'BedrijfstakkenBranchesSBI2008' with 'BedrijfskenmerkenSBI2008'\n",
    "    sbi_df = rename_sbi_column(period_df)\n",
    "    \n",
    "    # Step 3: Filter by industry\n",
    "    industry_df = filter_by_industry(sbi_df)\n",
    "    \n",
    "    # Step 4: Filter by year range (2008 to 2022)\n",
    "    year_df = filter_by_year(industry_df)\n",
    "    \n",
    "    # Step 5: Clean the DataFrame: reorder columns, drop unnecessary ones, and remove duplicates\n",
    "    clean_df = clean_dataframe(year_df)\n",
    "    \n",
    "    # Step 6: Group by 'Year', 'Quarter', and 'BedrijfstakkenBranchesSBI2008' and sum the numeric columns\n",
    "    final_df = group_and_sum(clean_df, ['Year', 'Quarter', 'BedrijfstakkenBranchesSBI2008'])\n",
    "    \n",
    "    return final_df\n",
    "\n",
    "# Load the identifiers from the JSON file\n",
    "with open('data/table_selection.json', 'r', encoding='utf-8') as json_file:\n",
    "    table_data = json.load(json_file)\n",
    "    identifiers = [entry['Identifier'] for entry in table_data]\n",
    "\n",
    "# Dynamically generate the file paths using the identifiers\n",
    "file_paths = [f'data/{identifier}.csv' for identifier in identifiers]\n",
    "\n",
    "# Load and process the data\n",
    "tables = load_csv_files(file_paths)\n",
    "final_df = process_tables(tables)\n",
    "\n",
    "# Save the final DataFrame to a CSV file\n",
    "final_df.to_csv('data/merged_tables.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial DataFrame:\n",
      "   ID      BedrijfstakkenBranchesSBI2008          Perioden  TotaalBedrijven_1  \\\n",
      "0   0  A-U Alle economische activiteiten  2007 1e kwartaal           987345.0   \n",
      "1   1  A-U Alle economische activiteiten  2007 2e kwartaal          1012210.0   \n",
      "2   2  A-U Alle economische activiteiten  2007 3e kwartaal          1040415.0   \n",
      "3   3  A-U Alle economische activiteiten  2007 4e kwartaal          1057860.0   \n",
      "4   4  A-U Alle economische activiteiten  2008 1e kwartaal          1087470.0   \n",
      "\n",
      "   k_1WerkzaamPersoon_2  k_2WerkzamePersonen_3  k_3Tot5WerkzamePersonen_4  \\\n",
      "0              619565.0               158445.0                    81295.0   \n",
      "1              641795.0               159225.0                    82530.0   \n",
      "2              672410.0               157220.0                    82565.0   \n",
      "3              687525.0               160035.0                    82930.0   \n",
      "4              720745.0               158780.0                    81475.0   \n",
      "\n",
      "   k_5Tot10WerkzamePersonen_5  k_10Tot20WerkzamePersonen_6  \\\n",
      "0                     60100.0                      32635.0   \n",
      "1                     60370.0                      32790.0   \n",
      "2                     60085.0                      32785.0   \n",
      "3                     59680.0                      32620.0   \n",
      "4                     59135.0                      32555.0   \n",
      "\n",
      "   k_20Tot50WerkzamePersonen_7  ...  MaatschapSamenwerking_23  \\\n",
      "0                      20280.0  ...                   47365.0   \n",
      "1                      20295.0  ...                   47290.0   \n",
      "2                      20285.0  ...                   44370.0   \n",
      "3                      20200.0  ...                   44405.0   \n",
      "4                      20035.0  ...                   44495.0   \n",
      "\n",
      "   VennootschapOnderFirmaVOF_24  CommanditaireVennootschapCV_25  \\\n",
      "0                      125220.0                          7180.0   \n",
      "1                      125560.0                          7085.0   \n",
      "2                      125075.0                          7085.0   \n",
      "3                      128075.0                          7220.0   \n",
      "4                      126220.0                          7105.0   \n",
      "\n",
      "   TotaalRechtspersonen_26  BeslotenVennootschapBV_27  \\\n",
      "0                 284880.0                   243290.0   \n",
      "1                 291490.0                   249790.0   \n",
      "2                 294640.0                   253150.0   \n",
      "3                 297830.0                   256420.0   \n",
      "4                 312375.0                   270615.0   \n",
      "\n",
      "   NaamlozeVennootschapNV_28  CooperatieveVereniging_29  \\\n",
      "0                     1060.0                     1285.0   \n",
      "1                     1050.0                     1480.0   \n",
      "2                     1000.0                     1345.0   \n",
      "3                      990.0                     1350.0   \n",
      "4                      990.0                     1360.0   \n",
      "\n",
      "   VerenigingOfStichting_30  Overheid_31  OverigOfOnbekend_32  \n",
      "0                   35160.0       1105.0               2980.0  \n",
      "1                   35050.0       1090.0               3030.0  \n",
      "2                   34980.0       1070.0               3100.0  \n",
      "3                   34900.0       1050.0               3125.0  \n",
      "4                   35185.0       1050.0               3175.0  \n",
      "\n",
      "[5 rows x 35 columns]\n",
      "\n",
      "DataFrame after load_csv_files equivalent processing:\n",
      "   ID      BedrijfstakkenBranchesSBI2008          Perioden  \\\n",
      "0   0  A-U Alle economische activiteiten  2007 1e kwartaal   \n",
      "1   1  A-U Alle economische activiteiten  2007 2e kwartaal   \n",
      "2   2  A-U Alle economische activiteiten  2007 3e kwartaal   \n",
      "3   3  A-U Alle economische activiteiten  2007 4e kwartaal   \n",
      "4   4  A-U Alle economische activiteiten  2008 1e kwartaal   \n",
      "\n",
      "   81588NED_TotaalBedrijven_1  81588NED_k_1WerkzaamPersoon_2  \\\n",
      "0                    987345.0                       619565.0   \n",
      "1                   1012210.0                       641795.0   \n",
      "2                   1040415.0                       672410.0   \n",
      "3                   1057860.0                       687525.0   \n",
      "4                   1087470.0                       720745.0   \n",
      "\n",
      "   81588NED_k_2WerkzamePersonen_3  81588NED_k_3Tot5WerkzamePersonen_4  \\\n",
      "0                        158445.0                             81295.0   \n",
      "1                        159225.0                             82530.0   \n",
      "2                        157220.0                             82565.0   \n",
      "3                        160035.0                             82930.0   \n",
      "4                        158780.0                             81475.0   \n",
      "\n",
      "   81588NED_k_5Tot10WerkzamePersonen_5  81588NED_k_10Tot20WerkzamePersonen_6  \\\n",
      "0                              60100.0                               32635.0   \n",
      "1                              60370.0                               32790.0   \n",
      "2                              60085.0                               32785.0   \n",
      "3                              59680.0                               32620.0   \n",
      "4                              59135.0                               32555.0   \n",
      "\n",
      "   81588NED_k_20Tot50WerkzamePersonen_7  ...  \\\n",
      "0                               20280.0  ...   \n",
      "1                               20295.0  ...   \n",
      "2                               20285.0  ...   \n",
      "3                               20200.0  ...   \n",
      "4                               20035.0  ...   \n",
      "\n",
      "   81588NED_MaatschapSamenwerking_23  81588NED_VennootschapOnderFirmaVOF_24  \\\n",
      "0                            47365.0                               125220.0   \n",
      "1                            47290.0                               125560.0   \n",
      "2                            44370.0                               125075.0   \n",
      "3                            44405.0                               128075.0   \n",
      "4                            44495.0                               126220.0   \n",
      "\n",
      "   81588NED_CommanditaireVennootschapCV_25  81588NED_TotaalRechtspersonen_26  \\\n",
      "0                                   7180.0                          284880.0   \n",
      "1                                   7085.0                          291490.0   \n",
      "2                                   7085.0                          294640.0   \n",
      "3                                   7220.0                          297830.0   \n",
      "4                                   7105.0                          312375.0   \n",
      "\n",
      "   81588NED_BeslotenVennootschapBV_27  81588NED_NaamlozeVennootschapNV_28  \\\n",
      "0                            243290.0                              1060.0   \n",
      "1                            249790.0                              1050.0   \n",
      "2                            253150.0                              1000.0   \n",
      "3                            256420.0                               990.0   \n",
      "4                            270615.0                               990.0   \n",
      "\n",
      "   81588NED_CooperatieveVereniging_29  81588NED_VerenigingOfStichting_30  \\\n",
      "0                              1285.0                            35160.0   \n",
      "1                              1480.0                            35050.0   \n",
      "2                              1345.0                            34980.0   \n",
      "3                              1350.0                            34900.0   \n",
      "4                              1360.0                            35185.0   \n",
      "\n",
      "   81588NED_Overheid_31  81588NED_OverigOfOnbekend_32  \n",
      "0                1105.0                        2980.0  \n",
      "1                1090.0                        3030.0  \n",
      "2                1070.0                        3100.0  \n",
      "3                1050.0                        3125.0  \n",
      "4                1050.0                        3175.0  \n",
      "\n",
      "[5 rows x 35 columns]\n",
      "\n",
      "DataFrame after processing 'Perioden' column:\n",
      "           Perioden  Year  Quarter\n",
      "0  2007 1e kwartaal  2007        1\n",
      "1  2007 2e kwartaal  2007        2\n",
      "2  2007 3e kwartaal  2007        3\n",
      "3  2007 4e kwartaal  2007        4\n",
      "4  2008 1e kwartaal  2008        1\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for -: 'NoneType' and 'int'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 30\u001b[0m\n\u001b[1;32m     28\u001b[0m frequency \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMaandelijks\u001b[39m\u001b[38;5;124m'\u001b[39m  \u001b[38;5;66;03m# Replace with the actual frequency from your identifier dictionary if needed\u001b[39;00m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m frequency \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMaandelijks\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m---> 30\u001b[0m     df \u001b[38;5;241m=\u001b[39m \u001b[43mmonthly_to_quarterly\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mDataFrame after monthly_to_quarterly conversion:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     32\u001b[0m     \u001b[38;5;28mprint\u001b[39m(df\u001b[38;5;241m.\u001b[39mhead())\n",
      "Cell \u001b[0;32mIn[20], line 140\u001b[0m, in \u001b[0;36mmonthly_to_quarterly\u001b[0;34m(df, period_column, value_columns)\u001b[0m\n\u001b[1;32m    137\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMonth\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df[period_column]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: extract_month(x))\n\u001b[1;32m    139\u001b[0m \u001b[38;5;66;03m# Create a 'Quarter' column based on the month\u001b[39;00m\n\u001b[0;32m--> 140\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mQuarter\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mMonth\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    142\u001b[0m \u001b[38;5;66;03m# Group by 'Year' and 'Quarter' and sum the value columns\u001b[39;00m\n\u001b[1;32m    143\u001b[0m quarterly_df \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mgroupby([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mYear\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mQuarter\u001b[39m\u001b[38;5;124m'\u001b[39m])[value_columns]\u001b[38;5;241m.\u001b[39msum()\u001b[38;5;241m.\u001b[39mreset_index()\n",
      "File \u001b[0;32m~/Documents/repos/uwv/.venv/lib/python3.12/site-packages/pandas/core/series.py:4924\u001b[0m, in \u001b[0;36mSeries.apply\u001b[0;34m(self, func, convert_dtype, args, by_row, **kwargs)\u001b[0m\n\u001b[1;32m   4789\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\n\u001b[1;32m   4790\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   4791\u001b[0m     func: AggFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4796\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   4797\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[1;32m   4798\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   4799\u001b[0m \u001b[38;5;124;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[1;32m   4800\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4915\u001b[0m \u001b[38;5;124;03m    dtype: float64\u001b[39;00m\n\u001b[1;32m   4916\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m   4917\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSeriesApply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   4918\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4919\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4920\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconvert_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4921\u001b[0m \u001b[43m        \u001b[49m\u001b[43mby_row\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mby_row\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4922\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4923\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m-> 4924\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/repos/uwv/.venv/lib/python3.12/site-packages/pandas/core/apply.py:1427\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1424\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_compat()\n\u001b[1;32m   1426\u001b[0m \u001b[38;5;66;03m# self.func is Callable\u001b[39;00m\n\u001b[0;32m-> 1427\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/repos/uwv/.venv/lib/python3.12/site-packages/pandas/core/apply.py:1507\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1501\u001b[0m \u001b[38;5;66;03m# row-wise access\u001b[39;00m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# apply doesn't have a `na_action` keyword and for backward compat reasons\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m \u001b[38;5;66;03m# we need to give `na_action=\"ignore\"` for categorical data.\u001b[39;00m\n\u001b[1;32m   1504\u001b[0m \u001b[38;5;66;03m# TODO: remove the `na_action=\"ignore\"` when that default has been changed in\u001b[39;00m\n\u001b[1;32m   1505\u001b[0m \u001b[38;5;66;03m#  Categorical (GH51645).\u001b[39;00m\n\u001b[1;32m   1506\u001b[0m action \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj\u001b[38;5;241m.\u001b[39mdtype, CategoricalDtype) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1507\u001b[0m mapped \u001b[38;5;241m=\u001b[39m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_map_values\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1508\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmapper\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcurried\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\n\u001b[1;32m   1509\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1511\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[38;5;241m0\u001b[39m], ABCSeries):\n\u001b[1;32m   1512\u001b[0m     \u001b[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[1;32m   1513\u001b[0m     \u001b[38;5;66;03m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[1;32m   1514\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_constructor_expanddim(\u001b[38;5;28mlist\u001b[39m(mapped), index\u001b[38;5;241m=\u001b[39mobj\u001b[38;5;241m.\u001b[39mindex)\n",
      "File \u001b[0;32m~/Documents/repos/uwv/.venv/lib/python3.12/site-packages/pandas/core/base.py:921\u001b[0m, in \u001b[0;36mIndexOpsMixin._map_values\u001b[0;34m(self, mapper, na_action, convert)\u001b[0m\n\u001b[1;32m    918\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arr, ExtensionArray):\n\u001b[1;32m    919\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mmap(mapper, na_action\u001b[38;5;241m=\u001b[39mna_action)\n\u001b[0;32m--> 921\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43malgorithms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_action\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/repos/uwv/.venv/lib/python3.12/site-packages/pandas/core/algorithms.py:1743\u001b[0m, in \u001b[0;36mmap_array\u001b[0;34m(arr, mapper, na_action, convert)\u001b[0m\n\u001b[1;32m   1741\u001b[0m values \u001b[38;5;241m=\u001b[39m arr\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m na_action \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1743\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_infer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1745\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mmap_infer_mask(\n\u001b[1;32m   1746\u001b[0m         values, mapper, mask\u001b[38;5;241m=\u001b[39misna(values)\u001b[38;5;241m.\u001b[39mview(np\u001b[38;5;241m.\u001b[39muint8), convert\u001b[38;5;241m=\u001b[39mconvert\n\u001b[1;32m   1747\u001b[0m     )\n",
      "File \u001b[0;32mlib.pyx:2972\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "Cell \u001b[0;32mIn[20], line 140\u001b[0m, in \u001b[0;36mmonthly_to_quarterly.<locals>.<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    137\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMonth\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df[period_column]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: extract_month(x))\n\u001b[1;32m    139\u001b[0m \u001b[38;5;66;03m# Create a 'Quarter' column based on the month\u001b[39;00m\n\u001b[0;32m--> 140\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mQuarter\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMonth\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: (\u001b[43mx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m) \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m \u001b[38;5;241m3\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    142\u001b[0m \u001b[38;5;66;03m# Group by 'Year' and 'Quarter' and sum the value columns\u001b[39;00m\n\u001b[1;32m    143\u001b[0m quarterly_df \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mgroupby([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mYear\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mQuarter\u001b[39m\u001b[38;5;124m'\u001b[39m])[value_columns]\u001b[38;5;241m.\u001b[39msum()\u001b[38;5;241m.\u001b[39mreset_index()\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for -: 'NoneType' and 'int'"
     ]
    }
   ],
   "source": [
    "# Load one specific table file path for testing\n",
    "file_path = 'data/81588NED.csv'  # Replace 'your_table.csv' with the actual file name\n",
    "file_name = file_path.split('/')[-1].split('.')[0]\n",
    "\n",
    "# Load the single table\n",
    "df = pd.read_csv(file_path)\n",
    "print(\"Initial DataFrame:\")\n",
    "print(df.head())\n",
    "\n",
    "# Step 1: Apply prefixing and special column renaming\n",
    "df = df.add_prefix(f\"{file_name}_\")\n",
    "df = df.rename(columns={\n",
    "    f\"{file_name}_Perioden\": 'Perioden',\n",
    "    f\"{file_name}_BedrijfstakkenBranchesSBI2008\": 'BedrijfstakkenBranchesSBI2008',\n",
    "    f\"{file_name}_ID\": 'ID',\n",
    "    f\"{file_name}_Jaar\": 'Jaar',\n",
    "    f\"{file_name}_Kwartaal\": 'Kwartaal'\n",
    "})\n",
    "print(\"\\nDataFrame after load_csv_files equivalent processing:\")\n",
    "print(df.head())\n",
    "\n",
    "# Step 2: Process 'Perioden' to extract 'Year' and 'Quarter'\n",
    "df = process_period_column(df)\n",
    "print(\"\\nDataFrame after processing 'Perioden' column:\")\n",
    "print(df[['Perioden', 'Year', 'Quarter']].head())\n",
    "\n",
    "# Step 3: If monthly data, convert to quarterly (based on a mock frequency value for testing)\n",
    "frequency = 'Maandelijks'  # Replace with the actual frequency from your identifier dictionary if needed\n",
    "if frequency == 'Maandelijks':\n",
    "    df = monthly_to_quarterly(df)\n",
    "    print(\"\\nDataFrame after monthly_to_quarterly conversion:\")\n",
    "    print(df.head())\n",
    "\n",
    "# Step 4: Rename SBI column if needed\n",
    "df = rename_sbi_column(df)\n",
    "print(\"\\nDataFrame after renaming SBI column:\")\n",
    "print(df.head())\n",
    "\n",
    "# Step 5: Filter by industry\n",
    "df = filter_by_industry(df)\n",
    "print(\"\\nDataFrame after filtering by industry:\")\n",
    "print(df.head())\n",
    "\n",
    "# Step 6: Filter by year range\n",
    "df = filter_by_year(df, start_year=2008, end_year=2022)\n",
    "print(\"\\nDataFrame after filtering by year range:\")\n",
    "print(df.head())\n",
    "\n",
    "# Step 7: Clean the DataFrame\n",
    "df = clean_dataframe(df)\n",
    "print(\"\\nDataFrame after cleaning:\")\n",
    "print(df.head())\n",
    "\n",
    "# Step 8: Reorder columns\n",
    "df = reorder_columns(df)\n",
    "print(\"\\nDataFrame after reordering columns:\")\n",
    "print(df.head())\n",
    "\n",
    "# Step 9: Group and sum the data\n",
    "df = group_and_sum(df, ['Year', 'Quarter', 'BedrijfstakkenBranchesSBI2008'])\n",
    "print(\"\\nFinal DataFrame after grouping and summing:\")\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
