{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import cbsodata\n",
    "import json\n",
    "import re\n",
    "import os\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of Identifiers: ['83451NED', '85928NED', '85663NED', '80072ned', '81589NED', '83147NED', '81588NED', '83149NED', '83148NED']\n"
     ]
    }
   ],
   "source": [
    "# Load the data from the JSON file\n",
    "with open('data/table_selection.json', 'r', encoding='utf-8') as json_file:\n",
    "    table_data = json.load(json_file)\n",
    "\n",
    "# Create a list to store the identifiers\n",
    "identifiers = []\n",
    "\n",
    "# Loop through the data and extract the Identifier for each entry\n",
    "for entry in table_data:\n",
    "    identifiers.append(entry['Identifier'])\n",
    "\n",
    "# Print the list of identifiers\n",
    "print(f\"List of Identifiers: {identifiers}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'os' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 37\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mData for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00midentifier\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m saved to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00moutput_file\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     36\u001b[0m \u001b[38;5;66;03m# Example usage\u001b[39;00m\n\u001b[0;32m---> 37\u001b[0m \u001b[43mfetch_and_save_tables\u001b[49m\u001b[43m(\u001b[49m\u001b[43midentifiers\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[5], line 14\u001b[0m, in \u001b[0;36mfetch_and_save_tables\u001b[0;34m(identifiers, output_folder)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03mFetches data for each table identifier using `cbsodata.get_data()` and saves it to a CSV file,\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124;03mskipping files that already exist.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;124;03m    None\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# Ensure the output folder exists\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[43mos\u001b[49m\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(output_folder):\n\u001b[1;32m     15\u001b[0m     os\u001b[38;5;241m.\u001b[39mmakedirs(output_folder)\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m identifier \u001b[38;5;129;01min\u001b[39;00m identifiers:\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;66;03m# Define the output CSV file path\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'os' is not defined"
     ]
    }
   ],
   "source": [
    "def fetch_and_save_tables(identifiers, output_folder='data'):\n",
    "    \"\"\"\n",
    "    Fetches data for each table identifier using `cbsodata.get_data()` and saves it to a CSV file,\n",
    "    skipping files that already exist.\n",
    "    \n",
    "    Parameters:\n",
    "        identifiers (list): List of table identifiers to fetch data for.\n",
    "        output_folder (str): The folder where the CSV files will be saved (default is 'data').\n",
    "    \n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    # Ensure the output folder exists\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "\n",
    "    for identifier in identifiers:\n",
    "        # Define the output CSV file path\n",
    "        output_file = f'{output_folder}/{identifier}.csv'\n",
    "        \n",
    "        # Check if the file already exists\n",
    "        if os.path.exists(output_file):\n",
    "            print(f\"Skipping {output_file} because it already exists.\")\n",
    "            continue\n",
    "        \n",
    "        # Fetch data for the current table identifier\n",
    "        print(f\"Fetching data for table identifier: {identifier}\")\n",
    "        data = pd.DataFrame(cbsodata.get_data(identifier))\n",
    "        \n",
    "        # Save the DataFrame to CSV\n",
    "        data.to_csv(output_file, index=False)\n",
    "        \n",
    "        # Print success message\n",
    "        print(f\"Data for {identifier} saved to {output_file}\")\n",
    "\n",
    "# Example usage\n",
    "fetch_and_save_tables(identifiers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load CSV files\n",
    "def load_csv_files(file_paths):\n",
    "    \"\"\"\n",
    "    Load multiple CSV files into DataFrames and prefix the column names with the file name.\n",
    "    \n",
    "    Parameters:\n",
    "        file_paths (list): List of file paths to CSV files.\n",
    "    \n",
    "    Returns:\n",
    "        list: List of DataFrames with prefixed column names.\n",
    "    \"\"\"\n",
    "    dataframes = []\n",
    "    \n",
    "    for file_path in file_paths:\n",
    "        # Extract the filename without the extension to use as a prefix\n",
    "        file_name = file_path.split('/')[-1].split('.')[0]\n",
    "        \n",
    "        # Load the CSV file into a DataFrame\n",
    "        df = pd.read_csv(file_path)\n",
    "        \n",
    "        # Prefix the column names with the filename\n",
    "        df = df.add_prefix(f\"{file_name}_\")\n",
    "        \n",
    "        # Special handling for 'Perioden' and 'SBI' columns, which shouldn't be prefixed\n",
    "        if f\"{file_name}_Perioden\" in df.columns:\n",
    "            df = df.rename(columns={f\"{file_name}_Perioden\": 'Perioden'})  # Keep 'Perioden' without prefix\n",
    "        if f\"{file_name}_BedrijfstakkenBranchesSBI2008\" in df.columns:\n",
    "            df = df.rename(columns={f\"{file_name}_BedrijfstakkenBranchesSBI2008\": 'BedrijfstakkenBranchesSBI2008'})  # Keep 'BedrijfstakkenBranchesSBI2008' without prefix\n",
    "        if f\"{file_name}_ID\" in df.columns:\n",
    "            df = df.rename(columns={f\"{file_name}_ID\": 'ID'})  # Keep 'ID' without prefix\n",
    "        if f\"{file_name}_Jaar\" in df.columns:\n",
    "            df = df.rename(columns={f\"{file_name}_Jaar\": 'Jaar'})  # Keep 'Jaar' without prefix\n",
    "        if f\"{file_name}_Kwartaal\" in df.columns:\n",
    "            df = df.rename(columns={f\"{file_name}_Kwartaal\": 'Kwartaal'})  # Keep 'Kwartaal' without prefix\n",
    "        \n",
    "        # Append to the list of DataFrames\n",
    "        dataframes.append(df)\n",
    "    \n",
    "    return dataframes\n",
    "\n",
    "# Function to process the 'Perioden' column\n",
    "def process_period_column(df, perioden_column='Perioden', year_column='Year', quarter_column='Quarter'):\n",
    "    \"\"\"\n",
    "    Process the 'Perioden' column to extract the latest year and quarter.\n",
    "    \n",
    "    Parameters:\n",
    "        df (DataFrame): DataFrame with 'Perioden' column.\n",
    "        perioden_column (str): Name of the period column.\n",
    "        year_column (str): Name of the column for extracted year.\n",
    "        quarter_column (str): Name of the column for extracted quarter.\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame: DataFrame with new 'Year' and 'Quarter' columns.\n",
    "    \"\"\"\n",
    "    # Extract latest year and quarter from 'Perioden' column\n",
    "    df[[year_column, quarter_column]] = df[perioden_column].apply(lambda x: pd.Series(extract_latest_year_and_quarter(x)))\n",
    "    return df\n",
    "\n",
    "# Helper function to extract latest year and quarter\n",
    "def extract_latest_year_and_quarter(period_text):\n",
    "    \"\"\"\n",
    "    Extracts the latest year and quarter from a period that may contain a date range (e.g., \"2023 april - 2024 maart\").\n",
    "    \n",
    "    Parameters:\n",
    "        period_text (str): The period string to process.\n",
    "    \n",
    "    Returns:\n",
    "        tuple: A tuple containing the latest year and quarter.\n",
    "    \"\"\"\n",
    "    # Regular expression to capture year and month/quarter references\n",
    "    match = re.findall(r'(\\d{4})\\s*(\\w+)', period_text)\n",
    "    \n",
    "    if match:\n",
    "        # Take the last match in the range (latest part of the period)\n",
    "        latest_year, latest_period_part = match[-1]\n",
    "        latest_year = int(latest_year)\n",
    "        \n",
    "        # Determine the corresponding quarter for the latest period part (month or quarter)\n",
    "        latest_quarter = extract_quarter(latest_period_part)\n",
    "        \n",
    "        return latest_year, latest_quarter\n",
    "    else:\n",
    "        # Return None if no valid year/quarter is found\n",
    "        return None, None\n",
    "\n",
    "# Helper function to determine the quarter based on months or quarter phrases like '3e kwartaal'\n",
    "def extract_quarter(period_part):\n",
    "    \"\"\"\n",
    "    Extracts the quarter from the period part (e.g., based on months or quarter keywords).\n",
    "    \n",
    "    Parameters:\n",
    "        period_part (str): The part of the period string after the year.\n",
    "    \n",
    "    Returns:\n",
    "        int: The corresponding quarter (1 to 4), or None if no valid quarter is found.\n",
    "    \"\"\"\n",
    "    # Handle month-based quarters\n",
    "    if any(month in period_part for month in ['januari', 'februari', 'maart']):\n",
    "        return 1\n",
    "    elif any(month in period_part for month in ['april', 'mei', 'juni']):\n",
    "        return 2\n",
    "    elif any(month in period_part for month in ['juli', 'augustus', 'september']):\n",
    "        return 3\n",
    "    elif any(month in period_part for month in ['oktober', 'november', 'december']):\n",
    "        return 4\n",
    "    \n",
    "    # Handle phrases like '1e kwartaal', '2e kwartaal', etc.\n",
    "    if '1e' in period_part:\n",
    "        return 1\n",
    "    elif '2e' in period_part:\n",
    "        return 2\n",
    "    elif '3e' in period_part:\n",
    "        return 3\n",
    "    elif '4e' in period_part:\n",
    "        return 4\n",
    "    \n",
    "    # Return None if no valid quarter is found\n",
    "    return None\n",
    "\n",
    "def rename_sbi_column(df, primary_sbi_column='BedrijfstakkenBranchesSBI2008', backup_sbi_column='BedrijfskenmerkenSBI2008'):\n",
    "    \"\"\"\n",
    "    Renames the 'BedrijfskenmerkenSBI2008' column to 'BedrijfstakkenBranchesSBI2008' if the primary column does not exist.\n",
    "    \n",
    "    Parameters:\n",
    "        df (DataFrame): The DataFrame to process.\n",
    "        primary_sbi_column (str): The desired primary SBI column name. Default is 'BedrijfstakkenBranchesSBI2008'.\n",
    "        backup_sbi_column (str): The backup SBI column to rename. Default is 'BedrijfskenmerkenSBI2008'.\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame: Updated DataFrame with the renamed column.\n",
    "    \"\"\"\n",
    "    # Check if the primary column does not exist and the backup column does exist\n",
    "    if primary_sbi_column not in df.columns and backup_sbi_column in df.columns:\n",
    "        # Rename 'BedrijfskenmerkenSBI2008' to 'BedrijfstakkenBranchesSBI2008'\n",
    "        df = df.rename(columns={backup_sbi_column: primary_sbi_column})\n",
    "        print(f\"Renamed '{backup_sbi_column}' to '{primary_sbi_column}'\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Function to filter by industry\n",
    "def filter_by_industry(df, industry_column='BedrijfstakkenBranchesSBI2008', valid_industries=None):\n",
    "    \"\"\"\n",
    "    Filter the DataFrame by specific industries.\n",
    "    \n",
    "    Parameters:\n",
    "        df (DataFrame): The DataFrame to filter.\n",
    "        industry_column (str): Name of the industry column.\n",
    "        valid_industries (list): List of valid industries to keep.\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame: Filtered DataFrame.\n",
    "    \"\"\"\n",
    "    if valid_industries is None:\n",
    "        valid_industries = [\n",
    "            \"Q Gezondheids- en welzijnszorg\", \n",
    "            \"G Handel\", \n",
    "            \"C Industrie\", \n",
    "            \"M Specialistische zakelijke diensten\", \n",
    "            \"N Verhuur en overige zakelijke diensten\", \n",
    "            \"O Openbaar bestuur en overheidsdiensten\"\n",
    "        ]\n",
    "    return df[df[industry_column].isin(valid_industries)]\n",
    "\n",
    "# Function to filter by year range\n",
    "def filter_by_year(df, year_column='Year', start_year=2008, end_year=2022):\n",
    "    \"\"\"\n",
    "    Filter the DataFrame by a range of years.\n",
    "    \n",
    "    Parameters:\n",
    "        df (DataFrame): The DataFrame to filter.\n",
    "        year_column (str): Name of the year column.\n",
    "        start_year (int): The start year (inclusive).\n",
    "        end_year (int): The end year (inclusive).\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame: Filtered DataFrame.\n",
    "    \"\"\"\n",
    "    return df[(df[year_column] >= start_year) & (df[year_column] <= end_year)]\n",
    "\n",
    "def clean_dataframe(df, id_column='ID', year_column='Year', quarter_column='Quarter', sbi_column='BedrijfstakkenBranchesSBI2008', sick_leave_column='80072ned_Ziekteverzuimpercentage_1', columns_to_drop=None):\n",
    "    \"\"\"\n",
    "    Cleans the DataFrame by reordering columns to have 'Year', 'Quarter', 'BedrijfstakkenBranchesSBI2008', and '80072ned_Ziekteverzuimpercentage_1' as the first four columns,\n",
    "    dropping specified columns, and removing duplicate rows.\n",
    "    \n",
    "    Parameters:\n",
    "        df (DataFrame): The DataFrame to clean.\n",
    "        year_column (str): The year column name. Default is 'Year'.\n",
    "        quarter_column (str): The quarter column name. Default is 'Quarter'.\n",
    "        sbi_column (str): The column name for SBI. Default is 'BedrijfstakkenBranchesSBI2008'.\n",
    "        sick_leave_column (str): The sick leave column name. Default is '80072ned_Ziekteverzuimpercentage_1'.\n",
    "        columns_to_drop (list): List of column names to drop. Default is ['ID', 'Perioden'].\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame: Cleaned DataFrame with reordered columns, specified columns dropped, and duplicates removed.\n",
    "    \"\"\"\n",
    "    if columns_to_drop is None:\n",
    "        columns_to_drop = ['ID', 'Perioden', 'Jaar', 'Kwartaal']\n",
    "\n",
    "    # Define the preferred order of the first four columns\n",
    "    preferred_columns = [year_column, quarter_column, sbi_column, sick_leave_column]\n",
    "\n",
    "    # Collect remaining columns in their original order (excluding the preferred ones)\n",
    "    remaining_columns = [col for col in df.columns if col not in preferred_columns]\n",
    "\n",
    "    # Combine the preferred columns with the remaining ones\n",
    "    ordered_columns = preferred_columns + remaining_columns\n",
    "\n",
    "    # Reorder DataFrame\n",
    "    df = df[ordered_columns]\n",
    "\n",
    "    # Drop the specified columns\n",
    "    df = df.drop(columns=columns_to_drop, errors='ignore')\n",
    "\n",
    "    # Remove duplicate rows\n",
    "    df = df.drop_duplicates()\n",
    "\n",
    "    return df\n",
    "\n",
    "def group_and_sum(df, group_by_columns):\n",
    "    \"\"\"\n",
    "    Group the DataFrame by specified columns and sum the numeric values.\n",
    "    \n",
    "    Parameters:\n",
    "        df (DataFrame): The DataFrame to group.\n",
    "        group_by_columns (list): List of columns to group by (e.g., ['Year', 'Quarter', 'BedrijfstakkenBranchesSBI2008']).\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame: Grouped and summed DataFrame.\n",
    "    \"\"\"\n",
    "    # Group by the specified columns and sum the numeric columns\n",
    "    df = df.groupby(group_by_columns).sum(numeric_only=True).reset_index()\n",
    "    \n",
    "    return df\n",
    "\n",
    "def process_tables(tables):\n",
    "    \"\"\"\n",
    "    Process and combine multiple tables into a single DataFrame by:\n",
    "    - Processing the 'Perioden' column to extract 'Year' and 'Quarter'\n",
    "    - Filtering by specific industries and year range\n",
    "    - Reordering columns to have 'Year' and 'Quarter' after 'ID'\n",
    "    - Dropping unnecessary columns\n",
    "    - Removing duplicates\n",
    "    - Grouping by 'Year', 'Quarter', and 'BedrijfstakkenBranchesSBI2008' and summing the data\n",
    "    \n",
    "    Parameters:\n",
    "        tables (list): List of DataFrames.\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame: The final combined DataFrame.\n",
    "    \"\"\"\n",
    "    # Concatenate the list of tables into one DataFrame\n",
    "    concat_df = pd.concat(tables, ignore_index=True)\n",
    "    \n",
    "    # Step 1: Process the 'Perioden' column\n",
    "    period_df = process_period_column(concat_df)\n",
    "    \n",
    "    # Step 2: Fill missing 'BedrijfstakkenBranchesSBI2008' with 'BedrijfskenmerkenSBI2008'\n",
    "    sbi_df = rename_sbi_column(period_df)\n",
    "    \n",
    "    # Step 3: Filter by industry\n",
    "    industry_df = filter_by_industry(sbi_df)\n",
    "    \n",
    "    # Step 4: Filter by year range (2008 to 2022)\n",
    "    year_df = filter_by_year(industry_df)\n",
    "    \n",
    "    # Step 5: Clean the DataFrame: reorder columns, drop unnecessary ones, and remove duplicates\n",
    "    clean_df = clean_dataframe(year_df)\n",
    "    \n",
    "    # Step 6: Group by 'Year', 'Quarter', and 'BedrijfstakkenBranchesSBI2008' and sum the numeric columns\n",
    "    final_df = group_and_sum(clean_df, ['Year', 'Quarter', 'BedrijfstakkenBranchesSBI2008'])\n",
    "    \n",
    "    return final_df\n",
    "\n",
    "# Load the identifiers from the JSON file\n",
    "with open('data/table_selection.json', 'r', encoding='utf-8') as json_file:\n",
    "    table_data = json.load(json_file)\n",
    "    identifiers = [entry['Identifier'] for entry in table_data]\n",
    "\n",
    "# Dynamically generate the file paths using the identifiers\n",
    "file_paths = [f'data/{identifier}.csv' for identifier in identifiers]\n",
    "\n",
    "# Load and process the data\n",
    "tables = load_csv_files(file_paths)\n",
    "final_df = process_tables(tables)\n",
    "\n",
    "# Save the final DataFrame to a CSV file\n",
    "final_df.to_csv('data/merged_tables.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
